{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "268x1mG64rCy"
   },
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VNvKG2TF3Y0B",
    "outputId": "64393040-91f6-49e8-8656-f8de9480b867"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing setup.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile setup.sh\n",
    "\n",
    "# maskrcnn_benchmark and coco api dependencies\n",
    "pip install ninja yacs cython matplotlib tqdm opencv-python\n",
    "\n",
    "# follow PyTorch installation in https://pytorch.org/get-started/locally/\n",
    "# we give the instructions for CUDA 9.0\n",
    "pip install -c pytorch pytorch-nightly torchvision cudatoolkit=9.0\n",
    "\n",
    "\n",
    "git clone https://github.com/cocodataset/cocoapi.git\n",
    "cd cocoapi/PythonAPI\n",
    "python setup.py build_ext install\n",
    "cd ../../\n",
    "\n",
    "# install apex\n",
    "rm -rf apex\n",
    "git clone https://github.com/NVIDIA/apex.git\n",
    "cd apex\n",
    "git pull\n",
    "python setup.py install --cuda_ext --cpp_ext\n",
    "cd ../\n",
    "\n",
    "# install PyTorch Detection\n",
    "git clone https://github.com/facebookresearch/maskrcnn-benchmark.git\n",
    "cd maskrcnn-benchmark\n",
    "\n",
    "# the following will install the lib with\n",
    "# symbolic links, so that you can modify\n",
    "# the files if you want and won't need to\n",
    "# re-build it\n",
    "python setup.py build develop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 13705
    },
    "colab_type": "code",
    "id": "NYzsp3Ng3mOy",
    "outputId": "e1230ab4-a5b6-41b7-fa69-5b175a20b26d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ninja\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/bf/32e5dd5cce6543374e4050a7292099402ab80787eddf3732810a55b37763/ninja-1.9.0.post1-py3-none-manylinux1_x86_64.whl (98kB)\n",
      "\u001b[K     |████████████████████████████████| 102kB 32.5MB/s \n",
      "\u001b[?25hCollecting yacs\n",
      "  Downloading https://files.pythonhosted.org/packages/2f/51/9d613d67a8561a0cdf696c3909870f157ed85617fea3cff769bb7de09ef7/yacs-0.1.6-py3-none-any.whl\n",
      "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (0.29.9)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.0.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (3.4.5.20)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from yacs) (3.13)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.0)\n",
      "Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.16.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.5.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib) (41.0.1)\n",
      "Installing collected packages: ninja, yacs\n",
      "Successfully installed ninja-1.9.0.post1 yacs-0.1.6\n",
      "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'pytorch'\u001b[0m\n",
      "Cloning into 'cocoapi'...\n",
      "remote: Enumerating objects: 953, done.\u001b[K\n",
      "remote: Total 953 (delta 0), reused 0 (delta 0), pack-reused 953\u001b[K\n",
      "Receiving objects: 100% (953/953), 11.70 MiB | 6.53 MiB/s, done.\n",
      "Resolving deltas: 100% (565/565), done.\n",
      "running build_ext\n",
      "cythoning pycocotools/_mask.pyx to pycocotools/_mask.c\n",
      "/usr/local/lib/python3.6/dist-packages/Cython/Compiler/Main.py:367: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/cocoapi/PythonAPI/pycocotools/_mask.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "building 'pycocotools._mask' extension\n",
      "creating build\n",
      "creating build/common\n",
      "creating build/temp.linux-x86_64-3.6\n",
      "creating build/temp.linux-x86_64-3.6/pycocotools\n",
      "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I../common -I/usr/include/python3.6m -c ../common/maskApi.c -o build/temp.linux-x86_64-3.6/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleDecode\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:46:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n",
      "       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:46:49:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
      "       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; \u001b[01;36m\u001b[Kv\u001b[m\u001b[K=!v; }}\n",
      "                                                 \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrPoly\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:166:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n",
      "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:166:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
      "   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); \u001b[01;36m\u001b[Kx\u001b[m\u001b[K[k]=x[0];\n",
      "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:167:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n",
      "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:167:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
      "   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); \u001b[01;36m\u001b[Ky\u001b[m\u001b[K[k]=y[0];\n",
      "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToString\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:212:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "       \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(more) c |= 0x20; c+=48; s[p++]=c;\n",
      "       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:212:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
      "       if(more) c |= 0x20; \u001b[01;36m\u001b[Kc\u001b[m\u001b[K+=48; s[p++]=c;\n",
      "                           \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrString\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:220:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "   \u001b[01;35m\u001b[Kwhile\u001b[m\u001b[K( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n",
      "   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:220:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’\n",
      "   while( s[m] ) m++; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K=malloc(sizeof(uint)*m); m=0;\n",
      "                      \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:228:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "     \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n",
      "     \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:228:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
      "     if(m>2) x+=(long) cnts[m-2]; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K[m++]=(uint) x;\n",
      "                                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToBbox\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:141:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kxp\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
      "       if(j%2==0) xp=x; else if\u001b[01;35m\u001b[K(\u001b[m\u001b[Kxp<x) { ys=0; ye=h-1; }\n",
      "                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I../common -I/usr/include/python3.6m -c pycocotools/_mask.c -o build/temp.linux-x86_64-3.6/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n",
      "creating build/lib.linux-x86_64-3.6\n",
      "creating build/lib.linux-x86_64-3.6/pycocotools\n",
      "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/../common/maskApi.o build/temp.linux-x86_64-3.6/pycocotools/_mask.o -o build/lib.linux-x86_64-3.6/pycocotools/_mask.cpython-36m-x86_64-linux-gnu.so\n",
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "creating pycocotools.egg-info\n",
      "writing pycocotools.egg-info/PKG-INFO\n",
      "writing dependency_links to pycocotools.egg-info/dependency_links.txt\n",
      "writing requirements to pycocotools.egg-info/requires.txt\n",
      "writing top-level names to pycocotools.egg-info/top_level.txt\n",
      "writing manifest file 'pycocotools.egg-info/SOURCES.txt'\n",
      "writing manifest file 'pycocotools.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "running build_py\n",
      "copying pycocotools/__init__.py -> build/lib.linux-x86_64-3.6/pycocotools\n",
      "copying pycocotools/mask.py -> build/lib.linux-x86_64-3.6/pycocotools\n",
      "copying pycocotools/coco.py -> build/lib.linux-x86_64-3.6/pycocotools\n",
      "copying pycocotools/cocoeval.py -> build/lib.linux-x86_64-3.6/pycocotools\n",
      "creating build/bdist.linux-x86_64\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/pycocotools\n",
      "copying build/lib.linux-x86_64-3.6/pycocotools/__init__.py -> build/bdist.linux-x86_64/egg/pycocotools\n",
      "copying build/lib.linux-x86_64-3.6/pycocotools/mask.py -> build/bdist.linux-x86_64/egg/pycocotools\n",
      "copying build/lib.linux-x86_64-3.6/pycocotools/_mask.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/pycocotools\n",
      "copying build/lib.linux-x86_64-3.6/pycocotools/coco.py -> build/bdist.linux-x86_64/egg/pycocotools\n",
      "copying build/lib.linux-x86_64-3.6/pycocotools/cocoeval.py -> build/bdist.linux-x86_64/egg/pycocotools\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pycocotools/__init__.py to __init__.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pycocotools/mask.py to mask.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pycocotools/coco.py to coco.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pycocotools/cocoeval.py to cocoeval.cpython-36.pyc\n",
      "creating stub loader for pycocotools/_mask.cpython-36m-x86_64-linux-gnu.so\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pycocotools/_mask.py to _mask.cpython-36.pyc\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying pycocotools.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying pycocotools.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying pycocotools.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying pycocotools.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying pycocotools.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "pycocotools.__pycache__._mask.cpython-36: module references __file__\n",
      "creating dist\n",
      "creating 'dist/pycocotools-2.0-py3.6-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing pycocotools-2.0-py3.6-linux-x86_64.egg\n",
      "creating /usr/local/lib/python3.6/dist-packages/pycocotools-2.0-py3.6-linux-x86_64.egg\n",
      "Extracting pycocotools-2.0-py3.6-linux-x86_64.egg to /usr/local/lib/python3.6/dist-packages\n",
      "Adding pycocotools 2.0 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.6/dist-packages/pycocotools-2.0-py3.6-linux-x86_64.egg\n",
      "Processing dependencies for pycocotools==2.0\n",
      "Searching for matplotlib==3.0.3\n",
      "Best match: matplotlib 3.0.3\n",
      "Adding matplotlib 3.0.3 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Searching for Cython==0.29.9\n",
      "Best match: Cython 0.29.9\n",
      "Adding Cython 0.29.9 to easy-install.pth file\n",
      "Installing cygdb script to /usr/local/bin\n",
      "Installing cython script to /usr/local/bin\n",
      "Installing cythonize script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Searching for setuptools==41.0.1\n",
      "Best match: setuptools 41.0.1\n",
      "Adding setuptools 41.0.1 to easy-install.pth file\n",
      "Installing easy_install script to /usr/local/bin\n",
      "Installing easy_install-3.6 script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Searching for pyparsing==2.4.0\n",
      "Best match: pyparsing 2.4.0\n",
      "Adding pyparsing 2.4.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Searching for kiwisolver==1.1.0\n",
      "Best match: kiwisolver 1.1.0\n",
      "Adding kiwisolver 1.1.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Searching for python-dateutil==2.5.3\n",
      "Best match: python-dateutil 2.5.3\n",
      "Adding python-dateutil 2.5.3 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Searching for numpy==1.16.4\n",
      "Best match: numpy 1.16.4\n",
      "Adding numpy 1.16.4 to easy-install.pth file\n",
      "Installing f2py script to /usr/local/bin\n",
      "Installing f2py3 script to /usr/local/bin\n",
      "Installing f2py3.6 script to /usr/local/bin\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Searching for cycler==0.10.0\n",
      "Best match: cycler 0.10.0\n",
      "Adding cycler 0.10.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Searching for six==1.12.0\n",
      "Best match: six 1.12.0\n",
      "Adding six 1.12.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python3.6/dist-packages\n",
      "Finished processing dependencies for pycocotools==2.0\n",
      "Cloning into 'apex'...\n",
      "remote: Enumerating objects: 28, done.\u001b[K\n",
      "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
      "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
      "remote: Total 4606 (delta 12), reused 7 (delta 3), pack-reused 4578\u001b[K\n",
      "Receiving objects: 100% (4606/4606), 8.68 MiB | 6.00 MiB/s, done.\n",
      "Resolving deltas: 100% (2982/2982), done.\n",
      "Already up to date.\n",
      "torch.__version__  =  1.1.0\n",
      "\n",
      "Compiling cuda extensions with\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2018 NVIDIA Corporation\n",
      "Built on Sat_Aug_25_21:08:01_CDT_2018\n",
      "Cuda compilation tools, release 10.0, V10.0.130\n",
      "from /usr/local/cuda/bin\n",
      "\n",
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "creating apex.egg-info\n",
      "writing apex.egg-info/PKG-INFO\n",
      "writing dependency_links to apex.egg-info/dependency_links.txt\n",
      "writing top-level names to apex.egg-info/top_level.txt\n",
      "writing manifest file 'apex.egg-info/SOURCES.txt'\n",
      "writing manifest file 'apex.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib.linux-x86_64-3.6\n",
      "creating build/lib.linux-x86_64-3.6/apex\n",
      "copying apex/__init__.py -> build/lib.linux-x86_64-3.6/apex\n",
      "creating build/lib.linux-x86_64-3.6/apex/reparameterization\n",
      "copying apex/reparameterization/__init__.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
      "copying apex/reparameterization/weight_norm.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
      "copying apex/reparameterization/reparameterization.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
      "creating build/lib.linux-x86_64-3.6/apex/parallel\n",
      "copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "copying apex/parallel/__init__.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "copying apex/parallel/LARC.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "copying apex/parallel/distributed.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "creating build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "creating build/lib.linux-x86_64-3.6/apex/amp\n",
      "copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "copying apex/amp/frontend.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "copying apex/amp/wrap.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "copying apex/amp/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "copying apex/amp/amp.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "copying apex/amp/compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "copying apex/amp/__version__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "copying apex/amp/opt.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "copying apex/amp/_initialize.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "copying apex/amp/utils.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "copying apex/amp/handle.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "copying apex/amp/scaler.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "creating build/lib.linux-x86_64-3.6/apex/normalization\n",
      "copying apex/normalization/__init__.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
      "copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
      "creating build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
      "copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
      "copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
      "creating build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "copying apex/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "creating build/lib.linux-x86_64-3.6/apex/RNN\n",
      "copying apex/RNN/__init__.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
      "copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
      "copying apex/RNN/models.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
      "copying apex/RNN/cells.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
      "creating build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "running build_ext\n",
      "building 'apex_C' extension\n",
      "creating build/temp.linux-x86_64-3.6\n",
      "creating build/temp.linux-x86_64-3.6/csrc\n",
      "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c csrc/flatten_unflatten.cpp -o build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -o build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so\n",
      "building 'amp_C' extension\n",
      "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/amp_C_frontend.cpp -o build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_scale_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_axpby_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_l2norm_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_1.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_2.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so\n",
      "building 'fused_adam_cuda' extension\n",
      "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/fused_adam_cuda.cpp -o build/temp.linux-x86_64-3.6/csrc/fused_adam_cuda.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_adam_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/fused_adam_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/fused_adam_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_adam_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/fused_adam_cuda.o build/temp.linux-x86_64-3.6/csrc/fused_adam_cuda_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/fused_adam_cuda.cpython-36m-x86_64-linux-gnu.so\n",
      "building 'syncbn' extension\n",
      "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/syncbn.cpp -o build/temp.linux-x86_64-3.6/csrc/syncbn.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/welford.cu -o build/temp.linux-x86_64-3.6/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/syncbn.o build/temp.linux-x86_64-3.6/csrc/welford.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so\n",
      "building 'fused_layer_norm_cuda' extension\n",
      "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda.cpp -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o -O3 -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -maxrregcount=50 -O3 --use_fast_math -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so\n",
      "creating build/bdist.linux-x86_64\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "copying build/lib.linux-x86_64-3.6/fused_adam_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
      "copying build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
      "copying build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/apex\n",
      "creating build/bdist.linux-x86_64/egg/apex/reparameterization\n",
      "copying build/lib.linux-x86_64-3.6/apex/reparameterization/__init__.py -> build/bdist.linux-x86_64/egg/apex/reparameterization\n",
      "copying build/lib.linux-x86_64-3.6/apex/reparameterization/weight_norm.py -> build/bdist.linux-x86_64/egg/apex/reparameterization\n",
      "copying build/lib.linux-x86_64-3.6/apex/reparameterization/reparameterization.py -> build/bdist.linux-x86_64/egg/apex/reparameterization\n",
      "copying build/lib.linux-x86_64-3.6/apex/__init__.py -> build/bdist.linux-x86_64/egg/apex\n",
      "creating build/bdist.linux-x86_64/egg/apex/parallel\n",
      "copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
      "copying build/lib.linux-x86_64-3.6/apex/parallel/__init__.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
      "copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
      "copying build/lib.linux-x86_64-3.6/apex/parallel/LARC.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
      "copying build/lib.linux-x86_64-3.6/apex/parallel/multiproc.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
      "copying build/lib.linux-x86_64-3.6/apex/parallel/distributed.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
      "copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
      "copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
      "creating build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
      "copying build/lib.linux-x86_64-3.6/apex/fp16_utils/__init__.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
      "copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16_optimizer.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
      "copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16util.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
      "copying build/lib.linux-x86_64-3.6/apex/fp16_utils/loss_scaler.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
      "creating build/bdist.linux-x86_64/egg/apex/amp\n",
      "creating build/bdist.linux-x86_64/egg/apex/amp/lists\n",
      "copying build/lib.linux-x86_64-3.6/apex/amp/lists/__init__.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n",
      "copying build/lib.linux-x86_64-3.6/apex/amp/lists/torch_overrides.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n",
      "copying build/lib.linux-x86_64-3.6/apex/amp/lists/functional_overrides.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n",
      "copying build/lib.linux-x86_64-3.6/apex/amp/lists/tensor_overrides.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n",
      "copying build/lib.linux-x86_64-3.6/apex/amp/rnn_compat.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
      "copying build/lib.linux-x86_64-3.6/apex/amp/frontend.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
      "copying build/lib.linux-x86_64-3.6/apex/amp/wrap.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
      "copying build/lib.linux-x86_64-3.6/apex/amp/__init__.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
      "copying build/lib.linux-x86_64-3.6/apex/amp/amp.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
      "copying build/lib.linux-x86_64-3.6/apex/amp/compat.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
      "copying build/lib.linux-x86_64-3.6/apex/amp/_process_optimizer.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
      "copying build/lib.linux-x86_64-3.6/apex/amp/__version__.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
      "copying build/lib.linux-x86_64-3.6/apex/amp/opt.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
      "copying build/lib.linux-x86_64-3.6/apex/amp/_initialize.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
      "copying build/lib.linux-x86_64-3.6/apex/amp/_amp_state.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
      "copying build/lib.linux-x86_64-3.6/apex/amp/utils.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
      "copying build/lib.linux-x86_64-3.6/apex/amp/handle.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
      "copying build/lib.linux-x86_64-3.6/apex/amp/scaler.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
      "creating build/bdist.linux-x86_64/egg/apex/normalization\n",
      "copying build/lib.linux-x86_64-3.6/apex/normalization/__init__.py -> build/bdist.linux-x86_64/egg/apex/normalization\n",
      "copying build/lib.linux-x86_64-3.6/apex/normalization/fused_layer_norm.py -> build/bdist.linux-x86_64/egg/apex/normalization\n",
      "creating build/bdist.linux-x86_64/egg/apex/multi_tensor_apply\n",
      "copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/__init__.py -> build/bdist.linux-x86_64/egg/apex/multi_tensor_apply\n",
      "copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/multi_tensor_apply.py -> build/bdist.linux-x86_64/egg/apex/multi_tensor_apply\n",
      "creating build/bdist.linux-x86_64/egg/apex/optimizers\n",
      "copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adam.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
      "copying build/lib.linux-x86_64-3.6/apex/optimizers/__init__.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
      "copying build/lib.linux-x86_64-3.6/apex/optimizers/fp16_optimizer.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
      "creating build/bdist.linux-x86_64/egg/apex/RNN\n",
      "copying build/lib.linux-x86_64-3.6/apex/RNN/__init__.py -> build/bdist.linux-x86_64/egg/apex/RNN\n",
      "copying build/lib.linux-x86_64-3.6/apex/RNN/RNNBackend.py -> build/bdist.linux-x86_64/egg/apex/RNN\n",
      "copying build/lib.linux-x86_64-3.6/apex/RNN/models.py -> build/bdist.linux-x86_64/egg/apex/RNN\n",
      "copying build/lib.linux-x86_64-3.6/apex/RNN/cells.py -> build/bdist.linux-x86_64/egg/apex/RNN\n",
      "copying build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
      "copying build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/reparameterization/__init__.py to __init__.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/reparameterization/weight_norm.py to weight_norm.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/reparameterization/reparameterization.py to reparameterization.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/__init__.py to __init__.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/__init__.py to __init__.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/LARC.py to LARC.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/multiproc.py to multiproc.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/distributed.py to distributed.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/__init__.py to __init__.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/fp16util.py to fp16util.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/__init__.py to __init__.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/rnn_compat.py to rnn_compat.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/frontend.py to frontend.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/wrap.py to wrap.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/__init__.py to __init__.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/amp.py to amp.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/compat.py to compat.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/_process_optimizer.py to _process_optimizer.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/__version__.py to __version__.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/opt.py to opt.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/_initialize.py to _initialize.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/_amp_state.py to _amp_state.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/utils.py to utils.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/handle.py to handle.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/scaler.py to scaler.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/normalization/__init__.py to __init__.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/multi_tensor_apply/__init__.py to __init__.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/__init__.py to __init__.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/__init__.py to __init__.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/RNNBackend.py to RNNBackend.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/models.py to models.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/cells.py to cells.cpython-36.pyc\n",
      "creating stub loader for apex_C.cpython-36m-x86_64-linux-gnu.so\n",
      "creating stub loader for amp_C.cpython-36m-x86_64-linux-gnu.so\n",
      "creating stub loader for fused_adam_cuda.cpython-36m-x86_64-linux-gnu.so\n",
      "creating stub loader for syncbn.cpython-36m-x86_64-linux-gnu.so\n",
      "creating stub loader for fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so\n",
      "byte-compiling build/bdist.linux-x86_64/egg/apex_C.py to apex_C.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/amp_C.py to amp_C.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fused_adam_cuda.py to fused_adam_cuda.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/syncbn.py to syncbn.cpython-36.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/fused_layer_norm_cuda.py to fused_layer_norm_cuda.cpython-36.pyc\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying apex.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying apex.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying apex.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying apex.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "__pycache__.amp_C.cpython-36: module references __file__\n",
      "__pycache__.apex_C.cpython-36: module references __file__\n",
      "__pycache__.fused_adam_cuda.cpython-36: module references __file__\n",
      "__pycache__.fused_layer_norm_cuda.cpython-36: module references __file__\n",
      "__pycache__.syncbn.cpython-36: module references __file__\n",
      "creating dist\n",
      "creating 'dist/apex-0.1-py3.6-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing apex-0.1-py3.6-linux-x86_64.egg\n",
      "creating /usr/local/lib/python3.6/dist-packages/apex-0.1-py3.6-linux-x86_64.egg\n",
      "Extracting apex-0.1-py3.6-linux-x86_64.egg to /usr/local/lib/python3.6/dist-packages\n",
      "Adding apex 0.1 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python3.6/dist-packages/apex-0.1-py3.6-linux-x86_64.egg\n",
      "Processing dependencies for apex==0.1\n",
      "Finished processing dependencies for apex==0.1\n",
      "Cloning into 'maskrcnn-benchmark'...\n",
      "remote: Enumerating objects: 1, done.\u001b[K\n",
      "remote: Counting objects: 100% (1/1), done.\u001b[K\n",
      "remote: Total 1524 (delta 0), reused 1 (delta 0), pack-reused 1523\u001b[K\n",
      "Receiving objects: 100% (1524/1524), 6.31 MiB | 4.94 MiB/s, done.\n",
      "Resolving deltas: 100% (917/917), done.\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib.linux-x86_64-3.6\n",
      "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark\n",
      "copying maskrcnn_benchmark/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark\n",
      "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/engine\n",
      "copying maskrcnn_benchmark/engine/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/engine\n",
      "copying maskrcnn_benchmark/engine/inference.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/engine\n",
      "copying maskrcnn_benchmark/engine/bbox_aug.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/engine\n",
      "copying maskrcnn_benchmark/engine/trainer.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/engine\n",
      "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/solver\n",
      "copying maskrcnn_benchmark/solver/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/solver\n",
      "copying maskrcnn_benchmark/solver/build.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/solver\n",
      "copying maskrcnn_benchmark/solver/lr_scheduler.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/solver\n",
      "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/config\n",
      "copying maskrcnn_benchmark/config/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/config\n",
      "copying maskrcnn_benchmark/config/defaults.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/config\n",
      "copying maskrcnn_benchmark/config/paths_catalog.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/config\n",
      "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/layers\n",
      "copying maskrcnn_benchmark/layers/sigmoid_focal_loss.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/layers\n",
      "copying maskrcnn_benchmark/layers/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/layers\n",
      "copying maskrcnn_benchmark/layers/misc.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/layers\n",
      "copying maskrcnn_benchmark/layers/smooth_l1_loss.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/layers\n",
      "copying maskrcnn_benchmark/layers/roi_align.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/layers\n",
      "copying maskrcnn_benchmark/layers/_utils.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/layers\n",
      "copying maskrcnn_benchmark/layers/nms.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/layers\n",
      "copying maskrcnn_benchmark/layers/batch_norm.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/layers\n",
      "copying maskrcnn_benchmark/layers/roi_pool.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/layers\n",
      "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data\n",
      "copying maskrcnn_benchmark/data/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data\n",
      "copying maskrcnn_benchmark/data/collate_batch.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data\n",
      "copying maskrcnn_benchmark/data/build.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data\n",
      "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/structures\n",
      "copying maskrcnn_benchmark/structures/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/structures\n",
      "copying maskrcnn_benchmark/structures/boxlist_ops.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/structures\n",
      "copying maskrcnn_benchmark/structures/image_list.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/structures\n",
      "copying maskrcnn_benchmark/structures/segmentation_mask.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/structures\n",
      "copying maskrcnn_benchmark/structures/keypoint.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/structures\n",
      "copying maskrcnn_benchmark/structures/bounding_box.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/structures\n",
      "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling\n",
      "copying maskrcnn_benchmark/modeling/box_coder.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling\n",
      "copying maskrcnn_benchmark/modeling/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling\n",
      "copying maskrcnn_benchmark/modeling/matcher.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling\n",
      "copying maskrcnn_benchmark/modeling/registry.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling\n",
      "copying maskrcnn_benchmark/modeling/utils.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling\n",
      "copying maskrcnn_benchmark/modeling/poolers.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling\n",
      "copying maskrcnn_benchmark/modeling/balanced_positive_negative_sampler.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling\n",
      "copying maskrcnn_benchmark/modeling/make_layers.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling\n",
      "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/utils\n",
      "copying maskrcnn_benchmark/utils/comm.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/utils\n",
      "copying maskrcnn_benchmark/utils/checkpoint.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/utils\n",
      "copying maskrcnn_benchmark/utils/metric_logger.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/utils\n",
      "copying maskrcnn_benchmark/utils/model_serialization.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/utils\n",
      "copying maskrcnn_benchmark/utils/miscellaneous.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/utils\n",
      "copying maskrcnn_benchmark/utils/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/utils\n",
      "copying maskrcnn_benchmark/utils/env.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/utils\n",
      "copying maskrcnn_benchmark/utils/imports.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/utils\n",
      "copying maskrcnn_benchmark/utils/timer.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/utils\n",
      "copying maskrcnn_benchmark/utils/cv2_util.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/utils\n",
      "copying maskrcnn_benchmark/utils/c2_model_loading.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/utils\n",
      "copying maskrcnn_benchmark/utils/registry.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/utils\n",
      "copying maskrcnn_benchmark/utils/collect_env.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/utils\n",
      "copying maskrcnn_benchmark/utils/model_zoo.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/utils\n",
      "copying maskrcnn_benchmark/utils/logger.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/utils\n",
      "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/layers/dcn\n",
      "copying maskrcnn_benchmark/layers/dcn/deform_conv_module.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/layers/dcn\n",
      "copying maskrcnn_benchmark/layers/dcn/deform_pool_module.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/layers/dcn\n",
      "copying maskrcnn_benchmark/layers/dcn/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/layers/dcn\n",
      "copying maskrcnn_benchmark/layers/dcn/deform_pool_func.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/layers/dcn\n",
      "copying maskrcnn_benchmark/layers/dcn/deform_conv_func.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/layers/dcn\n",
      "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/transforms\n",
      "copying maskrcnn_benchmark/data/transforms/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/transforms\n",
      "copying maskrcnn_benchmark/data/transforms/build.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/transforms\n",
      "copying maskrcnn_benchmark/data/transforms/transforms.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/transforms\n",
      "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/samplers\n",
      "copying maskrcnn_benchmark/data/samplers/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/samplers\n",
      "copying maskrcnn_benchmark/data/samplers/distributed.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/samplers\n",
      "copying maskrcnn_benchmark/data/samplers/grouped_batch_sampler.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/samplers\n",
      "copying maskrcnn_benchmark/data/samplers/iteration_based_batch_sampler.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/samplers\n",
      "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/datasets\n",
      "copying maskrcnn_benchmark/data/datasets/voc.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/datasets\n",
      "copying maskrcnn_benchmark/data/datasets/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/datasets\n",
      "copying maskrcnn_benchmark/data/datasets/coco.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/datasets\n",
      "copying maskrcnn_benchmark/data/datasets/concat_dataset.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/datasets\n",
      "copying maskrcnn_benchmark/data/datasets/list_dataset.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/datasets\n",
      "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/datasets/evaluation\n",
      "copying maskrcnn_benchmark/data/datasets/evaluation/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/datasets/evaluation\n",
      "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/datasets/evaluation/coco\n",
      "copying maskrcnn_benchmark/data/datasets/evaluation/coco/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/datasets/evaluation/coco\n",
      "copying maskrcnn_benchmark/data/datasets/evaluation/coco/coco_eval.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/datasets/evaluation/coco\n",
      "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/datasets/evaluation/voc\n",
      "copying maskrcnn_benchmark/data/datasets/evaluation/voc/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/datasets/evaluation/voc\n",
      "copying maskrcnn_benchmark/data/datasets/evaluation/voc/voc_eval.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/data/datasets/evaluation/voc\n",
      "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/rpn\n",
      "copying maskrcnn_benchmark/modeling/rpn/anchor_generator.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/rpn\n",
      "copying maskrcnn_benchmark/modeling/rpn/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/rpn\n",
      "copying maskrcnn_benchmark/modeling/rpn/loss.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/rpn\n",
      "copying maskrcnn_benchmark/modeling/rpn/inference.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/rpn\n",
      "copying maskrcnn_benchmark/modeling/rpn/rpn.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/rpn\n",
      "copying maskrcnn_benchmark/modeling/rpn/utils.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/rpn\n",
      "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/detector\n",
      "copying maskrcnn_benchmark/modeling/detector/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/detector\n",
      "copying maskrcnn_benchmark/modeling/detector/detectors.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/detector\n",
      "copying maskrcnn_benchmark/modeling/detector/generalized_rcnn.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/detector\n",
      "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads\n",
      "copying maskrcnn_benchmark/modeling/roi_heads/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads\n",
      "copying maskrcnn_benchmark/modeling/roi_heads/roi_heads.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads\n",
      "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/backbone\n",
      "copying maskrcnn_benchmark/modeling/backbone/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/backbone\n",
      "copying maskrcnn_benchmark/modeling/backbone/fbnet.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/backbone\n",
      "copying maskrcnn_benchmark/modeling/backbone/fbnet_modeldef.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/backbone\n",
      "copying maskrcnn_benchmark/modeling/backbone/fpn.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/backbone\n",
      "copying maskrcnn_benchmark/modeling/backbone/fbnet_builder.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/backbone\n",
      "copying maskrcnn_benchmark/modeling/backbone/backbone.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/backbone\n",
      "copying maskrcnn_benchmark/modeling/backbone/resnet.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/backbone\n",
      "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/rpn/retinanet\n",
      "copying maskrcnn_benchmark/modeling/rpn/retinanet/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/rpn/retinanet\n",
      "copying maskrcnn_benchmark/modeling/rpn/retinanet/loss.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/rpn/retinanet\n",
      "copying maskrcnn_benchmark/modeling/rpn/retinanet/inference.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/rpn/retinanet\n",
      "copying maskrcnn_benchmark/modeling/rpn/retinanet/retinanet.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/rpn/retinanet\n",
      "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads/box_head\n",
      "copying maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_feature_extractors.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads/box_head\n",
      "copying maskrcnn_benchmark/modeling/roi_heads/box_head/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads/box_head\n",
      "copying maskrcnn_benchmark/modeling/roi_heads/box_head/loss.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads/box_head\n",
      "copying maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_predictors.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads/box_head\n",
      "copying maskrcnn_benchmark/modeling/roi_heads/box_head/box_head.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads/box_head\n",
      "copying maskrcnn_benchmark/modeling/roi_heads/box_head/inference.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads/box_head\n",
      "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads/mask_head\n",
      "copying maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_feature_extractors.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads/mask_head\n",
      "copying maskrcnn_benchmark/modeling/roi_heads/mask_head/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads/mask_head\n",
      "copying maskrcnn_benchmark/modeling/roi_heads/mask_head/loss.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads/mask_head\n",
      "copying maskrcnn_benchmark/modeling/roi_heads/mask_head/mask_head.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads/mask_head\n",
      "copying maskrcnn_benchmark/modeling/roi_heads/mask_head/inference.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads/mask_head\n",
      "copying maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_predictors.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads/mask_head\n",
      "creating build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads/keypoint_head\n",
      "copying maskrcnn_benchmark/modeling/roi_heads/keypoint_head/keypoint_head.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads/keypoint_head\n",
      "copying maskrcnn_benchmark/modeling/roi_heads/keypoint_head/__init__.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads/keypoint_head\n",
      "copying maskrcnn_benchmark/modeling/roi_heads/keypoint_head/loss.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads/keypoint_head\n",
      "copying maskrcnn_benchmark/modeling/roi_heads/keypoint_head/roi_keypoint_predictors.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads/keypoint_head\n",
      "copying maskrcnn_benchmark/modeling/roi_heads/keypoint_head/inference.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads/keypoint_head\n",
      "copying maskrcnn_benchmark/modeling/roi_heads/keypoint_head/roi_keypoint_feature_extractors.py -> build/lib.linux-x86_64-3.6/maskrcnn_benchmark/modeling/roi_heads/keypoint_head\n",
      "running build_ext\n",
      "building 'maskrcnn_benchmark._C' extension\n",
      "creating build/temp.linux-x86_64-3.6\n",
      "creating build/temp.linux-x86_64-3.6/content\n",
      "creating build/temp.linux-x86_64-3.6/content/maskrcnn-benchmark\n",
      "creating build/temp.linux-x86_64-3.6/content/maskrcnn-benchmark/maskrcnn_benchmark\n",
      "creating build/temp.linux-x86_64-3.6/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc\n",
      "creating build/temp.linux-x86_64-3.6/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu\n",
      "creating build/temp.linux-x86_64-3.6/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda\n",
      "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c /content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/vision.cpp -o build/temp.linux-x86_64-3.6/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/vision.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c /content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp -o build/temp.linux-x86_64-3.6/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:2\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:\u001b[m\u001b[K In lambda function:\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:71:52:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
      "     at::ScalarType _st = ::detail::scalar_type(TYPE\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                        \\\n",
      "                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.cpp:242:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K’\n",
      "   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K(input.type(), \"ROIAlign_forward\", [&] {\n",
      "   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:47:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      " inline at::ScalarType \u001b[01;36m\u001b[Kscalar_type\u001b[m\u001b[K(const at::DeprecatedTypeProperties &t) {\n",
      "                       \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
      "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c /content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp -o build/temp.linux-x86_64-3.6/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:\u001b[m\u001b[K In lambda function:\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:71:52:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
      "     at::ScalarType _st = ::detail::scalar_type(TYPE\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                        \\\n",
      "                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.cpp:71:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K’\n",
      "   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K(dets.type(), \"nms\", [&] {\n",
      "   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:47:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      " inline at::ScalarType \u001b[01;36m\u001b[Kscalar_type\u001b[m\u001b[K(const at::DeprecatedTypeProperties &t) {\n",
      "                       \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
      "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c /content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/deform_conv_kernel_cuda.cu -o build/temp.linux-x86_64-3.6/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/deform_conv_kernel_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(83): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"lowest\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(84): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"max\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(85): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"lower_bound\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(86): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"upper_bound\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
      "\n",
      "\u001b[01m\u001b[K/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/deform_conv_kernel_cuda.cu:\u001b[m\u001b[K In lambda function:\n",
      "\u001b[01m\u001b[K/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/deform_conv_kernel_cuda.cu:266:124:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
      "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
      "                                                                                                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:47:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
      " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/deform_conv_kernel_cuda.cu:\u001b[m\u001b[K In lambda function:\n",
      "\u001b[01m\u001b[K/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/deform_conv_kernel_cuda.cu:360:126:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
      "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
      "                                                                                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:47:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
      " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/deform_conv_kernel_cuda.cu:\u001b[m\u001b[K In lambda function:\n",
      "\u001b[01m\u001b[K/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/deform_conv_kernel_cuda.cu:458:126:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
      "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
      "                                                                                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:47:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
      " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/deform_conv_kernel_cuda.cu:\u001b[m\u001b[K In lambda function:\n",
      "\u001b[01m\u001b[K/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/deform_conv_kernel_cuda.cu:788:124:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
      "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
      "                                                                                                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:47:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
      " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/deform_conv_kernel_cuda.cu:\u001b[m\u001b[K In lambda function:\n",
      "\u001b[01m\u001b[K/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/deform_conv_kernel_cuda.cu:820:126:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
      "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
      "                                                                                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:47:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
      " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/deform_conv_kernel_cuda.cu:\u001b[m\u001b[K In lambda function:\n",
      "\u001b[01m\u001b[K/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/deform_conv_kernel_cuda.cu:853:126:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
      "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
      "                                                                                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:47:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
      " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
      "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c /content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/nms.cu -o build/temp.linux-x86_64-3.6/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/nms.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c /content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/ROIAlign_cuda.cu -o build/temp.linux-x86_64-3.6/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/ROIAlign_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(83): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"lowest\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(84): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"max\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(85): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"lower_bound\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(86): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"upper_bound\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
      "\n",
      "\u001b[01m\u001b[K/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/ROIAlign_cuda.cu:\u001b[m\u001b[K In lambda function:\n",
      "\u001b[01m\u001b[K/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/ROIAlign_cuda.cu:283:120:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
      "   AT_DISPATCH_FLOATING_TYPES(input.type(), \"ROIAlign_forward\", [&] {\n",
      "                                                                                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:47:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
      " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/ROIAlign_cuda.cu:\u001b[m\u001b[K In lambda function:\n",
      "\u001b[01m\u001b[K/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/ROIAlign_cuda.cu:329:118:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
      "   AT_DISPATCH_FLOATING_TYPES(grad.type(), \"ROIAlign_backward\", [&] {\n",
      "                                                                                                                      \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:47:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
      " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
      "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c /content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/deform_conv_cuda.cu -o build/temp.linux-x86_64-3.6/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/deform_conv_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c /content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/deform_pool_cuda.cu -o build/temp.linux-x86_64-3.6/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/deform_pool_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c /content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/ROIPool_cuda.cu -o build/temp.linux-x86_64-3.6/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/ROIPool_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(83): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"lowest\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(84): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"max\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(85): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"lower_bound\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(86): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"upper_bound\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
      "\n",
      "\u001b[01m\u001b[K/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/ROIPool_cuda.cu:\u001b[m\u001b[K In lambda function:\n",
      "\u001b[01m\u001b[K/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/ROIPool_cuda.cu:137:120:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
      "   AT_DISPATCH_FLOATING_TYPES(input.type(), \"ROIPool_forward\", [&] {\n",
      "                                                                                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:47:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
      " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/ROIPool_cuda.cu:\u001b[m\u001b[K In lambda function:\n",
      "\u001b[01m\u001b[K/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/ROIPool_cuda.cu:185:118:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
      "   AT_DISPATCH_FLOATING_TYPES(grad.type(), \"ROIPool_backward\", [&] {\n",
      "                                                                                                                      \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:47:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
      " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
      "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c /content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/deform_pool_kernel_cuda.cu -o build/temp.linux-x86_64-3.6/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/deform_pool_kernel_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(83): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"lowest\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(84): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"max\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(85): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"lower_bound\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(86): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"upper_bound\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
      "\n",
      "\u001b[01m\u001b[K/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/deform_pool_kernel_cuda.cu:\u001b[m\u001b[K In lambda function:\n",
      "\u001b[01m\u001b[K/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/deform_pool_kernel_cuda.cu:292:118:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
      "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
      "                                                                                                                      \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:47:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
      " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/deform_pool_kernel_cuda.cu:\u001b[m\u001b[K In lambda function:\n",
      "\u001b[01m\u001b[K/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/deform_pool_kernel_cuda.cu:343:126:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
      "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
      "                                                                                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:47:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
      " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
      "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c /content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/SigmoidFocalLoss_cuda.cu -o build/temp.linux-x86_64-3.6/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/SigmoidFocalLoss_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(83): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"lowest\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(84): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"max\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(85): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"lower_bound\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(86): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"upper_bound\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
      "\n",
      "\u001b[01m\u001b[K/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/SigmoidFocalLoss_cuda.cu:\u001b[m\u001b[K In lambda function:\n",
      "\u001b[01m\u001b[K/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/SigmoidFocalLoss_cuda.cu:129:122:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
      "   AT_DISPATCH_FLOATING_TYPES(logits.type(), \"SigmoidFocalLoss_forward\", [&] {\n",
      "                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:47:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
      " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/SigmoidFocalLoss_cuda.cu:\u001b[m\u001b[K In lambda function:\n",
      "\u001b[01m\u001b[K/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/SigmoidFocalLoss_cuda.cu:173:122:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
      "   AT_DISPATCH_FLOATING_TYPES(logits.type(), \"SigmoidFocalLoss_backward\", [&] {\n",
      "                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:47:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
      " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
      "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/vision.o build/temp.linux-x86_64-3.6/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.o build/temp.linux-x86_64-3.6/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cpu/nms_cpu.o build/temp.linux-x86_64-3.6/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/deform_conv_kernel_cuda.o build/temp.linux-x86_64-3.6/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/nms.o build/temp.linux-x86_64-3.6/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/ROIAlign_cuda.o build/temp.linux-x86_64-3.6/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/deform_conv_cuda.o build/temp.linux-x86_64-3.6/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/deform_pool_cuda.o build/temp.linux-x86_64-3.6/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/ROIPool_cuda.o build/temp.linux-x86_64-3.6/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/deform_pool_kernel_cuda.o build/temp.linux-x86_64-3.6/content/maskrcnn-benchmark/maskrcnn_benchmark/csrc/cuda/SigmoidFocalLoss_cuda.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/maskrcnn_benchmark/_C.cpython-36m-x86_64-linux-gnu.so\n",
      "running develop\n",
      "running egg_info\n",
      "creating maskrcnn_benchmark.egg-info\n",
      "writing maskrcnn_benchmark.egg-info/PKG-INFO\n",
      "writing dependency_links to maskrcnn_benchmark.egg-info/dependency_links.txt\n",
      "writing top-level names to maskrcnn_benchmark.egg-info/top_level.txt\n",
      "writing manifest file 'maskrcnn_benchmark.egg-info/SOURCES.txt'\n",
      "writing manifest file 'maskrcnn_benchmark.egg-info/SOURCES.txt'\n",
      "running build_ext\n",
      "copying build/lib.linux-x86_64-3.6/maskrcnn_benchmark/_C.cpython-36m-x86_64-linux-gnu.so -> maskrcnn_benchmark\n",
      "Creating /usr/local/lib/python3.6/dist-packages/maskrcnn-benchmark.egg-link (link to .)\n",
      "Adding maskrcnn-benchmark 0.1 to easy-install.pth file\n",
      "\n",
      "Installed /content/maskrcnn-benchmark\n",
      "Processing dependencies for maskrcnn-benchmark==0.1\n",
      "Finished processing dependencies for maskrcnn-benchmark==0.1\n"
     ]
    }
   ],
   "source": [
    "!sh setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1uoPMGDl49Wk"
   },
   "source": [
    "### Checking our Installation\n",
    "\n",
    "If a `Module not found` error appears, restart the runtime. The libraries should be loaded after restarting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3q-n76S95KA3"
   },
   "outputs": [],
   "source": [
    "import maskrcnn_benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-N9mxq4OX6Yc"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kLzesfGNX9O2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Set up custom environment before nearly anything else is imported\n",
    "# NOTE: this should be the first import (no not reorder)\n",
    "from maskrcnn_benchmark.utils.env import setup_environment  # noqa F401 isort:skip\n",
    "\n",
    "from maskrcnn_benchmark.data.build import *\n",
    "from maskrcnn_benchmark.structures.bounding_box import BoxList\n",
    "from maskrcnn_benchmark.structures.segmentation_mask import SegmentationMask\n",
    "from maskrcnn_benchmark.modeling.detector import build_detection_model\n",
    "from maskrcnn_benchmark.utils.checkpoint import DetectronCheckpointer\n",
    "from maskrcnn_benchmark.structures.image_list import to_image_list\n",
    "from maskrcnn_benchmark.modeling.roi_heads.mask_head.inference import Masker\n",
    "from maskrcnn_benchmark import layers as L\n",
    "from maskrcnn_benchmark.utils import cv2_util\n",
    "from maskrcnn_benchmark.utils.miscellaneous import mkdir\n",
    "from maskrcnn_benchmark.utils.logger import setup_logger\n",
    "from maskrcnn_benchmark.utils.comm import synchronize, get_rank\n",
    "from maskrcnn_benchmark.config import cfg\n",
    "from maskrcnn_benchmark.config import cfg\n",
    "from maskrcnn_benchmark.data import make_data_loader\n",
    "from maskrcnn_benchmark.solver import make_lr_scheduler\n",
    "from maskrcnn_benchmark.solver import make_optimizer\n",
    "from maskrcnn_benchmark.engine.inference import inference\n",
    "from maskrcnn_benchmark.engine.trainer import do_train\n",
    "from maskrcnn_benchmark.modeling.detector import build_detection_model\n",
    "from maskrcnn_benchmark.utils.checkpoint import DetectronCheckpointer\n",
    "from maskrcnn_benchmark.utils.collect_env import collect_env_info\n",
    "from maskrcnn_benchmark.utils.comm import synchronize, get_rank\n",
    "from maskrcnn_benchmark.utils.imports import import_file\n",
    "from maskrcnn_benchmark.data.datasets.evaluation import evaluate\n",
    "from maskrcnn_benchmark.utils.comm import is_main_process, get_world_size\n",
    "from maskrcnn_benchmark.utils.comm import all_gather\n",
    "from maskrcnn_benchmark.utils.timer import Timer, get_time_str\n",
    "from maskrcnn_benchmark.engine.inference import compute_on_dataset, _accumulate_predictions_from_multiple_gpus\n",
    "from maskrcnn_benchmark.data.datasets.evaluation.coco import coco_evaluation\n",
    "\n",
    "from PIL import Image\n",
    "import json\n",
    "import logging\n",
    "import torch\n",
    "import numpy as np\n",
    "import skimage.draw as draw\n",
    "import tempfile\n",
    "from pycocotools.coco import COCO\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.\n",
    "from torchvision import transforms as T\n",
    "from torchvision.transforms import functional as F\n",
    "from skimage.io import imshow as cv2_imshow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DvU-NYKJ3uzb"
   },
   "source": [
    "# Loading Our Dataset\n",
    "\n",
    "To train a network using the `facebookresearch/maskrcnn-benchmark` repo, we first need to define our dataset. The dataset needs to be a subclass of `object` and should implement 6 things. \n",
    "\n",
    "1. `__getitem__(self, idx)`: This function should return a PIL Image, a BoxList and the idx. The Boxlist is an abstraction for our bounding boxes, segmentation masks, class labels and also people keypoints. Please check [ABSTRACTIONS.md](https://github.com/facebookresearch/maskrcnn-benchmark/blob/master/ABSTRACTIONS.md) for more details on this. \n",
    "\n",
    "2. `__len__()`: returns the length of the dataset. \n",
    "\n",
    "3. `get_img_info(self, idx)`: Return a dict of img info with the fields \"height\" and \"width\" filled in with the idx's image's height and width.\n",
    "\n",
    "4. `self.coco`: Should be a variable that holds the COCO object for your annotations so that you can perform evaluations of your dataset. \n",
    "\n",
    "5. `self.id_to_img_map`: Is a dictionary that maps the ids to coco image ids. Almost in all cases just map the idxs to idxs. This is simply a requirement for the coco evaluation. \n",
    "\n",
    "6. `self.contiguous_category_id_to_json_id`: Another requirement for coco evaluation. It maps the categpry to json category id. Again, for almost all purposes category id and json id should be same. \n",
    "\n",
    "Given below is a sample fo a dataset. It is the Shape Dataset taken from the [Matterport/Mask_RCNN](https://github.com/matterport/Mask_RCNN) Repo. One important detail is that the constructor of the dataset should have the variable `transforms`, which is set inside the constructor. It should then be used in `__getitem__(self, idx)` as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xnr8tbDz7WjS"
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tb_5MERf7c_1"
   },
   "outputs": [],
   "source": [
    "# Helper Functions for the Shapes Dataset\n",
    "\n",
    "def non_max_suppression(boxes, scores, threshold):\n",
    "    \"\"\"Performs non-maximum suppression and returns indices of kept boxes.\n",
    "    boxes: [N, (y1, x1, y2, x2)]. Notice that (y2, x2) lays outside the box.\n",
    "    scores: 1-D array of box scores.\n",
    "    threshold: Float. IoU threshold to use for filtering.\n",
    "    \"\"\"\n",
    "    assert boxes.shape[0] > 0\n",
    "    if boxes.dtype.kind != \"f\":\n",
    "        boxes = boxes.astype(np.float32)\n",
    "\n",
    "    # Compute box areas\n",
    "    y1 = boxes[:, 0]\n",
    "    x1 = boxes[:, 1]\n",
    "    y2 = boxes[:, 2]\n",
    "    x2 = boxes[:, 3]\n",
    "    area = (y2 - y1) * (x2 - x1)\n",
    "\n",
    "    # Get indicies of boxes sorted by scores (highest first)\n",
    "    ixs = scores.argsort()[::-1]\n",
    "\n",
    "    pick = []\n",
    "    while len(ixs) > 0:\n",
    "        # Pick top box and add its index to the list\n",
    "        i = ixs[0]\n",
    "        pick.append(i)\n",
    "        # Compute IoU of the picked box with the rest\n",
    "        iou = compute_iou(boxes[i], boxes[ixs[1:]], area[i], area[ixs[1:]])\n",
    "        # Identify boxes with IoU over the threshold. This\n",
    "        # returns indices into ixs[1:], so add 1 to get\n",
    "        # indices into ixs.\n",
    "        remove_ixs = np.where(iou > threshold)[0] + 1\n",
    "        # Remove indices of the picked and overlapped boxes.\n",
    "        ixs = np.delete(ixs, remove_ixs)\n",
    "        ixs = np.delete(ixs, 0)\n",
    "    return np.array(pick, dtype=np.int32)\n",
    "\n",
    "def compute_iou(box, boxes, box_area, boxes_area):\n",
    "    \"\"\"Calculates IoU of the given box with the array of the given boxes.\n",
    "    box: 1D vector [y1, x1, y2, x2]\n",
    "    boxes: [boxes_count, (y1, x1, y2, x2)]\n",
    "    box_area: float. the area of 'box'\n",
    "    boxes_area: array of length boxes_count.\n",
    "    Note: the areas are passed in rather than calculated here for\n",
    "    efficiency. Calculate once in the caller to avoid duplicate work.\n",
    "    \"\"\"\n",
    "    # Calculate intersection areas\n",
    "    y1 = np.maximum(box[0], boxes[:, 0])\n",
    "    y2 = np.minimum(box[2], boxes[:, 2])\n",
    "    x1 = np.maximum(box[1], boxes[:, 1])\n",
    "    x2 = np.minimum(box[3], boxes[:, 3])\n",
    "    intersection = np.maximum(x2 - x1, 0) * np.maximum(y2 - y1, 0)\n",
    "    union = box_area + boxes_area[:] - intersection[:]\n",
    "    iou = intersection / union\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5DC0K7tW7d-M"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WhG_Tu9ELAsj"
   },
   "outputs": [],
   "source": [
    "class ShapeDataset(object):\n",
    "  \n",
    "  def __init__(self, num_examples, transforms=None):\n",
    "    \n",
    "    self.height = 128\n",
    "    self.width = 128\n",
    "    \n",
    "    self.num_examples = num_examples\n",
    "    self.transforms = transforms # IMPORTANT, DON'T MISS\n",
    "    self.image_info = []\n",
    "    self.logger = logging.getLogger(__name__)\n",
    "    \n",
    "    # Class Names: Note that the ids start from 1, not 0. This repo uses the index 0 for background\n",
    "    self.class_names = {\"square\": 1, \"circle\": 2, \"triangle\": 3}\n",
    "    \n",
    "    # Add images\n",
    "    # Generate random specifications of images (i.e. color and\n",
    "    # list of shapes sizes and locations). This is more compact than\n",
    "    # actual images. Images are generated on the fly in load_image().\n",
    "    for i in range(num_examples):\n",
    "        bg_color, shapes = self.random_image(self.height, self.width)\n",
    "        self.image_info.append({ \"path\":None,\n",
    "                       \"width\": self.width, \"height\": self.height,\n",
    "                       \"bg_color\": bg_color, \"shapes\": shapes\n",
    "                       })\n",
    "    \n",
    "    # Fills in the self.coco varibale for evaluation.\n",
    "    self.get_gt()\n",
    "    \n",
    "    # Variables needed for coco mAP evaluation\n",
    "    self.id_to_img_map = {}\n",
    "    for i, _ in enumerate(self.image_info):\n",
    "      self.id_to_img_map[i] = i\n",
    "\n",
    "    self.contiguous_category_id_to_json_id = { 0:0 ,1:1, 2:2, 3:3 }\n",
    "    \n",
    "\n",
    "  def random_shape(self, height, width):\n",
    "    \"\"\"Generates specifications of a random shape that lies within\n",
    "    the given height and width boundaries.\n",
    "    Returns a tuple of three values:\n",
    "    * The shape name (square, circle, ...)\n",
    "    * Shape color: a tuple of 3 values, RGB.\n",
    "    * Shape dimensions: A tuple of values that define the shape size\n",
    "                        and location. Differs per shape type.\n",
    "    \"\"\"\n",
    "    # Shape\n",
    "    shape = random.choice([\"square\", \"circle\", \"triangle\"])\n",
    "    # Color\n",
    "    color = tuple([random.randint(0, 255) for _ in range(3)])\n",
    "    # Center x, y\n",
    "    buffer = 20\n",
    "    y = random.randint(buffer, height - buffer - 1)\n",
    "    x = random.randint(buffer, width - buffer - 1)\n",
    "    # Size\n",
    "    s = random.randint(buffer, height//4)\n",
    "    return shape, color, (x, y, s)\n",
    "\n",
    "  def random_image(self, height, width):\n",
    "      \"\"\"Creates random specifications of an image with multiple shapes.\n",
    "      Returns the background color of the image and a list of shape\n",
    "      specifications that can be used to draw the image.\n",
    "      \"\"\"\n",
    "      # Pick random background color\n",
    "      bg_color = np.array([random.randint(0, 255) for _ in range(3)])\n",
    "      # Generate a few random shapes and record their\n",
    "      # bounding boxes\n",
    "      shapes = []\n",
    "      boxes = []\n",
    "      N = random.randint(1, 4)\n",
    "      labels = {}\n",
    "      for _ in range(N):\n",
    "          shape, color, dims = self.random_shape(height, width)\n",
    "          shapes.append((shape, color, dims))\n",
    "          x, y, s = dims\n",
    "          boxes.append([y-s, x-s, y+s, x+s])\n",
    "\n",
    "      # Apply non-max suppression with 0.3 threshold to avoid\n",
    "      # shapes covering each other\n",
    "      keep_ixs = non_max_suppression(np.array(boxes), np.arange(N), 0.3)\n",
    "      shapes = [s for i, s in enumerate(shapes) if i in keep_ixs]\n",
    "      \n",
    "      return bg_color, shapes\n",
    "  \n",
    "  \n",
    "  def draw_shape(self, image, shape, dims, color):\n",
    "      \"\"\"Draws a shape from the given specs.\"\"\"\n",
    "      # Get the center x, y and the size s\n",
    "      x, y, s = dims\n",
    "      if shape == 'square':\n",
    "          cv2.rectangle(image, (x-s, y-s), (x+s, y+s), color, -1)\n",
    "      elif shape == \"circle\":\n",
    "          cv2.circle(image, (x, y), s, color, -1)\n",
    "      elif shape == \"triangle\":\n",
    "          points = np.array([[(x, y-s),\n",
    "                              (x-s/math.sin(math.radians(60)), y+s),\n",
    "                              (x+s/math.sin(math.radians(60)), y+s),\n",
    "                              ]], dtype=np.int32)\n",
    "          cv2.fillPoly(image, points, color)\n",
    "      return image, [ x-s, y-s, x+s, y+s]\n",
    "\n",
    "\n",
    "  def load_mask(self, image_id):\n",
    "    \"\"\"\n",
    "    Generates instance masks for shapes of the given image ID.\n",
    "    \"\"\"\n",
    "    info = self.image_info[image_id]\n",
    "    shapes = info['shapes']\n",
    "    count = len(shapes)\n",
    "    mask = np.zeros([info['height'], info['width'], count], dtype=np.uint8)\n",
    "    \n",
    "    boxes = []\n",
    "    \n",
    "    for i, (shape, _, dims) in enumerate(info['shapes']):\n",
    "        mask[:, :, i:i+1], box = self.draw_shape(mask[:, :, i:i+1].copy(),\n",
    "                                            shape, dims, 1)\n",
    "        boxes.append(box)\n",
    "        \n",
    "    # Handle occlusions\n",
    "    occlusion = np.logical_not(mask[:, :, -1]).astype(np.uint8)\n",
    "    for i in range(count-2, -1, -1):\n",
    "        mask[:, :, i] = mask[:, :, i] * occlusion\n",
    "        occlusion = np.logical_and(occlusion, np.logical_not(mask[:, :, i]))\n",
    "    # Map class names to class IDs.\n",
    "    class_ids = np.array([self.class_names[s[0]] for s in shapes])\n",
    "    return mask.astype(np.uint8), class_ids.astype(np.int32), boxes\n",
    "  \n",
    "  def load_image(self, image_id):\n",
    "    \"\"\"Generate an image from the specs of the given image ID.\n",
    "    Typically this function loads the image from a file, but\n",
    "    in this case it generates the image on the fly from the\n",
    "    specs in image_info.\n",
    "    \"\"\"\n",
    "    info = self.image_info[image_id]\n",
    "    bg_color = np.array(info['bg_color']).reshape([1, 1, 3])\n",
    "    image = np.ones([info['height'], info['width'], 3], dtype=np.uint8)\n",
    "    image = image * bg_color.astype(np.uint8)\n",
    "    for shape, color, dims in info['shapes']:\n",
    "        image, _ = self.draw_shape(image, shape, dims, color)\n",
    "    return image\n",
    "      \n",
    "  def __getitem__(self, idx):\n",
    "    \n",
    "    \"\"\"Generate an image from the specs of the given image ID.\n",
    "    Typically this function loads the image from a file, but\n",
    "    in this case it generates the image on the fly from the\n",
    "    specs in image_info.\n",
    "    \"\"\"\n",
    "    image = Image.fromarray(self.load_image(idx))\n",
    "    masks, labels, boxes = self.load_mask(idx)\n",
    "    \n",
    "    # create a BoxList from the boxes\n",
    "    boxlist = BoxList(boxes, image.size, mode=\"xyxy\")\n",
    "\n",
    "    # add the labels to the boxlist\n",
    "    boxlist.add_field(\"labels\", torch.tensor(labels))\n",
    "\n",
    "    # Add masks to the boxlist\n",
    "    masks = np.transpose(masks, (2,0,1))\n",
    "    masks = SegmentationMask(torch.tensor(masks), image.size, \"mask\")\n",
    "    boxlist.add_field(\"masks\", masks)\n",
    "    \n",
    "    # Important line! don't forget to add this\n",
    "    if self.transforms:\n",
    "        image, boxlist = self.transforms(image, boxlist)\n",
    "\n",
    "    # return the image, the boxlist and the idx in your dataset\n",
    "    return image, boxlist, idx\n",
    "  \n",
    "  \n",
    "  def __len__(self):\n",
    "      return self.num_examples\n",
    "    \n",
    "\n",
    "  def get_img_info(self, idx):\n",
    "      # get img_height and img_width. This is used if\n",
    "      # we want to split the batches according to the aspect ratio\n",
    "      # of the image, as it can be more efficient than loading the\n",
    "      # image from disk\n",
    "\n",
    "      return {\"height\": self.height, \"width\": self.width}\n",
    "    \n",
    "  def get_gt(self):\n",
    "      # Prepares dataset for coco eval\n",
    "      \n",
    "      \n",
    "      images = []\n",
    "      annotations = []\n",
    "      results = []\n",
    "      \n",
    "      # Define categories\n",
    "      categories = [ {\"id\": 1, \"name\": \"square\"}, {\"id\": 2, \"name\": \"circle\"}, {\"id\": 3, \"name\": \"triangle\"}]\n",
    "\n",
    "\n",
    "      i = 1\n",
    "      ann_id = 0\n",
    "\n",
    "      for img_id, d in enumerate(self.image_info):\n",
    "\n",
    "        images.append( {\"id\": img_id, 'height': self.height, 'width': self.width } )\n",
    "\n",
    "        for (shape, color, dims) in d['shapes']:\n",
    "          \n",
    "          if shape == \"square\":\n",
    "            category_id = 1\n",
    "          elif shape == \"circle\":\n",
    "            category_id = 2\n",
    "          elif shape == \"triangle\":\n",
    "            category_id = 3\n",
    "          \n",
    "          x, y, s = dims\n",
    "          bbox = [ x - s, y - s, x+s, y +s ] \n",
    "          area = (bbox[0] - bbox[2]) * (bbox[1] - bbox[3])\n",
    "          \n",
    "          # Format for COCO\n",
    "          annotations.append( {\n",
    "              \"id\": int(ann_id),\n",
    "              \"category_id\": category_id,\n",
    "              \"image_id\": int(img_id),\n",
    "              \"area\" : float(area),\n",
    "              \"bbox\": [ float(bbox[0]), float(bbox[1]), float(bbox[2]) - float(bbox[0]) + 1, float(bbox[3]) - float(bbox[1]) + 1 ], # note that the bboxes are in x, y , width, height format\n",
    "              \"iscrowd\" : 0\n",
    "          } )\n",
    "\n",
    "          ann_id += 1\n",
    "\n",
    "      # Save ground truth file\n",
    "      \n",
    "      with open(\"tmp_gt.json\", \"w\") as f:\n",
    "        json.dump({\"images\": images, \"annotations\": annotations, \"categories\": categories }, f)\n",
    "\n",
    "      # Load gt for coco eval\n",
    "      self.coco = COCO(\"tmp_gt.json\") \n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2hpTvuSp830x"
   },
   "source": [
    "## Visualise Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BI2ncK7kATEh"
   },
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "6nsO_MRUbBpk",
    "outputId": "db8c6102-8663-4bb5-e9e9-c9f305f014f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "(128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "train_dt = ShapeDataset(100)\n",
    "im, boxlist, idx = train_dt[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F9njOSX0AU5-"
   },
   "source": [
    "### Display some sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "colab_type": "code",
    "id": "nMXB9sAW994F",
    "outputId": "6de8c71d-c656-42a0-eeb0-24982fcad9de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 3)\n",
      "(128, 128, 2)\n",
      "(128, 128, 3)\n",
      "(128, 128, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rows = 2\n",
    "cols = 2\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "for i in range(1, rows*cols+1):\n",
    "  im, boxlist, idx = train_dt[i+5]\n",
    "  fig.add_subplot(rows, cols, i)\n",
    "  plt.imshow(im)\n",
    "plt.show()\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ORQXaa6k30yD"
   },
   "source": [
    "# Training a Model\n",
    "\n",
    "Now we move on to training our very own model. Here we will be fine-tuning a Mask RCNN on this dataset. To do this we need\n",
    "\n",
    "1. A base model that has the same amount of output classes as our dataset. In this case, we have need for only 3 classes instead of COCO's 80. Hence , we first need to do some model trimming. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SVaNqbpiAzwx"
   },
   "source": [
    "## Model Trimming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hbzY16ocEdrg"
   },
   "source": [
    "### Helper Functions for Visualising Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yk5a6RpsEdIt"
   },
   "outputs": [],
   "source": [
    "class Resize(object):\n",
    "    def __init__(self, min_size, max_size):\n",
    "        self.min_size = min_size\n",
    "        self.max_size = max_size\n",
    "\n",
    "    # modified from torchvision to add support for max size\n",
    "    def get_size(self, image_size):\n",
    "        w, h = image_size\n",
    "        size = self.min_size\n",
    "        max_size = self.max_size\n",
    "        if max_size is not None:\n",
    "            min_original_size = float(min((w, h)))\n",
    "            max_original_size = float(max((w, h)))\n",
    "            if max_original_size / min_original_size * size > max_size:\n",
    "                size = int(round(max_size * min_original_size / max_original_size))\n",
    "\n",
    "        if (w <= h and w == size) or (h <= w and h == size):\n",
    "            return (h, w)\n",
    "\n",
    "        if w < h:\n",
    "            ow = size\n",
    "            oh = int(size * h / w)\n",
    "        else:\n",
    "            oh = size\n",
    "            ow = int(size * w / h)\n",
    "\n",
    "        return (oh, ow)\n",
    "\n",
    "    def __call__(self, image):\n",
    "        size = self.get_size(image.size)\n",
    "        image = F.resize(image, size)\n",
    "        return image\n",
    "      \n",
    "      \n",
    "class COCODemo(object):\n",
    "  \n",
    "    def __init__(\n",
    "        self,\n",
    "        cfg,\n",
    "        confidence_threshold=0.7,\n",
    "        show_mask_heatmaps=False,\n",
    "        masks_per_dim=2,\n",
    "        min_image_size=224,\n",
    "    ):\n",
    "        self.cfg = cfg.clone()\n",
    "        self.model = build_detection_model(cfg)\n",
    "        self.model.eval()\n",
    "        self.device = torch.device(cfg.MODEL.DEVICE)\n",
    "        self.model.to(self.device)\n",
    "        self.min_image_size = min_image_size\n",
    "\n",
    "        save_dir = cfg.OUTPUT_DIR\n",
    "        checkpointer = DetectronCheckpointer(cfg, self.model, save_dir=save_dir)\n",
    "        _ = checkpointer.load(cfg.MODEL.WEIGHT)\n",
    "\n",
    "        self.transforms = self.build_transform()\n",
    "\n",
    "        mask_threshold = -1 if show_mask_heatmaps else 0.5\n",
    "        self.masker = Masker(threshold=mask_threshold, padding=1)\n",
    "\n",
    "        # used to make colors for each class\n",
    "        self.palette = torch.tensor([2 ** 25 - 1, 2 ** 15 - 1, 2 ** 21 - 1])\n",
    "\n",
    "        self.cpu_device = torch.device(\"cpu\")\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        self.show_mask_heatmaps = show_mask_heatmaps\n",
    "        self.masks_per_dim = masks_per_dim\n",
    "\n",
    "    def build_transform(self):\n",
    "        \"\"\"\n",
    "        Creates a basic transformation that was used to train the models\n",
    "        \"\"\"\n",
    "        cfg = self.cfg\n",
    "\n",
    "        # we are loading images with OpenCV, so we don't need to convert them\n",
    "        # to BGR, they are already! So all we need to do is to normalize\n",
    "        # by 255 if we want to convert to BGR255 format, or flip the channels\n",
    "        # if we want it to be in RGB in [0-1] range.\n",
    "        if cfg.INPUT.TO_BGR255:\n",
    "            to_bgr_transform = T.Lambda(lambda x: x * 255)\n",
    "        else:\n",
    "            to_bgr_transform = T.Lambda(lambda x: x[[2, 1, 0]])\n",
    "\n",
    "        normalize_transform = T.Normalize(\n",
    "            mean=cfg.INPUT.PIXEL_MEAN, std=cfg.INPUT.PIXEL_STD\n",
    "        )\n",
    "        min_size = cfg.INPUT.MIN_SIZE_TEST\n",
    "        max_size = cfg.INPUT.MAX_SIZE_TEST\n",
    "        transform = T.Compose(\n",
    "            [\n",
    "                T.ToPILImage(),\n",
    "                Resize(min_size, max_size),\n",
    "                T.ToTensor(),\n",
    "                to_bgr_transform,\n",
    "                normalize_transform,\n",
    "            ]\n",
    "        )\n",
    "        return transform\n",
    "\n",
    "    def run_on_opencv_image(self, image):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            image (np.ndarray): an image as returned by OpenCV\n",
    "        Returns:\n",
    "            prediction (BoxList): the detected objects. Additional information\n",
    "                of the detection properties can be found in the fields of\n",
    "                the BoxList via `prediction.fields()`\n",
    "        \"\"\"\n",
    "        predictions = self.compute_prediction(image)\n",
    "        top_predictions = self.select_top_predictions(predictions)\n",
    "\n",
    "        result = image.copy()\n",
    "        if self.show_mask_heatmaps:\n",
    "            return self.create_mask_montage(result, top_predictions)\n",
    "        result = self.overlay_boxes(result, top_predictions)\n",
    "        if self.cfg.MODEL.MASK_ON:\n",
    "            result = self.overlay_mask(result, top_predictions)\n",
    "        if self.cfg.MODEL.KEYPOINT_ON:\n",
    "            result = self.overlay_keypoints(result, top_predictions)\n",
    "        result = self.overlay_class_names(result, top_predictions)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def compute_prediction(self, original_image):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            original_image (np.ndarray): an image as returned by OpenCV\n",
    "        Returns:\n",
    "            prediction (BoxList): the detected objects. Additional information\n",
    "                of the detection properties can be found in the fields of\n",
    "                the BoxList via `prediction.fields()`\n",
    "        \"\"\"\n",
    "        # apply pre-processing to image\n",
    "        image = self.transforms(original_image)\n",
    "        # convert to an ImageList, padded so that it is divisible by\n",
    "        # cfg.DATALOADER.SIZE_DIVISIBILITY\n",
    "        image_list = to_image_list(image, self.cfg.DATALOADER.SIZE_DIVISIBILITY)\n",
    "        image_list = image_list.to(self.device)\n",
    "        # compute predictions\n",
    "        with torch.no_grad():\n",
    "            predictions = self.model(image_list)\n",
    "        predictions = [o.to(self.cpu_device) for o in predictions]\n",
    "\n",
    "        # always single image is passed at a time\n",
    "        prediction = predictions[0]\n",
    "\n",
    "        # reshape prediction (a BoxList) into the original image size\n",
    "        height, width = original_image.shape[:-1]\n",
    "        prediction = prediction.resize((width, height))\n",
    "\n",
    "        if prediction.has_field(\"mask\"):\n",
    "            # if we have masks, paste the masks in the right position\n",
    "            # in the image, as defined by the bounding boxes\n",
    "            masks = prediction.get_field(\"mask\")\n",
    "            # always single image is passed at a time\n",
    "            masks = self.masker([masks], [prediction])[0]\n",
    "            prediction.add_field(\"mask\", masks)\n",
    "        return prediction\n",
    "\n",
    "    def select_top_predictions(self, predictions):\n",
    "        \"\"\"\n",
    "        Select only predictions which have a `score` > self.confidence_threshold,\n",
    "        and returns the predictions in descending order of score\n",
    "        Arguments:\n",
    "            predictions (BoxList): the result of the computation by the model.\n",
    "                It should contain the field `scores`.\n",
    "        Returns:\n",
    "            prediction (BoxList): the detected objects. Additional information\n",
    "                of the detection properties can be found in the fields of\n",
    "                the BoxList via `prediction.fields()`\n",
    "        \"\"\"\n",
    "        scores = predictions.get_field(\"scores\")\n",
    "        keep = torch.nonzero(scores > self.confidence_threshold).squeeze(1)\n",
    "        predictions = predictions[keep]\n",
    "        scores = predictions.get_field(\"scores\")\n",
    "        _, idx = scores.sort(0, descending=True)\n",
    "        return predictions[idx]\n",
    "\n",
    "    def compute_colors_for_labels(self, labels):\n",
    "        \"\"\"\n",
    "        Simple function that adds fixed colors depending on the class\n",
    "        \"\"\"\n",
    "        colors = labels[:, None] * self.palette\n",
    "        colors = (colors % 255).numpy().astype(\"uint8\")\n",
    "        return colors\n",
    "\n",
    "    def overlay_boxes(self, image, predictions):\n",
    "        \"\"\"\n",
    "        Adds the predicted boxes on top of the image\n",
    "        Arguments:\n",
    "            image (np.ndarray): an image as returned by OpenCV\n",
    "            predictions (BoxList): the result of the computation by the model.\n",
    "                It should contain the field `labels`.\n",
    "        \"\"\"\n",
    "        labels = predictions.get_field(\"labels\")\n",
    "        boxes = predictions.bbox\n",
    "\n",
    "        colors = self.compute_colors_for_labels(labels).tolist()\n",
    "\n",
    "        for box, color in zip(boxes, colors):\n",
    "            box = box.to(torch.int64)\n",
    "            top_left, bottom_right = box[:2].tolist(), box[2:].tolist()\n",
    "            image = cv2.rectangle(\n",
    "                image, tuple(top_left), tuple(bottom_right), tuple(color), 1\n",
    "            )\n",
    "\n",
    "        return image\n",
    "\n",
    "    def overlay_mask(self, image, predictions):\n",
    "        \"\"\"\n",
    "        Adds the instances contours for each predicted object.\n",
    "        Each label has a different color.\n",
    "        Arguments:\n",
    "            image (np.ndarray): an image as returned by OpenCV\n",
    "            predictions (BoxList): the result of the computation by the model.\n",
    "                It should contain the field `mask` and `labels`.\n",
    "        \"\"\"\n",
    "        masks = predictions.get_field(\"mask\").numpy()\n",
    "        labels = predictions.get_field(\"labels\")\n",
    "\n",
    "        colors = self.compute_colors_for_labels(labels).tolist()\n",
    "\n",
    "        for mask, color in zip(masks, colors):\n",
    "            thresh = mask[0, :, :, None]\n",
    "            contours, hierarchy = cv2_util.findContours(\n",
    "                thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE\n",
    "            )\n",
    "            image = cv2.drawContours(image, contours, -1, color, 3)\n",
    "\n",
    "        composite = image\n",
    "\n",
    "        return composite\n",
    "\n",
    "    def overlay_keypoints(self, image, predictions):\n",
    "        keypoints = predictions.get_field(\"keypoints\")\n",
    "        kps = keypoints.keypoints\n",
    "        scores = keypoints.get_field(\"logits\")\n",
    "        kps = torch.cat((kps[:, :, 0:2], scores[:, :, None]), dim=2).numpy()\n",
    "        for region in kps:\n",
    "            image = vis_keypoints(image, region.transpose((1, 0)))\n",
    "        return image\n",
    "\n",
    "    def create_mask_montage(self, image, predictions):\n",
    "        \"\"\"\n",
    "        Create a montage showing the probability heatmaps for each one one of the\n",
    "        detected objects\n",
    "        Arguments:\n",
    "            image (np.ndarray): an image as returned by OpenCV\n",
    "            predictions (BoxList): the result of the computation by the model.\n",
    "                It should contain the field `mask`.\n",
    "        \"\"\"\n",
    "        masks = predictions.get_field(\"mask\")\n",
    "        masks_per_dim = self.masks_per_dim\n",
    "        masks = L.interpolate(\n",
    "            masks.float(), scale_factor=1 / masks_per_dim\n",
    "        ).byte()\n",
    "        height, width = masks.shape[-2:]\n",
    "        max_masks = masks_per_dim ** 2\n",
    "        masks = masks[:max_masks]\n",
    "        # handle case where we have less detections than max_masks\n",
    "        if len(masks) < max_masks:\n",
    "            masks_padded = torch.zeros(max_masks, 1, height, width, dtype=torch.uint8)\n",
    "            masks_padded[: len(masks)] = masks\n",
    "            masks = masks_padded\n",
    "        masks = masks.reshape(masks_per_dim, masks_per_dim, height, width)\n",
    "        result = torch.zeros(\n",
    "            (masks_per_dim * height, masks_per_dim * width), dtype=torch.uint8\n",
    "        )\n",
    "        for y in range(masks_per_dim):\n",
    "            start_y = y * height\n",
    "            end_y = (y + 1) * height\n",
    "            for x in range(masks_per_dim):\n",
    "                start_x = x * width\n",
    "                end_x = (x + 1) * width\n",
    "                result[start_y:end_y, start_x:end_x] = masks[y, x]\n",
    "        return cv2.applyColorMap(result.numpy(), cv2.COLORMAP_JET)\n",
    "\n",
    "    def overlay_class_names(self, image, predictions):\n",
    "        \"\"\"\n",
    "        Adds detected class names and scores in the positions defined by the\n",
    "        top-left corner of the predicted bounding box\n",
    "        Arguments:\n",
    "            image (np.ndarray): an image as returned by OpenCV\n",
    "            predictions (BoxList): the result of the computation by the model.\n",
    "                It should contain the field `scores` and `labels`.\n",
    "        \"\"\"\n",
    "        scores = predictions.get_field(\"scores\").tolist()\n",
    "        labels = predictions.get_field(\"labels\").tolist()\n",
    "        labels = [self.CATEGORIES[i] for i in labels]\n",
    "        boxes = predictions.bbox\n",
    "\n",
    "        template = \"{}: {:.2f}\"\n",
    "        for box, score, label in zip(boxes, scores, labels):\n",
    "            x, y = box[:2]\n",
    "            s = template.format(label, score)\n",
    "            cv2.putText(\n",
    "                image, s, (x, y), cv2.FONT_HERSHEY_SIMPLEX, .5, (255, 255, 255), 1\n",
    "            )\n",
    "\n",
    "        return image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from maskrcnn_benchmark.structures.keypoint import PersonKeypoints\n",
    "\n",
    "def vis_keypoints(img, kps, kp_thresh=2, alpha=0.7):\n",
    "    \"\"\"Visualizes keypoints (adapted from vis_one_image).\n",
    "    kps has shape (4, #keypoints) where 4 rows are (x, y, logit, prob).\n",
    "    \"\"\"\n",
    "    dataset_keypoints = PersonKeypoints.NAMES\n",
    "    kp_lines = PersonKeypoints.CONNECTIONS\n",
    "\n",
    "    # Convert from plt 0-1 RGBA colors to 0-255 BGR colors for opencv.\n",
    "    cmap = plt.get_cmap('rainbow')\n",
    "    colors = [cmap(i) for i in np.linspace(0, 1, len(kp_lines) + 2)]\n",
    "    colors = [(c[2] * 255, c[1] * 255, c[0] * 255) for c in colors]\n",
    "\n",
    "    # Perform the drawing on a copy of the image, to allow for blending.\n",
    "    kp_mask = np.copy(img)\n",
    "\n",
    "    # Draw mid shoulder / mid hip first for better visualization.\n",
    "    mid_shoulder = (\n",
    "        kps[:2, dataset_keypoints.index('right_shoulder')] +\n",
    "        kps[:2, dataset_keypoints.index('left_shoulder')]) / 2.0\n",
    "    sc_mid_shoulder = np.minimum(\n",
    "        kps[2, dataset_keypoints.index('right_shoulder')],\n",
    "        kps[2, dataset_keypoints.index('left_shoulder')])\n",
    "    mid_hip = (\n",
    "        kps[:2, dataset_keypoints.index('right_hip')] +\n",
    "        kps[:2, dataset_keypoints.index('left_hip')]) / 2.0\n",
    "    sc_mid_hip = np.minimum(\n",
    "        kps[2, dataset_keypoints.index('right_hip')],\n",
    "        kps[2, dataset_keypoints.index('left_hip')])\n",
    "    nose_idx = dataset_keypoints.index('nose')\n",
    "    if sc_mid_shoulder > kp_thresh and kps[2, nose_idx] > kp_thresh:\n",
    "        cv2.line(\n",
    "            kp_mask, tuple(mid_shoulder), tuple(kps[:2, nose_idx]),\n",
    "            color=colors[len(kp_lines)], thickness=2, lineType=cv2.LINE_AA)\n",
    "    if sc_mid_shoulder > kp_thresh and sc_mid_hip > kp_thresh:\n",
    "        cv2.line(\n",
    "            kp_mask, tuple(mid_shoulder), tuple(mid_hip),\n",
    "            color=colors[len(kp_lines) + 1], thickness=2, lineType=cv2.LINE_AA)\n",
    "\n",
    "    # Draw the keypoints.\n",
    "    for l in range(len(kp_lines)):\n",
    "        i1 = kp_lines[l][0]\n",
    "        i2 = kp_lines[l][1]\n",
    "        p1 = kps[0, i1], kps[1, i1]\n",
    "        p2 = kps[0, i2], kps[1, i2]\n",
    "        if kps[2, i1] > kp_thresh and kps[2, i2] > kp_thresh:\n",
    "            cv2.line(\n",
    "                kp_mask, p1, p2,\n",
    "                color=colors[l], thickness=2, lineType=cv2.LINE_AA)\n",
    "        if kps[2, i1] > kp_thresh:\n",
    "            cv2.circle(\n",
    "                kp_mask, p1,\n",
    "                radius=3, color=colors[l], thickness=-1, lineType=cv2.LINE_AA)\n",
    "        if kps[2, i2] > kp_thresh:\n",
    "            cv2.circle(\n",
    "                kp_mask, p2,\n",
    "                radius=3, color=colors[l], thickness=-1, lineType=cv2.LINE_AA)\n",
    "\n",
    "    # Blend the keypoints.\n",
    "    return cv2.addWeighted(img, 1.0 - alpha, kp_mask, alpha, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "If8z4OZfDHmC"
   },
   "source": [
    "### Base Model Config\n",
    "\n",
    "This is the base model that we will fine-tune from. First we need to replace the bounding box heads and mask heads to make it compatible with our Shapes Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wM0coO44ClbV",
    "outputId": "9a9c1f2d-0f6d-420e-b737-30b295b15935"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing base_config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile base_config.yaml\n",
    "MODEL:\n",
    "  META_ARCHITECTURE: \"GeneralizedRCNN\"\n",
    "  WEIGHT: \"catalog://Caffe2Detectron/COCO/35858933/e2e_mask_rcnn_R-50-FPN_1x\"\n",
    "  BACKBONE:\n",
    "    CONV_BODY: \"R-50-FPN\"\n",
    "  RESNETS:\n",
    "    BACKBONE_OUT_CHANNELS: 256\n",
    "  RPN:\n",
    "    USE_FPN: True\n",
    "    ANCHOR_STRIDE: (4, 8, 16, 32, 64)\n",
    "    PRE_NMS_TOP_N_TRAIN: 2000\n",
    "    PRE_NMS_TOP_N_TEST: 1000\n",
    "    POST_NMS_TOP_N_TEST: 1000\n",
    "    FPN_POST_NMS_TOP_N_TEST: 1000\n",
    "  ROI_HEADS:\n",
    "    USE_FPN: True\n",
    "  ROI_BOX_HEAD:\n",
    "    POOLER_RESOLUTION: 7\n",
    "    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n",
    "    POOLER_SAMPLING_RATIO: 2\n",
    "    FEATURE_EXTRACTOR: \"FPN2MLPFeatureExtractor\"\n",
    "    PREDICTOR: \"FPNPredictor\"\n",
    "  ROI_MASK_HEAD:\n",
    "    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n",
    "    FEATURE_EXTRACTOR: \"MaskRCNNFPNFeatureExtractor\"\n",
    "    PREDICTOR: \"MaskRCNNC4Predictor\"\n",
    "    POOLER_RESOLUTION: 14\n",
    "    POOLER_SAMPLING_RATIO: 2\n",
    "    RESOLUTION: 28\n",
    "    SHARE_BOX_FEATURE_EXTRACTOR: False\n",
    "  MASK_ON: True\n",
    "DATALOADER:\n",
    "  SIZE_DIVISIBILITY: 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mOo-0LGFEAmc"
   },
   "source": [
    "### Pre-trained weight removal\n",
    "\n",
    "Here, the pre-trained weights of bbox, mask and class predictions are removed. This is done so that we can make the model shapes dataset compatible i.e predict 3 classes instead of Coco's 81 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ISFsxBxBDZcQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-28 12:07:00,087 maskrcnn_benchmark INFO: Using 1 GPUs\n",
      "2019-06-28 12:07:03,069 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from catalog://Caffe2Detectron/COCO/35858933/e2e_mask_rcnn_R-50-FPN_1x\n",
      "2019-06-28 12:07:03,071 maskrcnn_benchmark.utils.checkpoint INFO: catalog://Caffe2Detectron/COCO/35858933/e2e_mask_rcnn_R-50-FPN_1x points to https://dl.fbaipublicfiles.com/detectron/35858933/12_2017_baselines/e2e_mask_rcnn_R-50-FPN_1x.yaml.01_48_14.DzEQe4wC/output/train/coco_2014_train%3Acoco_2014_valminusminival/generalized_rcnn/model_final.pkl\n",
      "2019-06-28 12:07:03,073 maskrcnn_benchmark.utils.checkpoint INFO: url https://dl.fbaipublicfiles.com/detectron/35858933/12_2017_baselines/e2e_mask_rcnn_R-50-FPN_1x.yaml.01_48_14.DzEQe4wC/output/train/coco_2014_train%3Acoco_2014_valminusminival/generalized_rcnn/model_final.pkl cached in /home/vflorenc/.torch/models/_detectron_35858933_12_2017_baselines_e2e_mask_rcnn_R-50-FPN_1x.yaml.01_48_14.DzEQe4wC_output_train_coco_2014_train%3Acoco_2014_valminusminival_generalized_rcnn_model_final.pkl\n",
      "2019-06-28 12:07:03,407 maskrcnn_benchmark.utils.c2_model_loading INFO: Remapping C2 weights\n",
      "2019-06-28 12:07:03,408 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: _[mask]_fcn1_b                 mapped name: mask_fcn1.bias\n",
      "2019-06-28 12:07:03,409 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: _[mask]_fcn1_w                 mapped name: mask_fcn1.weight\n",
      "2019-06-28 12:07:03,411 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: _[mask]_fcn2_b                 mapped name: mask_fcn2.bias\n",
      "2019-06-28 12:07:03,413 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: _[mask]_fcn2_w                 mapped name: mask_fcn2.weight\n",
      "2019-06-28 12:07:03,415 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: _[mask]_fcn3_b                 mapped name: mask_fcn3.bias\n",
      "2019-06-28 12:07:03,416 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: _[mask]_fcn3_w                 mapped name: mask_fcn3.weight\n",
      "2019-06-28 12:07:03,417 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: _[mask]_fcn4_b                 mapped name: mask_fcn4.bias\n",
      "2019-06-28 12:07:03,419 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: _[mask]_fcn4_w                 mapped name: mask_fcn4.weight\n",
      "2019-06-28 12:07:03,420 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: bbox_pred_b                    mapped name: bbox_pred.bias\n",
      "2019-06-28 12:07:03,422 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: bbox_pred_w                    mapped name: bbox_pred.weight\n",
      "2019-06-28 12:07:03,423 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: cls_score_b                    mapped name: cls_score.bias\n",
      "2019-06-28 12:07:03,423 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: cls_score_w                    mapped name: cls_score.weight\n",
      "2019-06-28 12:07:03,424 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: conv1_b                        mapped name: conv1.bias\n",
      "2019-06-28 12:07:03,426 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: conv1_w                        mapped name: conv1.weight\n",
      "2019-06-28 12:07:03,427 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: conv5_mask_b                   mapped name: conv5_mask.bias\n",
      "2019-06-28 12:07:03,428 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: conv5_mask_w                   mapped name: conv5_mask.weight\n",
      "2019-06-28 12:07:03,429 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: conv_rpn_fpn2_b                mapped name: rpn.head.conv.bias\n",
      "2019-06-28 12:07:03,430 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: conv_rpn_fpn2_w                mapped name: rpn.head.conv.weight\n",
      "2019-06-28 12:07:03,431 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: fc1000_b                       mapped name: fc1000.bias\n",
      "2019-06-28 12:07:03,433 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: fc1000_w                       mapped name: fc1000.weight\n",
      "2019-06-28 12:07:03,433 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: fc6_b                          mapped name: fc6.bias\n",
      "2019-06-28 12:07:03,435 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: fc6_w                          mapped name: fc6.weight\n",
      "2019-06-28 12:07:03,435 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: fc7_b                          mapped name: fc7.bias\n",
      "2019-06-28 12:07:03,437 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: fc7_w                          mapped name: fc7.weight\n",
      "2019-06-28 12:07:03,438 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: fpn_inner_res2_2_sum_lateral_b mapped name: fpn_inner1.bias\n",
      "2019-06-28 12:07:03,439 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: fpn_inner_res2_2_sum_lateral_w mapped name: fpn_inner1.weight\n",
      "2019-06-28 12:07:03,440 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: fpn_inner_res3_3_sum_lateral_b mapped name: fpn_inner2.bias\n",
      "2019-06-28 12:07:03,441 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: fpn_inner_res3_3_sum_lateral_w mapped name: fpn_inner2.weight\n",
      "2019-06-28 12:07:03,442 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: fpn_inner_res4_5_sum_lateral_b mapped name: fpn_inner3.bias\n",
      "2019-06-28 12:07:03,443 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: fpn_inner_res4_5_sum_lateral_w mapped name: fpn_inner3.weight\n",
      "2019-06-28 12:07:03,444 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: fpn_inner_res5_2_sum_b         mapped name: fpn_inner4.bias\n",
      "2019-06-28 12:07:03,445 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: fpn_inner_res5_2_sum_w         mapped name: fpn_inner4.weight\n",
      "2019-06-28 12:07:03,446 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: fpn_res2_2_sum_b               mapped name: fpn_layer1.bias\n",
      "2019-06-28 12:07:03,447 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: fpn_res2_2_sum_w               mapped name: fpn_layer1.weight\n",
      "2019-06-28 12:07:03,448 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: fpn_res3_3_sum_b               mapped name: fpn_layer2.bias\n",
      "2019-06-28 12:07:03,449 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: fpn_res3_3_sum_w               mapped name: fpn_layer2.weight\n",
      "2019-06-28 12:07:03,450 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: fpn_res4_5_sum_b               mapped name: fpn_layer3.bias\n",
      "2019-06-28 12:07:03,450 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: fpn_res4_5_sum_w               mapped name: fpn_layer3.weight\n",
      "2019-06-28 12:07:03,451 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: fpn_res5_2_sum_b               mapped name: fpn_layer4.bias\n",
      "2019-06-28 12:07:03,454 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: fpn_res5_2_sum_w               mapped name: fpn_layer4.weight\n",
      "2019-06-28 12:07:03,454 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: mask_fcn_logits_b              mapped name: mask_fcn_logits.bias\n",
      "2019-06-28 12:07:03,456 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: mask_fcn_logits_w              mapped name: mask_fcn_logits.weight\n",
      "2019-06-28 12:07:03,457 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch1_b               mapped name: layer1.0.downsample.0.bias\n",
      "2019-06-28 12:07:03,457 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch1_bn_b            mapped name: layer1.0.downsample.1.bias\n",
      "2019-06-28 12:07:03,459 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch1_bn_s            mapped name: layer1.0.downsample.1.weight\n",
      "2019-06-28 12:07:03,460 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch1_w               mapped name: layer1.0.downsample.0.weight\n",
      "2019-06-28 12:07:03,461 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_b              mapped name: layer1.0.conv1.bias\n",
      "2019-06-28 12:07:03,462 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_bn_b           mapped name: layer1.0.bn1.bias\n",
      "2019-06-28 12:07:03,463 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_bn_s           mapped name: layer1.0.bn1.weight\n",
      "2019-06-28 12:07:03,465 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_w              mapped name: layer1.0.conv1.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-28 12:07:03,466 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_b              mapped name: layer1.0.conv2.bias\n",
      "2019-06-28 12:07:03,467 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_bn_b           mapped name: layer1.0.bn2.bias\n",
      "2019-06-28 12:07:03,469 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_bn_s           mapped name: layer1.0.bn2.weight\n",
      "2019-06-28 12:07:03,469 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_w              mapped name: layer1.0.conv2.weight\n",
      "2019-06-28 12:07:03,471 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_b              mapped name: layer1.0.conv3.bias\n",
      "2019-06-28 12:07:03,472 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_bn_b           mapped name: layer1.0.bn3.bias\n",
      "2019-06-28 12:07:03,473 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_bn_s           mapped name: layer1.0.bn3.weight\n",
      "2019-06-28 12:07:03,474 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_w              mapped name: layer1.0.conv3.weight\n",
      "2019-06-28 12:07:03,475 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_b              mapped name: layer1.1.conv1.bias\n",
      "2019-06-28 12:07:03,475 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_bn_b           mapped name: layer1.1.bn1.bias\n",
      "2019-06-28 12:07:03,476 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_bn_s           mapped name: layer1.1.bn1.weight\n",
      "2019-06-28 12:07:03,478 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_w              mapped name: layer1.1.conv1.weight\n",
      "2019-06-28 12:07:03,479 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_b              mapped name: layer1.1.conv2.bias\n",
      "2019-06-28 12:07:03,480 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_bn_b           mapped name: layer1.1.bn2.bias\n",
      "2019-06-28 12:07:03,481 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_bn_s           mapped name: layer1.1.bn2.weight\n",
      "2019-06-28 12:07:03,482 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_w              mapped name: layer1.1.conv2.weight\n",
      "2019-06-28 12:07:03,483 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_b              mapped name: layer1.1.conv3.bias\n",
      "2019-06-28 12:07:03,485 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_bn_b           mapped name: layer1.1.bn3.bias\n",
      "2019-06-28 12:07:03,486 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_bn_s           mapped name: layer1.1.bn3.weight\n",
      "2019-06-28 12:07:03,487 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_w              mapped name: layer1.1.conv3.weight\n",
      "2019-06-28 12:07:03,489 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_b              mapped name: layer1.2.conv1.bias\n",
      "2019-06-28 12:07:03,489 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_bn_b           mapped name: layer1.2.bn1.bias\n",
      "2019-06-28 12:07:03,490 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_bn_s           mapped name: layer1.2.bn1.weight\n",
      "2019-06-28 12:07:03,491 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_w              mapped name: layer1.2.conv1.weight\n",
      "2019-06-28 12:07:03,492 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_b              mapped name: layer1.2.conv2.bias\n",
      "2019-06-28 12:07:03,494 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_bn_b           mapped name: layer1.2.bn2.bias\n",
      "2019-06-28 12:07:03,495 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_bn_s           mapped name: layer1.2.bn2.weight\n",
      "2019-06-28 12:07:03,497 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_w              mapped name: layer1.2.conv2.weight\n",
      "2019-06-28 12:07:03,498 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_b              mapped name: layer1.2.conv3.bias\n",
      "2019-06-28 12:07:03,500 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_bn_b           mapped name: layer1.2.bn3.bias\n",
      "2019-06-28 12:07:03,501 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_bn_s           mapped name: layer1.2.bn3.weight\n",
      "2019-06-28 12:07:03,502 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_w              mapped name: layer1.2.conv3.weight\n",
      "2019-06-28 12:07:03,503 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch1_b               mapped name: layer2.0.downsample.0.bias\n",
      "2019-06-28 12:07:03,504 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch1_bn_b            mapped name: layer2.0.downsample.1.bias\n",
      "2019-06-28 12:07:03,507 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch1_bn_s            mapped name: layer2.0.downsample.1.weight\n",
      "2019-06-28 12:07:03,509 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch1_w               mapped name: layer2.0.downsample.0.weight\n",
      "2019-06-28 12:07:03,510 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_b              mapped name: layer2.0.conv1.bias\n",
      "2019-06-28 12:07:03,511 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_bn_b           mapped name: layer2.0.bn1.bias\n",
      "2019-06-28 12:07:03,513 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_bn_s           mapped name: layer2.0.bn1.weight\n",
      "2019-06-28 12:07:03,514 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_w              mapped name: layer2.0.conv1.weight\n",
      "2019-06-28 12:07:03,515 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_b              mapped name: layer2.0.conv2.bias\n",
      "2019-06-28 12:07:03,516 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_bn_b           mapped name: layer2.0.bn2.bias\n",
      "2019-06-28 12:07:03,516 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_bn_s           mapped name: layer2.0.bn2.weight\n",
      "2019-06-28 12:07:03,517 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_w              mapped name: layer2.0.conv2.weight\n",
      "2019-06-28 12:07:03,517 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_b              mapped name: layer2.0.conv3.bias\n",
      "2019-06-28 12:07:03,518 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_bn_b           mapped name: layer2.0.bn3.bias\n",
      "2019-06-28 12:07:03,520 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_bn_s           mapped name: layer2.0.bn3.weight\n",
      "2019-06-28 12:07:03,521 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_w              mapped name: layer2.0.conv3.weight\n",
      "2019-06-28 12:07:03,522 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_b              mapped name: layer2.1.conv1.bias\n",
      "2019-06-28 12:07:03,523 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_bn_b           mapped name: layer2.1.bn1.bias\n",
      "2019-06-28 12:07:03,523 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_bn_s           mapped name: layer2.1.bn1.weight\n",
      "2019-06-28 12:07:03,525 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_w              mapped name: layer2.1.conv1.weight\n",
      "2019-06-28 12:07:03,526 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_b              mapped name: layer2.1.conv2.bias\n",
      "2019-06-28 12:07:03,527 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_bn_b           mapped name: layer2.1.bn2.bias\n",
      "2019-06-28 12:07:03,527 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_bn_s           mapped name: layer2.1.bn2.weight\n",
      "2019-06-28 12:07:03,530 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_w              mapped name: layer2.1.conv2.weight\n",
      "2019-06-28 12:07:03,531 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_b              mapped name: layer2.1.conv3.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-28 12:07:03,531 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_bn_b           mapped name: layer2.1.bn3.bias\n",
      "2019-06-28 12:07:03,533 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_bn_s           mapped name: layer2.1.bn3.weight\n",
      "2019-06-28 12:07:03,533 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_w              mapped name: layer2.1.conv3.weight\n",
      "2019-06-28 12:07:03,534 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_b              mapped name: layer2.2.conv1.bias\n",
      "2019-06-28 12:07:03,535 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_bn_b           mapped name: layer2.2.bn1.bias\n",
      "2019-06-28 12:07:03,535 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_bn_s           mapped name: layer2.2.bn1.weight\n",
      "2019-06-28 12:07:03,537 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_w              mapped name: layer2.2.conv1.weight\n",
      "2019-06-28 12:07:03,538 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_b              mapped name: layer2.2.conv2.bias\n",
      "2019-06-28 12:07:03,539 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_bn_b           mapped name: layer2.2.bn2.bias\n",
      "2019-06-28 12:07:03,540 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_bn_s           mapped name: layer2.2.bn2.weight\n",
      "2019-06-28 12:07:03,541 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_w              mapped name: layer2.2.conv2.weight\n",
      "2019-06-28 12:07:03,541 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_b              mapped name: layer2.2.conv3.bias\n",
      "2019-06-28 12:07:03,542 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_bn_b           mapped name: layer2.2.bn3.bias\n",
      "2019-06-28 12:07:03,543 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_bn_s           mapped name: layer2.2.bn3.weight\n",
      "2019-06-28 12:07:03,544 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_w              mapped name: layer2.2.conv3.weight\n",
      "2019-06-28 12:07:03,545 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_b              mapped name: layer2.3.conv1.bias\n",
      "2019-06-28 12:07:03,546 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_bn_b           mapped name: layer2.3.bn1.bias\n",
      "2019-06-28 12:07:03,547 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_bn_s           mapped name: layer2.3.bn1.weight\n",
      "2019-06-28 12:07:03,548 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_w              mapped name: layer2.3.conv1.weight\n",
      "2019-06-28 12:07:03,549 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_b              mapped name: layer2.3.conv2.bias\n",
      "2019-06-28 12:07:03,550 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_bn_b           mapped name: layer2.3.bn2.bias\n",
      "2019-06-28 12:07:03,551 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_bn_s           mapped name: layer2.3.bn2.weight\n",
      "2019-06-28 12:07:03,552 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_w              mapped name: layer2.3.conv2.weight\n",
      "2019-06-28 12:07:03,553 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_b              mapped name: layer2.3.conv3.bias\n",
      "2019-06-28 12:07:03,554 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_bn_b           mapped name: layer2.3.bn3.bias\n",
      "2019-06-28 12:07:03,555 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_bn_s           mapped name: layer2.3.bn3.weight\n",
      "2019-06-28 12:07:03,556 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_w              mapped name: layer2.3.conv3.weight\n",
      "2019-06-28 12:07:03,557 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch1_b               mapped name: layer3.0.downsample.0.bias\n",
      "2019-06-28 12:07:03,558 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch1_bn_b            mapped name: layer3.0.downsample.1.bias\n",
      "2019-06-28 12:07:03,559 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch1_bn_s            mapped name: layer3.0.downsample.1.weight\n",
      "2019-06-28 12:07:03,560 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch1_w               mapped name: layer3.0.downsample.0.weight\n",
      "2019-06-28 12:07:03,561 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_b              mapped name: layer3.0.conv1.bias\n",
      "2019-06-28 12:07:03,562 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_bn_b           mapped name: layer3.0.bn1.bias\n",
      "2019-06-28 12:07:03,562 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_bn_s           mapped name: layer3.0.bn1.weight\n",
      "2019-06-28 12:07:03,564 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_w              mapped name: layer3.0.conv1.weight\n",
      "2019-06-28 12:07:03,567 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_b              mapped name: layer3.0.conv2.bias\n",
      "2019-06-28 12:07:03,568 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_bn_b           mapped name: layer3.0.bn2.bias\n",
      "2019-06-28 12:07:03,569 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_bn_s           mapped name: layer3.0.bn2.weight\n",
      "2019-06-28 12:07:03,570 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_w              mapped name: layer3.0.conv2.weight\n",
      "2019-06-28 12:07:03,571 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_b              mapped name: layer3.0.conv3.bias\n",
      "2019-06-28 12:07:03,572 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_bn_b           mapped name: layer3.0.bn3.bias\n",
      "2019-06-28 12:07:03,573 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_bn_s           mapped name: layer3.0.bn3.weight\n",
      "2019-06-28 12:07:03,574 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_w              mapped name: layer3.0.conv3.weight\n",
      "2019-06-28 12:07:03,574 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_b              mapped name: layer3.1.conv1.bias\n",
      "2019-06-28 12:07:03,575 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_bn_b           mapped name: layer3.1.bn1.bias\n",
      "2019-06-28 12:07:03,576 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_bn_s           mapped name: layer3.1.bn1.weight\n",
      "2019-06-28 12:07:03,579 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_w              mapped name: layer3.1.conv1.weight\n",
      "2019-06-28 12:07:03,580 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_b              mapped name: layer3.1.conv2.bias\n",
      "2019-06-28 12:07:03,581 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_bn_b           mapped name: layer3.1.bn2.bias\n",
      "2019-06-28 12:07:03,582 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_bn_s           mapped name: layer3.1.bn2.weight\n",
      "2019-06-28 12:07:03,583 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_w              mapped name: layer3.1.conv2.weight\n",
      "2019-06-28 12:07:03,584 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_b              mapped name: layer3.1.conv3.bias\n",
      "2019-06-28 12:07:03,585 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_bn_b           mapped name: layer3.1.bn3.bias\n",
      "2019-06-28 12:07:03,587 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_bn_s           mapped name: layer3.1.bn3.weight\n",
      "2019-06-28 12:07:03,587 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_w              mapped name: layer3.1.conv3.weight\n",
      "2019-06-28 12:07:03,588 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_b              mapped name: layer3.2.conv1.bias\n",
      "2019-06-28 12:07:03,589 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_bn_b           mapped name: layer3.2.bn1.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-28 12:07:03,590 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_bn_s           mapped name: layer3.2.bn1.weight\n",
      "2019-06-28 12:07:03,590 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_w              mapped name: layer3.2.conv1.weight\n",
      "2019-06-28 12:07:03,591 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_b              mapped name: layer3.2.conv2.bias\n",
      "2019-06-28 12:07:03,591 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_bn_b           mapped name: layer3.2.bn2.bias\n",
      "2019-06-28 12:07:03,593 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_bn_s           mapped name: layer3.2.bn2.weight\n",
      "2019-06-28 12:07:03,594 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_w              mapped name: layer3.2.conv2.weight\n",
      "2019-06-28 12:07:03,595 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_b              mapped name: layer3.2.conv3.bias\n",
      "2019-06-28 12:07:03,596 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_bn_b           mapped name: layer3.2.bn3.bias\n",
      "2019-06-28 12:07:03,597 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_bn_s           mapped name: layer3.2.bn3.weight\n",
      "2019-06-28 12:07:03,598 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_w              mapped name: layer3.2.conv3.weight\n",
      "2019-06-28 12:07:03,599 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_b              mapped name: layer3.3.conv1.bias\n",
      "2019-06-28 12:07:03,600 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_bn_b           mapped name: layer3.3.bn1.bias\n",
      "2019-06-28 12:07:03,601 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_bn_s           mapped name: layer3.3.bn1.weight\n",
      "2019-06-28 12:07:03,602 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_w              mapped name: layer3.3.conv1.weight\n",
      "2019-06-28 12:07:03,603 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_b              mapped name: layer3.3.conv2.bias\n",
      "2019-06-28 12:07:03,604 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_bn_b           mapped name: layer3.3.bn2.bias\n",
      "2019-06-28 12:07:03,606 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_bn_s           mapped name: layer3.3.bn2.weight\n",
      "2019-06-28 12:07:03,607 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_w              mapped name: layer3.3.conv2.weight\n",
      "2019-06-28 12:07:03,608 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_b              mapped name: layer3.3.conv3.bias\n",
      "2019-06-28 12:07:03,609 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_bn_b           mapped name: layer3.3.bn3.bias\n",
      "2019-06-28 12:07:03,610 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_bn_s           mapped name: layer3.3.bn3.weight\n",
      "2019-06-28 12:07:03,611 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_w              mapped name: layer3.3.conv3.weight\n",
      "2019-06-28 12:07:03,613 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_b              mapped name: layer3.4.conv1.bias\n",
      "2019-06-28 12:07:03,614 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_bn_b           mapped name: layer3.4.bn1.bias\n",
      "2019-06-28 12:07:03,615 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_bn_s           mapped name: layer3.4.bn1.weight\n",
      "2019-06-28 12:07:03,616 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_w              mapped name: layer3.4.conv1.weight\n",
      "2019-06-28 12:07:03,618 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_b              mapped name: layer3.4.conv2.bias\n",
      "2019-06-28 12:07:03,619 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_bn_b           mapped name: layer3.4.bn2.bias\n",
      "2019-06-28 12:07:03,619 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_bn_s           mapped name: layer3.4.bn2.weight\n",
      "2019-06-28 12:07:03,620 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_w              mapped name: layer3.4.conv2.weight\n",
      "2019-06-28 12:07:03,621 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_b              mapped name: layer3.4.conv3.bias\n",
      "2019-06-28 12:07:03,622 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_bn_b           mapped name: layer3.4.bn3.bias\n",
      "2019-06-28 12:07:03,622 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_bn_s           mapped name: layer3.4.bn3.weight\n",
      "2019-06-28 12:07:03,624 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_w              mapped name: layer3.4.conv3.weight\n",
      "2019-06-28 12:07:03,625 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_b              mapped name: layer3.5.conv1.bias\n",
      "2019-06-28 12:07:03,626 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_bn_b           mapped name: layer3.5.bn1.bias\n",
      "2019-06-28 12:07:03,627 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_bn_s           mapped name: layer3.5.bn1.weight\n",
      "2019-06-28 12:07:03,629 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_w              mapped name: layer3.5.conv1.weight\n",
      "2019-06-28 12:07:03,631 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_b              mapped name: layer3.5.conv2.bias\n",
      "2019-06-28 12:07:03,631 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_bn_b           mapped name: layer3.5.bn2.bias\n",
      "2019-06-28 12:07:03,633 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_bn_s           mapped name: layer3.5.bn2.weight\n",
      "2019-06-28 12:07:03,634 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_w              mapped name: layer3.5.conv2.weight\n",
      "2019-06-28 12:07:03,634 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_b              mapped name: layer3.5.conv3.bias\n",
      "2019-06-28 12:07:03,635 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_bn_b           mapped name: layer3.5.bn3.bias\n",
      "2019-06-28 12:07:03,635 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_bn_s           mapped name: layer3.5.bn3.weight\n",
      "2019-06-28 12:07:03,636 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_w              mapped name: layer3.5.conv3.weight\n",
      "2019-06-28 12:07:03,636 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch1_b               mapped name: layer4.0.downsample.0.bias\n",
      "2019-06-28 12:07:03,637 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch1_bn_b            mapped name: layer4.0.downsample.1.bias\n",
      "2019-06-28 12:07:03,638 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch1_bn_s            mapped name: layer4.0.downsample.1.weight\n",
      "2019-06-28 12:07:03,638 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch1_w               mapped name: layer4.0.downsample.0.weight\n",
      "2019-06-28 12:07:03,639 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_b              mapped name: layer4.0.conv1.bias\n",
      "2019-06-28 12:07:03,641 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_bn_b           mapped name: layer4.0.bn1.bias\n",
      "2019-06-28 12:07:03,641 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_bn_s           mapped name: layer4.0.bn1.weight\n",
      "2019-06-28 12:07:03,642 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_w              mapped name: layer4.0.conv1.weight\n",
      "2019-06-28 12:07:03,643 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_b              mapped name: layer4.0.conv2.bias\n",
      "2019-06-28 12:07:03,643 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_bn_b           mapped name: layer4.0.bn2.bias\n",
      "2019-06-28 12:07:03,644 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_bn_s           mapped name: layer4.0.bn2.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-28 12:07:03,645 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_w              mapped name: layer4.0.conv2.weight\n",
      "2019-06-28 12:07:03,646 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_b              mapped name: layer4.0.conv3.bias\n",
      "2019-06-28 12:07:03,647 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_bn_b           mapped name: layer4.0.bn3.bias\n",
      "2019-06-28 12:07:03,647 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_bn_s           mapped name: layer4.0.bn3.weight\n",
      "2019-06-28 12:07:03,648 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_w              mapped name: layer4.0.conv3.weight\n",
      "2019-06-28 12:07:03,649 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_b              mapped name: layer4.1.conv1.bias\n",
      "2019-06-28 12:07:03,650 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_bn_b           mapped name: layer4.1.bn1.bias\n",
      "2019-06-28 12:07:03,651 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_bn_s           mapped name: layer4.1.bn1.weight\n",
      "2019-06-28 12:07:03,652 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_w              mapped name: layer4.1.conv1.weight\n",
      "2019-06-28 12:07:03,653 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_b              mapped name: layer4.1.conv2.bias\n",
      "2019-06-28 12:07:03,653 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_bn_b           mapped name: layer4.1.bn2.bias\n",
      "2019-06-28 12:07:03,655 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_bn_s           mapped name: layer4.1.bn2.weight\n",
      "2019-06-28 12:07:03,655 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_w              mapped name: layer4.1.conv2.weight\n",
      "2019-06-28 12:07:03,657 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_b              mapped name: layer4.1.conv3.bias\n",
      "2019-06-28 12:07:03,658 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_bn_b           mapped name: layer4.1.bn3.bias\n",
      "2019-06-28 12:07:03,659 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_bn_s           mapped name: layer4.1.bn3.weight\n",
      "2019-06-28 12:07:03,660 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_w              mapped name: layer4.1.conv3.weight\n",
      "2019-06-28 12:07:03,661 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_b              mapped name: layer4.2.conv1.bias\n",
      "2019-06-28 12:07:03,662 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_bn_b           mapped name: layer4.2.bn1.bias\n",
      "2019-06-28 12:07:03,663 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_bn_s           mapped name: layer4.2.bn1.weight\n",
      "2019-06-28 12:07:03,663 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_w              mapped name: layer4.2.conv1.weight\n",
      "2019-06-28 12:07:03,664 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_b              mapped name: layer4.2.conv2.bias\n",
      "2019-06-28 12:07:03,665 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_bn_b           mapped name: layer4.2.bn2.bias\n",
      "2019-06-28 12:07:03,666 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_bn_s           mapped name: layer4.2.bn2.weight\n",
      "2019-06-28 12:07:03,667 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_w              mapped name: layer4.2.conv2.weight\n",
      "2019-06-28 12:07:03,668 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_b              mapped name: layer4.2.conv3.bias\n",
      "2019-06-28 12:07:03,669 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_bn_b           mapped name: layer4.2.bn3.bias\n",
      "2019-06-28 12:07:03,669 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_bn_s           mapped name: layer4.2.bn3.weight\n",
      "2019-06-28 12:07:03,670 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_w              mapped name: layer4.2.conv3.weight\n",
      "2019-06-28 12:07:03,671 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res_conv1_bn_b                 mapped name: bn1.bias\n",
      "2019-06-28 12:07:03,671 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res_conv1_bn_s                 mapped name: bn1.weight\n",
      "2019-06-28 12:07:03,673 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: rpn_bbox_pred_fpn2_b           mapped name: rpn.head.bbox_pred.bias\n",
      "2019-06-28 12:07:03,674 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: rpn_bbox_pred_fpn2_w           mapped name: rpn.head.bbox_pred.weight\n",
      "2019-06-28 12:07:03,677 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: rpn_cls_logits_fpn2_b          mapped name: rpn.head.cls_logits.bias\n",
      "2019-06-28 12:07:03,679 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: rpn_cls_logits_fpn2_w          mapped name: rpn.head.cls_logits.weight\n",
      "2019-06-28 12:07:03,682 maskrcnn_benchmark.utils.c2_model_loading INFO: Remapping conv weights for deformable conv weights\n",
      "2019-06-28 12:07:03,709 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.bias                   loaded from layer1.0.bn1.bias            of shape (64,)\n",
      "2019-06-28 12:07:03,712 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.weight                 loaded from layer1.0.bn1.weight          of shape (64,)\n",
      "2019-06-28 12:07:03,721 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.bias                   loaded from layer1.0.bn2.bias            of shape (64,)\n",
      "2019-06-28 12:07:03,722 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.weight                 loaded from layer1.0.bn2.weight          of shape (64,)\n",
      "2019-06-28 12:07:03,722 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.bias                   loaded from layer1.0.bn3.bias            of shape (256,)\n",
      "2019-06-28 12:07:03,723 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.weight                 loaded from layer1.0.bn3.weight          of shape (256,)\n",
      "2019-06-28 12:07:03,724 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv1.weight               loaded from layer1.0.conv1.weight        of shape (64, 64, 1, 1)\n",
      "2019-06-28 12:07:03,725 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv2.weight               loaded from layer1.0.conv2.weight        of shape (64, 64, 3, 3)\n",
      "2019-06-28 12:07:03,725 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv3.weight               loaded from layer1.0.conv3.weight        of shape (256, 64, 1, 1)\n",
      "2019-06-28 12:07:03,727 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.0.weight        loaded from layer1.0.downsample.0.weight of shape (256, 64, 1, 1)\n",
      "2019-06-28 12:07:03,727 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.bias          loaded from layer1.0.downsample.1.bias   of shape (256,)\n",
      "2019-06-28 12:07:03,729 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.weight        loaded from layer1.0.downsample.1.weight of shape (256,)\n",
      "2019-06-28 12:07:03,729 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.bias                   loaded from layer1.1.bn1.bias            of shape (64,)\n",
      "2019-06-28 12:07:03,730 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.weight                 loaded from layer1.1.bn1.weight          of shape (64,)\n",
      "2019-06-28 12:07:03,731 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.bias                   loaded from layer1.1.bn2.bias            of shape (64,)\n",
      "2019-06-28 12:07:03,732 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.weight                 loaded from layer1.1.bn2.weight          of shape (64,)\n",
      "2019-06-28 12:07:03,733 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.bias                   loaded from layer1.1.bn3.bias            of shape (256,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-28 12:07:03,734 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.weight                 loaded from layer1.1.bn3.weight          of shape (256,)\n",
      "2019-06-28 12:07:03,735 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv1.weight               loaded from layer1.1.conv1.weight        of shape (64, 256, 1, 1)\n",
      "2019-06-28 12:07:03,737 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv2.weight               loaded from layer1.1.conv2.weight        of shape (64, 64, 3, 3)\n",
      "2019-06-28 12:07:03,737 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv3.weight               loaded from layer1.1.conv3.weight        of shape (256, 64, 1, 1)\n",
      "2019-06-28 12:07:03,738 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.bias                   loaded from layer1.2.bn1.bias            of shape (64,)\n",
      "2019-06-28 12:07:03,739 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.weight                 loaded from layer1.2.bn1.weight          of shape (64,)\n",
      "2019-06-28 12:07:03,740 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.bias                   loaded from layer1.2.bn2.bias            of shape (64,)\n",
      "2019-06-28 12:07:03,741 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.weight                 loaded from layer1.2.bn2.weight          of shape (64,)\n",
      "2019-06-28 12:07:03,742 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.bias                   loaded from layer1.2.bn3.bias            of shape (256,)\n",
      "2019-06-28 12:07:03,743 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.weight                 loaded from layer1.2.bn3.weight          of shape (256,)\n",
      "2019-06-28 12:07:03,744 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv1.weight               loaded from layer1.2.conv1.weight        of shape (64, 256, 1, 1)\n",
      "2019-06-28 12:07:03,746 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv2.weight               loaded from layer1.2.conv2.weight        of shape (64, 64, 3, 3)\n",
      "2019-06-28 12:07:03,746 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv3.weight               loaded from layer1.2.conv3.weight        of shape (256, 64, 1, 1)\n",
      "2019-06-28 12:07:03,748 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.bias                   loaded from layer2.0.bn1.bias            of shape (128,)\n",
      "2019-06-28 12:07:03,749 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.weight                 loaded from layer2.0.bn1.weight          of shape (128,)\n",
      "2019-06-28 12:07:03,749 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.bias                   loaded from layer2.0.bn2.bias            of shape (128,)\n",
      "2019-06-28 12:07:03,751 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.weight                 loaded from layer2.0.bn2.weight          of shape (128,)\n",
      "2019-06-28 12:07:03,752 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.bias                   loaded from layer2.0.bn3.bias            of shape (512,)\n",
      "2019-06-28 12:07:03,754 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.weight                 loaded from layer2.0.bn3.weight          of shape (512,)\n",
      "2019-06-28 12:07:03,755 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv1.weight               loaded from layer2.0.conv1.weight        of shape (128, 256, 1, 1)\n",
      "2019-06-28 12:07:03,758 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv2.weight               loaded from layer2.0.conv2.weight        of shape (128, 128, 3, 3)\n",
      "2019-06-28 12:07:03,760 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv3.weight               loaded from layer2.0.conv3.weight        of shape (512, 128, 1, 1)\n",
      "2019-06-28 12:07:03,761 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.0.weight        loaded from layer2.0.downsample.0.weight of shape (512, 256, 1, 1)\n",
      "2019-06-28 12:07:03,762 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.bias          loaded from layer2.0.downsample.1.bias   of shape (512,)\n",
      "2019-06-28 12:07:03,763 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.weight        loaded from layer2.0.downsample.1.weight of shape (512,)\n",
      "2019-06-28 12:07:03,764 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.bias                   loaded from layer2.1.bn1.bias            of shape (128,)\n",
      "2019-06-28 12:07:03,764 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.weight                 loaded from layer2.1.bn1.weight          of shape (128,)\n",
      "2019-06-28 12:07:03,765 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.bias                   loaded from layer2.1.bn2.bias            of shape (128,)\n",
      "2019-06-28 12:07:03,766 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.weight                 loaded from layer2.1.bn2.weight          of shape (128,)\n",
      "2019-06-28 12:07:03,766 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.bias                   loaded from layer2.1.bn3.bias            of shape (512,)\n",
      "2019-06-28 12:07:03,767 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.weight                 loaded from layer2.1.bn3.weight          of shape (512,)\n",
      "2019-06-28 12:07:03,769 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv1.weight               loaded from layer2.1.conv1.weight        of shape (128, 512, 1, 1)\n",
      "2019-06-28 12:07:03,769 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv2.weight               loaded from layer2.1.conv2.weight        of shape (128, 128, 3, 3)\n",
      "2019-06-28 12:07:03,770 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv3.weight               loaded from layer2.1.conv3.weight        of shape (512, 128, 1, 1)\n",
      "2019-06-28 12:07:03,771 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.bias                   loaded from layer2.2.bn1.bias            of shape (128,)\n",
      "2019-06-28 12:07:03,771 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.weight                 loaded from layer2.2.bn1.weight          of shape (128,)\n",
      "2019-06-28 12:07:03,772 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.bias                   loaded from layer2.2.bn2.bias            of shape (128,)\n",
      "2019-06-28 12:07:03,774 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.weight                 loaded from layer2.2.bn2.weight          of shape (128,)\n",
      "2019-06-28 12:07:03,776 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.bias                   loaded from layer2.2.bn3.bias            of shape (512,)\n",
      "2019-06-28 12:07:03,776 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.weight                 loaded from layer2.2.bn3.weight          of shape (512,)\n",
      "2019-06-28 12:07:03,777 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv1.weight               loaded from layer2.2.conv1.weight        of shape (128, 512, 1, 1)\n",
      "2019-06-28 12:07:03,778 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv2.weight               loaded from layer2.2.conv2.weight        of shape (128, 128, 3, 3)\n",
      "2019-06-28 12:07:03,779 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv3.weight               loaded from layer2.2.conv3.weight        of shape (512, 128, 1, 1)\n",
      "2019-06-28 12:07:03,780 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.bias                   loaded from layer2.3.bn1.bias            of shape (128,)\n",
      "2019-06-28 12:07:03,781 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.weight                 loaded from layer2.3.bn1.weight          of shape (128,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-28 12:07:03,782 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.bias                   loaded from layer2.3.bn2.bias            of shape (128,)\n",
      "2019-06-28 12:07:03,784 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.weight                 loaded from layer2.3.bn2.weight          of shape (128,)\n",
      "2019-06-28 12:07:03,785 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.bias                   loaded from layer2.3.bn3.bias            of shape (512,)\n",
      "2019-06-28 12:07:03,786 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.weight                 loaded from layer2.3.bn3.weight          of shape (512,)\n",
      "2019-06-28 12:07:03,788 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv1.weight               loaded from layer2.3.conv1.weight        of shape (128, 512, 1, 1)\n",
      "2019-06-28 12:07:03,788 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv2.weight               loaded from layer2.3.conv2.weight        of shape (128, 128, 3, 3)\n",
      "2019-06-28 12:07:03,789 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv3.weight               loaded from layer2.3.conv3.weight        of shape (512, 128, 1, 1)\n",
      "2019-06-28 12:07:03,790 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.bias                   loaded from layer3.0.bn1.bias            of shape (256,)\n",
      "2019-06-28 12:07:03,791 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.weight                 loaded from layer3.0.bn1.weight          of shape (256,)\n",
      "2019-06-28 12:07:03,791 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.bias                   loaded from layer3.0.bn2.bias            of shape (256,)\n",
      "2019-06-28 12:07:03,792 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.weight                 loaded from layer3.0.bn2.weight          of shape (256,)\n",
      "2019-06-28 12:07:03,795 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.bias                   loaded from layer3.0.bn3.bias            of shape (1024,)\n",
      "2019-06-28 12:07:03,797 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.weight                 loaded from layer3.0.bn3.weight          of shape (1024,)\n",
      "2019-06-28 12:07:03,798 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv1.weight               loaded from layer3.0.conv1.weight        of shape (256, 512, 1, 1)\n",
      "2019-06-28 12:07:03,800 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv2.weight               loaded from layer3.0.conv2.weight        of shape (256, 256, 3, 3)\n",
      "2019-06-28 12:07:03,800 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv3.weight               loaded from layer3.0.conv3.weight        of shape (1024, 256, 1, 1)\n",
      "2019-06-28 12:07:03,801 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.0.weight        loaded from layer3.0.downsample.0.weight of shape (1024, 512, 1, 1)\n",
      "2019-06-28 12:07:03,802 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.bias          loaded from layer3.0.downsample.1.bias   of shape (1024,)\n",
      "2019-06-28 12:07:03,802 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.weight        loaded from layer3.0.downsample.1.weight of shape (1024,)\n",
      "2019-06-28 12:07:03,805 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.bias                   loaded from layer3.1.bn1.bias            of shape (256,)\n",
      "2019-06-28 12:07:03,806 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.weight                 loaded from layer3.1.bn1.weight          of shape (256,)\n",
      "2019-06-28 12:07:03,806 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.bias                   loaded from layer3.1.bn2.bias            of shape (256,)\n",
      "2019-06-28 12:07:03,807 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.weight                 loaded from layer3.1.bn2.weight          of shape (256,)\n",
      "2019-06-28 12:07:03,808 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.bias                   loaded from layer3.1.bn3.bias            of shape (1024,)\n",
      "2019-06-28 12:07:03,808 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.weight                 loaded from layer3.1.bn3.weight          of shape (1024,)\n",
      "2019-06-28 12:07:03,809 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv1.weight               loaded from layer3.1.conv1.weight        of shape (256, 1024, 1, 1)\n",
      "2019-06-28 12:07:03,812 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv2.weight               loaded from layer3.1.conv2.weight        of shape (256, 256, 3, 3)\n",
      "2019-06-28 12:07:03,813 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv3.weight               loaded from layer3.1.conv3.weight        of shape (1024, 256, 1, 1)\n",
      "2019-06-28 12:07:03,814 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.bias                   loaded from layer3.2.bn1.bias            of shape (256,)\n",
      "2019-06-28 12:07:03,815 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.weight                 loaded from layer3.2.bn1.weight          of shape (256,)\n",
      "2019-06-28 12:07:03,816 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.bias                   loaded from layer3.2.bn2.bias            of shape (256,)\n",
      "2019-06-28 12:07:03,816 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.weight                 loaded from layer3.2.bn2.weight          of shape (256,)\n",
      "2019-06-28 12:07:03,817 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.bias                   loaded from layer3.2.bn3.bias            of shape (1024,)\n",
      "2019-06-28 12:07:03,818 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.weight                 loaded from layer3.2.bn3.weight          of shape (1024,)\n",
      "2019-06-28 12:07:03,818 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv1.weight               loaded from layer3.2.conv1.weight        of shape (256, 1024, 1, 1)\n",
      "2019-06-28 12:07:03,819 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv2.weight               loaded from layer3.2.conv2.weight        of shape (256, 256, 3, 3)\n",
      "2019-06-28 12:07:03,820 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv3.weight               loaded from layer3.2.conv3.weight        of shape (1024, 256, 1, 1)\n",
      "2019-06-28 12:07:03,820 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.bias                   loaded from layer3.3.bn1.bias            of shape (256,)\n",
      "2019-06-28 12:07:03,821 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.weight                 loaded from layer3.3.bn1.weight          of shape (256,)\n",
      "2019-06-28 12:07:03,822 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.bias                   loaded from layer3.3.bn2.bias            of shape (256,)\n",
      "2019-06-28 12:07:03,822 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.weight                 loaded from layer3.3.bn2.weight          of shape (256,)\n",
      "2019-06-28 12:07:03,824 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.bias                   loaded from layer3.3.bn3.bias            of shape (1024,)\n",
      "2019-06-28 12:07:03,825 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.weight                 loaded from layer3.3.bn3.weight          of shape (1024,)\n",
      "2019-06-28 12:07:03,826 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv1.weight               loaded from layer3.3.conv1.weight        of shape (256, 1024, 1, 1)\n",
      "2019-06-28 12:07:03,828 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv2.weight               loaded from layer3.3.conv2.weight        of shape (256, 256, 3, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-28 12:07:03,829 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv3.weight               loaded from layer3.3.conv3.weight        of shape (1024, 256, 1, 1)\n",
      "2019-06-28 12:07:03,829 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.bias                   loaded from layer3.4.bn1.bias            of shape (256,)\n",
      "2019-06-28 12:07:03,830 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.weight                 loaded from layer3.4.bn1.weight          of shape (256,)\n",
      "2019-06-28 12:07:03,831 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.bias                   loaded from layer3.4.bn2.bias            of shape (256,)\n",
      "2019-06-28 12:07:03,831 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.weight                 loaded from layer3.4.bn2.weight          of shape (256,)\n",
      "2019-06-28 12:07:03,832 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.bias                   loaded from layer3.4.bn3.bias            of shape (1024,)\n",
      "2019-06-28 12:07:03,835 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.weight                 loaded from layer3.4.bn3.weight          of shape (1024,)\n",
      "2019-06-28 12:07:03,837 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv1.weight               loaded from layer3.4.conv1.weight        of shape (256, 1024, 1, 1)\n",
      "2019-06-28 12:07:03,837 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv2.weight               loaded from layer3.4.conv2.weight        of shape (256, 256, 3, 3)\n",
      "2019-06-28 12:07:03,839 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv3.weight               loaded from layer3.4.conv3.weight        of shape (1024, 256, 1, 1)\n",
      "2019-06-28 12:07:03,841 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.bias                   loaded from layer3.5.bn1.bias            of shape (256,)\n",
      "2019-06-28 12:07:03,842 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.weight                 loaded from layer3.5.bn1.weight          of shape (256,)\n",
      "2019-06-28 12:07:03,842 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.bias                   loaded from layer3.5.bn2.bias            of shape (256,)\n",
      "2019-06-28 12:07:03,843 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.weight                 loaded from layer3.5.bn2.weight          of shape (256,)\n",
      "2019-06-28 12:07:03,843 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.bias                   loaded from layer3.5.bn3.bias            of shape (1024,)\n",
      "2019-06-28 12:07:03,844 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.weight                 loaded from layer3.5.bn3.weight          of shape (1024,)\n",
      "2019-06-28 12:07:03,845 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv1.weight               loaded from layer3.5.conv1.weight        of shape (256, 1024, 1, 1)\n",
      "2019-06-28 12:07:03,846 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv2.weight               loaded from layer3.5.conv2.weight        of shape (256, 256, 3, 3)\n",
      "2019-06-28 12:07:03,847 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv3.weight               loaded from layer3.5.conv3.weight        of shape (1024, 256, 1, 1)\n",
      "2019-06-28 12:07:03,847 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.bias                   loaded from layer4.0.bn1.bias            of shape (512,)\n",
      "2019-06-28 12:07:03,848 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.weight                 loaded from layer4.0.bn1.weight          of shape (512,)\n",
      "2019-06-28 12:07:03,853 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.bias                   loaded from layer4.0.bn2.bias            of shape (512,)\n",
      "2019-06-28 12:07:03,853 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.weight                 loaded from layer4.0.bn2.weight          of shape (512,)\n",
      "2019-06-28 12:07:03,854 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.bias                   loaded from layer4.0.bn3.bias            of shape (2048,)\n",
      "2019-06-28 12:07:03,856 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.weight                 loaded from layer4.0.bn3.weight          of shape (2048,)\n",
      "2019-06-28 12:07:03,857 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv1.weight               loaded from layer4.0.conv1.weight        of shape (512, 1024, 1, 1)\n",
      "2019-06-28 12:07:03,858 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv2.weight               loaded from layer4.0.conv2.weight        of shape (512, 512, 3, 3)\n",
      "2019-06-28 12:07:03,859 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv3.weight               loaded from layer4.0.conv3.weight        of shape (2048, 512, 1, 1)\n",
      "2019-06-28 12:07:03,860 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.0.weight        loaded from layer4.0.downsample.0.weight of shape (2048, 1024, 1, 1)\n",
      "2019-06-28 12:07:03,861 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.bias          loaded from layer4.0.downsample.1.bias   of shape (2048,)\n",
      "2019-06-28 12:07:03,862 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.weight        loaded from layer4.0.downsample.1.weight of shape (2048,)\n",
      "2019-06-28 12:07:03,865 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.bias                   loaded from layer4.1.bn1.bias            of shape (512,)\n",
      "2019-06-28 12:07:03,866 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.weight                 loaded from layer4.1.bn1.weight          of shape (512,)\n",
      "2019-06-28 12:07:03,867 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.bias                   loaded from layer4.1.bn2.bias            of shape (512,)\n",
      "2019-06-28 12:07:03,869 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.weight                 loaded from layer4.1.bn2.weight          of shape (512,)\n",
      "2019-06-28 12:07:03,869 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.bias                   loaded from layer4.1.bn3.bias            of shape (2048,)\n",
      "2019-06-28 12:07:03,870 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.weight                 loaded from layer4.1.bn3.weight          of shape (2048,)\n",
      "2019-06-28 12:07:03,871 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv1.weight               loaded from layer4.1.conv1.weight        of shape (512, 2048, 1, 1)\n",
      "2019-06-28 12:07:03,873 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv2.weight               loaded from layer4.1.conv2.weight        of shape (512, 512, 3, 3)\n",
      "2019-06-28 12:07:03,874 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv3.weight               loaded from layer4.1.conv3.weight        of shape (2048, 512, 1, 1)\n",
      "2019-06-28 12:07:03,876 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.bias                   loaded from layer4.2.bn1.bias            of shape (512,)\n",
      "2019-06-28 12:07:03,878 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.weight                 loaded from layer4.2.bn1.weight          of shape (512,)\n",
      "2019-06-28 12:07:03,879 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.bias                   loaded from layer4.2.bn2.bias            of shape (512,)\n",
      "2019-06-28 12:07:03,882 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.weight                 loaded from layer4.2.bn2.weight          of shape (512,)\n",
      "2019-06-28 12:07:03,883 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.bias                   loaded from layer4.2.bn3.bias            of shape (2048,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-28 12:07:03,883 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.weight                 loaded from layer4.2.bn3.weight          of shape (2048,)\n",
      "2019-06-28 12:07:03,885 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv1.weight               loaded from layer4.2.conv1.weight        of shape (512, 2048, 1, 1)\n",
      "2019-06-28 12:07:03,887 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv2.weight               loaded from layer4.2.conv2.weight        of shape (512, 512, 3, 3)\n",
      "2019-06-28 12:07:03,887 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv3.weight               loaded from layer4.2.conv3.weight        of shape (2048, 512, 1, 1)\n",
      "2019-06-28 12:07:03,888 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.bias                       loaded from bn1.bias                     of shape (64,)\n",
      "2019-06-28 12:07:03,889 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.weight                     loaded from bn1.weight                   of shape (64,)\n",
      "2019-06-28 12:07:03,890 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.conv1.weight                   loaded from conv1.weight                 of shape (64, 3, 7, 7)\n",
      "2019-06-28 12:07:03,891 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner1.bias                      loaded from fpn_inner1.bias              of shape (256,)\n",
      "2019-06-28 12:07:03,892 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner1.weight                    loaded from fpn_inner1.weight            of shape (256, 256, 1, 1)\n",
      "2019-06-28 12:07:03,893 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner2.bias                      loaded from fpn_inner2.bias              of shape (256,)\n",
      "2019-06-28 12:07:03,893 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner2.weight                    loaded from fpn_inner2.weight            of shape (256, 512, 1, 1)\n",
      "2019-06-28 12:07:03,896 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner3.bias                      loaded from fpn_inner3.bias              of shape (256,)\n",
      "2019-06-28 12:07:03,897 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner3.weight                    loaded from fpn_inner3.weight            of shape (256, 1024, 1, 1)\n",
      "2019-06-28 12:07:03,898 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner4.bias                      loaded from fpn_inner4.bias              of shape (256,)\n",
      "2019-06-28 12:07:03,898 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner4.weight                    loaded from fpn_inner4.weight            of shape (256, 2048, 1, 1)\n",
      "2019-06-28 12:07:03,900 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer1.bias                      loaded from fpn_layer1.bias              of shape (256,)\n",
      "2019-06-28 12:07:03,901 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer1.weight                    loaded from fpn_layer1.weight            of shape (256, 256, 3, 3)\n",
      "2019-06-28 12:07:03,902 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer2.bias                      loaded from fpn_layer2.bias              of shape (256,)\n",
      "2019-06-28 12:07:03,903 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer2.weight                    loaded from fpn_layer2.weight            of shape (256, 256, 3, 3)\n",
      "2019-06-28 12:07:03,904 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer3.bias                      loaded from fpn_layer3.bias              of shape (256,)\n",
      "2019-06-28 12:07:03,905 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer3.weight                    loaded from fpn_layer3.weight            of shape (256, 256, 3, 3)\n",
      "2019-06-28 12:07:03,906 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer4.bias                      loaded from fpn_layer4.bias              of shape (256,)\n",
      "2019-06-28 12:07:03,907 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer4.weight                    loaded from fpn_layer4.weight            of shape (256, 256, 3, 3)\n",
      "2019-06-28 12:07:03,908 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc6.bias          loaded from fc6.bias                     of shape (1024,)\n",
      "2019-06-28 12:07:03,909 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc6.weight        loaded from fc6.weight                   of shape (1024, 12544)\n",
      "2019-06-28 12:07:03,910 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc7.bias          loaded from fc7.bias                     of shape (1024,)\n",
      "2019-06-28 12:07:03,911 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc7.weight        loaded from fc7.weight                   of shape (1024, 1024)\n",
      "2019-06-28 12:07:03,911 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.bbox_pred.bias            loaded from bbox_pred.bias               of shape (324,)\n",
      "2019-06-28 12:07:03,913 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.bbox_pred.weight          loaded from bbox_pred.weight             of shape (324, 1024)\n",
      "2019-06-28 12:07:03,916 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.cls_score.bias            loaded from cls_score.bias               of shape (81,)\n",
      "2019-06-28 12:07:03,917 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.predictor.cls_score.weight          loaded from cls_score.weight             of shape (81, 1024)\n",
      "2019-06-28 12:07:03,918 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.mask.feature_extractor.mask_fcn1.bias   loaded from mask_fcn1.bias               of shape (256,)\n",
      "2019-06-28 12:07:03,919 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.mask.feature_extractor.mask_fcn1.weight loaded from mask_fcn1.weight             of shape (256, 256, 3, 3)\n",
      "2019-06-28 12:07:03,920 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.mask.feature_extractor.mask_fcn2.bias   loaded from mask_fcn2.bias               of shape (256,)\n",
      "2019-06-28 12:07:03,921 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.mask.feature_extractor.mask_fcn2.weight loaded from mask_fcn2.weight             of shape (256, 256, 3, 3)\n",
      "2019-06-28 12:07:03,923 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.mask.feature_extractor.mask_fcn3.bias   loaded from mask_fcn3.bias               of shape (256,)\n",
      "2019-06-28 12:07:03,924 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.mask.feature_extractor.mask_fcn3.weight loaded from mask_fcn3.weight             of shape (256, 256, 3, 3)\n",
      "2019-06-28 12:07:03,925 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.mask.feature_extractor.mask_fcn4.bias   loaded from mask_fcn4.bias               of shape (256,)\n",
      "2019-06-28 12:07:03,926 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.mask.feature_extractor.mask_fcn4.weight loaded from mask_fcn4.weight             of shape (256, 256, 3, 3)\n",
      "2019-06-28 12:07:03,927 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.mask.predictor.conv5_mask.bias          loaded from conv5_mask.bias              of shape (256,)\n",
      "2019-06-28 12:07:03,929 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.mask.predictor.conv5_mask.weight        loaded from conv5_mask.weight            of shape (256, 256, 2, 2)\n",
      "2019-06-28 12:07:03,930 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.mask.predictor.mask_fcn_logits.bias     loaded from mask_fcn_logits.bias         of shape (81,)\n",
      "2019-06-28 12:07:03,931 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.mask.predictor.mask_fcn_logits.weight   loaded from mask_fcn_logits.weight       of shape (81, 256, 1, 1)\n",
      "2019-06-28 12:07:03,931 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bbox_pred.bias                           loaded from rpn.head.bbox_pred.bias      of shape (12,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-28 12:07:03,933 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bbox_pred.weight                         loaded from rpn.head.bbox_pred.weight    of shape (12, 256, 1, 1)\n",
      "2019-06-28 12:07:03,934 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.cls_logits.bias                          loaded from rpn.head.cls_logits.bias     of shape (3,)\n",
      "2019-06-28 12:07:03,934 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.cls_logits.weight                        loaded from rpn.head.cls_logits.weight   of shape (3, 256, 1, 1)\n",
      "2019-06-28 12:07:03,935 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.conv.bias                                loaded from rpn.head.conv.bias           of shape (256,)\n",
      "2019-06-28 12:07:03,936 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.conv.weight                              loaded from rpn.head.conv.weight         of shape (256, 256, 3, 3)\n",
      "key: roi_heads.box.predictor.cls_score.weight is removed\n",
      "key: roi_heads.box.predictor.cls_score.bias is removed\n",
      "key: roi_heads.box.predictor.bbox_pred.weight is removed\n",
      "key: roi_heads.box.predictor.bbox_pred.bias is removed\n",
      "key: roi_heads.mask.predictor.mask_fcn_logits.weight is removed\n",
      "key: roi_heads.mask.predictor.mask_fcn_logits.bias is removed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def removekey(d, listofkeys):\n",
    "  r = dict(d)\n",
    "  for key in listofkeys:\n",
    "      print('key: {} is removed'.format(key))\n",
    "      r.pop(key)\n",
    "  return r\n",
    " \n",
    "logger_dir = 'log'\n",
    "\n",
    "if logger_dir:\n",
    "    mkdir(logger_dir)\n",
    "\n",
    "logger = setup_logger(\"maskrcnn_benchmark\", logger_dir, get_rank())\n",
    "logger.info(\"Using {} GPUs\".format(1))\n",
    "\n",
    "config_file = \"base_config.yaml\"\n",
    "\n",
    "# update the config options with the config file\n",
    "cfg.merge_from_file(config_file)\n",
    "\n",
    "\n",
    "# Add these for printing class names over your predictions.\n",
    "COCODemo.CATEGORIES = [\n",
    "    \"__background\",\n",
    "    \"square\",\n",
    "    \"circle\",\n",
    "    \"triangle\"\n",
    "]\n",
    "\n",
    "demo = COCODemo(\n",
    "    cfg, \n",
    "    min_image_size=800,\n",
    "    confidence_threshold=0.7)\n",
    "\n",
    "base_model = demo.model\n",
    "\n",
    "# Removes pretrained weights from state dict\n",
    "new_state_dict = removekey(base_model.state_dict(), [ \n",
    "                      \"roi_heads.box.predictor.cls_score.weight\", \"roi_heads.box.predictor.cls_score.bias\", \n",
    "                      \"roi_heads.box.predictor.bbox_pred.weight\", \"roi_heads.box.predictor.bbox_pred.bias\",\n",
    "                     \"roi_heads.mask.predictor.mask_fcn_logits.weight\", \"roi_heads.mask.predictor.mask_fcn_logits.bias\"\n",
    "                  ])\n",
    "\n",
    "# Save new state dict, we will use this as our starting weights for our fine-tuned model\n",
    "torch.save(new_state_dict, \"base_model.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bbCBInqHFUg7"
   },
   "source": [
    "### Fine Tuned Model Config\n",
    "\n",
    "Here we define our shape Dataset config. The important fields are \n",
    "\n",
    "1. WEIGHT: which point to our `base_model.pth` saved in the previous step\n",
    "2. NUM_CLASSES: Which define how many classes we will predict . Note that the number includes the background, hence our shapes dataset has 4 classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5AhIiTgmFXyi",
    "outputId": "94f21f80-5baa-4a67-945a-0bfd726f5d11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing shapes_config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile shapes_config.yaml\n",
    "MODEL:\n",
    "  META_ARCHITECTURE: \"GeneralizedRCNN\"\n",
    "  WEIGHT: \"base_model.pth\"\n",
    "  BACKBONE:\n",
    "    CONV_BODY: \"R-50-FPN\"\n",
    "  RESNETS:\n",
    "    BACKBONE_OUT_CHANNELS: 256\n",
    "  RPN:\n",
    "    USE_FPN: True\n",
    "    ANCHOR_STRIDE: (4, 8, 16, 32, 64)\n",
    "    PRE_NMS_TOP_N_TRAIN: 2000\n",
    "    PRE_NMS_TOP_N_TEST: 1000\n",
    "    POST_NMS_TOP_N_TEST: 1000\n",
    "    FPN_POST_NMS_TOP_N_TEST: 1000\n",
    "  ROI_HEADS:\n",
    "    USE_FPN: True\n",
    "  ROI_BOX_HEAD:\n",
    "    POOLER_RESOLUTION: 7\n",
    "    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n",
    "    POOLER_SAMPLING_RATIO: 2\n",
    "    FEATURE_EXTRACTOR: \"FPN2MLPFeatureExtractor\"\n",
    "    PREDICTOR: \"FPNPredictor\"\n",
    "    NUM_CLASSES: 4 # background + num_classes : IMPORTANT dont forget to add this\n",
    "  ROI_MASK_HEAD:\n",
    "    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n",
    "    FEATURE_EXTRACTOR: \"MaskRCNNFPNFeatureExtractor\"\n",
    "    PREDICTOR: \"MaskRCNNC4Predictor\"\n",
    "    POOLER_RESOLUTION: 14\n",
    "    POOLER_SAMPLING_RATIO: 2\n",
    "    RESOLUTION: 28\n",
    "    SHARE_BOX_FEATURE_EXTRACTOR: False\n",
    "  MASK_ON: True\n",
    "DATALOADER:\n",
    "  SIZE_DIVISIBILITY: 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tAn3omCjTFGI"
   },
   "source": [
    "### Data Loader\n",
    "\n",
    "This function creates a data loader with our shapes dataset. This data loader is used internally in the repo to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oODu2UpVTHXz"
   },
   "outputs": [],
   "source": [
    "def build_data_loader(cfg, dataset, is_train=True, is_distributed=False, start_iter=0):\n",
    "    num_gpus = get_world_size()\n",
    "    if is_train:\n",
    "        images_per_batch = cfg.SOLVER.IMS_PER_BATCH\n",
    "        assert (\n",
    "            images_per_batch % num_gpus == 0\n",
    "        ), \"SOLVER.IMS_PER_BATCH ({}) must be divisible by the number of GPUs ({}) used.\".format(\n",
    "            images_per_batch, num_gpus)\n",
    "        images_per_gpu = images_per_batch // num_gpus\n",
    "        shuffle = True\n",
    "        num_iters = cfg.SOLVER.MAX_ITER\n",
    "    else:\n",
    "        images_per_batch = cfg.TEST.IMS_PER_BATCH\n",
    "        assert (\n",
    "            images_per_batch % num_gpus == 0\n",
    "        ), \"TEST.IMS_PER_BATCH ({}) must be divisible by the number of GPUs ({}) used.\".format(\n",
    "            images_per_batch, num_gpus)\n",
    "        images_per_gpu = images_per_batch // num_gpus\n",
    "        shuffle = False if not is_distributed else True\n",
    "        num_iters = None\n",
    "        start_iter = 0\n",
    "\n",
    "    if images_per_gpu > 1:\n",
    "        logger = logging.getLogger(__name__)\n",
    "        logger.warning(\n",
    "            \"When using more than one image per GPU you may encounter \"\n",
    "            \"an out-of-memory (OOM) error if your GPU does not have \"\n",
    "            \"sufficient memory. If this happens, you can reduce \"\n",
    "            \"SOLVER.IMS_PER_BATCH (for training) or \"\n",
    "            \"TEST.IMS_PER_BATCH (for inference). For training, you must \"\n",
    "            \"also adjust the learning rate and schedule length according \"\n",
    "            \"to the linear scaling rule. See for example: \"\n",
    "            \"https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\"\n",
    "        )\n",
    "\n",
    "    # group images which have similar aspect ratio. In this case, we only\n",
    "    # group in two cases: those with width / height > 1, and the other way around,\n",
    "    # but the code supports more general grouping strategy\n",
    "    aspect_grouping = [1] if cfg.DATALOADER.ASPECT_RATIO_GROUPING else []\n",
    "\n",
    "    paths_catalog = import_file(\n",
    "        \"maskrcnn_benchmark.config.paths_catalog\", cfg.PATHS_CATALOG, True\n",
    "    )\n",
    "    DatasetCatalog = paths_catalog.DatasetCatalog\n",
    "    dataset_list = cfg.DATASETS.TRAIN if is_train else cfg.DATASETS.TEST\n",
    "    print('dataset_list: ', dataset_list)\n",
    "    \n",
    "    # If bbox aug is enabled in testing, simply set transforms to None and we will apply transforms later\n",
    "    transforms = None if not is_train and cfg.TEST.BBOX_AUG.ENABLED else build_transforms(cfg, is_train)\n",
    "    \n",
    "    dataset.transforms = transforms\n",
    "    datasets = [ dataset ]\n",
    "    \n",
    "    data_loaders = []\n",
    "    for dataset in datasets:\n",
    "        sampler = make_data_sampler(dataset, shuffle, is_distributed)\n",
    "        batch_sampler = make_batch_data_sampler(\n",
    "            dataset, sampler, aspect_grouping, images_per_gpu, num_iters, start_iter\n",
    "        )\n",
    "        collator = BBoxAugCollator() if not is_train and cfg.TEST.BBOX_AUG.ENABLED else \\\n",
    "            BatchCollator(cfg.DATALOADER.SIZE_DIVISIBILITY)\n",
    "        num_workers = cfg.DATALOADER.NUM_WORKERS\n",
    "        data_loader = torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            num_workers=num_workers,\n",
    "            batch_sampler=batch_sampler,\n",
    "            collate_fn=collator,\n",
    "        )\n",
    "        data_loaders.append(data_loader)\n",
    "    if is_train:\n",
    "        # during training, a single (possibly concatenated) data_loader is returned\n",
    "        assert len(data_loaders) == 1\n",
    "        return data_loaders[0]\n",
    "    return data_loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BTKsrHa-TkGr"
   },
   "source": [
    "### Train Function\n",
    "\n",
    "The train function is the entry point into the training process. It creates data loaders, optimisers, loads from checkpoint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LYTguCvrTnHW"
   },
   "outputs": [],
   "source": [
    "# See if we can use apex.DistributedDataParallel instead of the torch default,\n",
    "# and enable mixed-precision via apex.amp\n",
    "try:\n",
    "    from apex import amp\n",
    "except ImportError:\n",
    "    raise ImportError('Use APEX for multi-precision via apex.amp')\n",
    "\n",
    "def train(cfg, local_rank, distributed, dataset):\n",
    "    model = build_detection_model(cfg)\n",
    "    device = torch.device('cuda')\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = make_optimizer(cfg, model)\n",
    "    scheduler = make_lr_scheduler(cfg, optimizer)\n",
    "\n",
    "    # Initialize mixed-precision training\n",
    "    use_mixed_precision = cfg.DTYPE == \"float16\"\n",
    "    amp_opt_level = 'O1' if use_mixed_precision else 'O0'\n",
    "    model, optimizer = amp.initialize(model, optimizer, opt_level=amp_opt_level)\n",
    "\n",
    "    if distributed:\n",
    "        model = torch.nn.parallel.DistributedDataParallel(\n",
    "            model, device_ids=[local_rank], output_device=local_rank,\n",
    "            # this should be removed if we update BatchNorm stats\n",
    "            broadcast_buffers=False,\n",
    "        )\n",
    "\n",
    "    arguments = {}\n",
    "    arguments[\"iteration\"] = 0\n",
    "\n",
    "    output_dir = cfg.OUTPUT_DIR\n",
    "    save_to_disk = get_rank() == 0\n",
    "    checkpointer = DetectronCheckpointer(\n",
    "        cfg, model, optimizer, scheduler, output_dir, save_to_disk\n",
    "    )\n",
    "    extra_checkpoint_data = checkpointer.load(cfg.MODEL.WEIGHT)\n",
    "    arguments.update(extra_checkpoint_data)\n",
    "\n",
    "\n",
    "    data_loader = build_data_loader(cfg, dataset)\n",
    "\n",
    "    checkpoint_period = cfg.SOLVER.CHECKPOINT_PERIOD\n",
    "\n",
    "    do_train(\n",
    "        model,\n",
    "        data_loader,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        checkpointer,\n",
    "        device,\n",
    "        checkpoint_period,\n",
    "        arguments,\n",
    "    )\n",
    "\n",
    "    return model# See if we can use apex.DistributedDataParallel instead of the torch default,\n",
    "# and enable mixed-precision via apex.amp\n",
    "try:\n",
    "    from apex import amp\n",
    "except ImportError:\n",
    "    raise ImportError('Use APEX for multi-precision via apex.amp')\n",
    "\n",
    "def train(cfg, local_rank, distributed, dataset):\n",
    "    model = build_detection_model(cfg)\n",
    "    device = torch.device('cuda')\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = make_optimizer(cfg, model)\n",
    "    scheduler = make_lr_scheduler(cfg, optimizer)\n",
    "\n",
    "    # Initialize mixed-precision training\n",
    "    use_mixed_precision = cfg.DTYPE == \"float16\"\n",
    "    amp_opt_level = 'O1' if use_mixed_precision else 'O0'\n",
    "    model, optimizer = amp.initialize(model, optimizer, opt_level=amp_opt_level)\n",
    "\n",
    "    if distributed:\n",
    "        model = torch.nn.parallel.DistributedDataParallel(\n",
    "            model, device_ids=[local_rank], output_device=local_rank,\n",
    "            # this should be removed if we update BatchNorm stats\n",
    "            broadcast_buffers=False,\n",
    "        )\n",
    "\n",
    "    arguments = {}\n",
    "    arguments[\"iteration\"] = 0\n",
    "\n",
    "    output_dir = cfg.OUTPUT_DIR\n",
    "    save_to_disk = get_rank() == 0\n",
    "    checkpointer = DetectronCheckpointer(\n",
    "        cfg, model, optimizer, scheduler, output_dir, save_to_disk\n",
    "    )\n",
    "    extra_checkpoint_data = checkpointer.load(cfg.MODEL.WEIGHT)\n",
    "    arguments.update(extra_checkpoint_data)\n",
    "\n",
    "\n",
    "    data_loader = build_data_loader(cfg, dataset)\n",
    "\n",
    "    checkpoint_period = cfg.SOLVER.CHECKPOINT_PERIOD\n",
    "\n",
    "    do_train(\n",
    "        model,\n",
    "        data_loader,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        checkpointer,\n",
    "        device,\n",
    "        checkpoint_period,\n",
    "        arguments,\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r-SfVh-qCmhe"
   },
   "source": [
    "## Set training config and train\n",
    "\n",
    "here we fire off training by calling the above function. before that we set some important config for our training. We make our dataset and update our config. Then we fire off training !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 6735
    },
    "colab_type": "code",
    "id": "ad0VIyZqVDXy",
    "outputId": "3b5a93ff-9203-4530-fc86-de557fe4428c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Selected optimization level O0:  Pure FP32 training.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O0\n",
      "cast_model_type        : torch.float32\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : False\n",
      "loss_scale             : 1.0\n",
      "2019-06-28 12:08:34,296 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from base_model.pth\n",
      "2019-06-28 12:08:34,354 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.bias                   loaded from backbone.body.layer1.0.bn1.bias                   of shape (64,)\n",
      "2019-06-28 12:08:34,355 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.running_mean           loaded from backbone.body.layer1.0.bn1.running_mean           of shape (64,)\n",
      "2019-06-28 12:08:34,356 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.running_var            loaded from backbone.body.layer1.0.bn1.running_var            of shape (64,)\n",
      "2019-06-28 12:08:34,357 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn1.weight                 loaded from backbone.body.layer1.0.bn1.weight                 of shape (64,)\n",
      "2019-06-28 12:08:34,357 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.bias                   loaded from backbone.body.layer1.0.bn2.bias                   of shape (64,)\n",
      "2019-06-28 12:08:34,358 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.running_mean           loaded from backbone.body.layer1.0.bn2.running_mean           of shape (64,)\n",
      "2019-06-28 12:08:34,359 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.running_var            loaded from backbone.body.layer1.0.bn2.running_var            of shape (64,)\n",
      "2019-06-28 12:08:34,359 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn2.weight                 loaded from backbone.body.layer1.0.bn2.weight                 of shape (64,)\n",
      "2019-06-28 12:08:34,360 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.bias                   loaded from backbone.body.layer1.0.bn3.bias                   of shape (256,)\n",
      "2019-06-28 12:08:34,361 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.running_mean           loaded from backbone.body.layer1.0.bn3.running_mean           of shape (256,)\n",
      "2019-06-28 12:08:34,361 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.running_var            loaded from backbone.body.layer1.0.bn3.running_var            of shape (256,)\n",
      "2019-06-28 12:08:34,362 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.bn3.weight                 loaded from backbone.body.layer1.0.bn3.weight                 of shape (256,)\n",
      "2019-06-28 12:08:34,362 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv1.weight               loaded from backbone.body.layer1.0.conv1.weight               of shape (64, 64, 1, 1)\n",
      "2019-06-28 12:08:34,363 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv2.weight               loaded from backbone.body.layer1.0.conv2.weight               of shape (64, 64, 3, 3)\n",
      "2019-06-28 12:08:34,363 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.conv3.weight               loaded from backbone.body.layer1.0.conv3.weight               of shape (256, 64, 1, 1)\n",
      "2019-06-28 12:08:34,364 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.0.weight        loaded from backbone.body.layer1.0.downsample.0.weight        of shape (256, 64, 1, 1)\n",
      "2019-06-28 12:08:34,364 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.bias          loaded from backbone.body.layer1.0.downsample.1.bias          of shape (256,)\n",
      "2019-06-28 12:08:34,365 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.running_mean  loaded from backbone.body.layer1.0.downsample.1.running_mean  of shape (256,)\n",
      "2019-06-28 12:08:34,365 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.running_var   loaded from backbone.body.layer1.0.downsample.1.running_var   of shape (256,)\n",
      "2019-06-28 12:08:34,366 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.weight        loaded from backbone.body.layer1.0.downsample.1.weight        of shape (256,)\n",
      "2019-06-28 12:08:34,366 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.bias                   loaded from backbone.body.layer1.1.bn1.bias                   of shape (64,)\n",
      "2019-06-28 12:08:34,367 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.running_mean           loaded from backbone.body.layer1.1.bn1.running_mean           of shape (64,)\n",
      "2019-06-28 12:08:34,368 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.running_var            loaded from backbone.body.layer1.1.bn1.running_var            of shape (64,)\n",
      "2019-06-28 12:08:34,368 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn1.weight                 loaded from backbone.body.layer1.1.bn1.weight                 of shape (64,)\n",
      "2019-06-28 12:08:34,369 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.bias                   loaded from backbone.body.layer1.1.bn2.bias                   of shape (64,)\n",
      "2019-06-28 12:08:34,370 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.running_mean           loaded from backbone.body.layer1.1.bn2.running_mean           of shape (64,)\n",
      "2019-06-28 12:08:34,370 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.running_var            loaded from backbone.body.layer1.1.bn2.running_var            of shape (64,)\n",
      "2019-06-28 12:08:34,372 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn2.weight                 loaded from backbone.body.layer1.1.bn2.weight                 of shape (64,)\n",
      "2019-06-28 12:08:34,373 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.bias                   loaded from backbone.body.layer1.1.bn3.bias                   of shape (256,)\n",
      "2019-06-28 12:08:34,375 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.running_mean           loaded from backbone.body.layer1.1.bn3.running_mean           of shape (256,)\n",
      "2019-06-28 12:08:34,377 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.running_var            loaded from backbone.body.layer1.1.bn3.running_var            of shape (256,)\n",
      "2019-06-28 12:08:34,378 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.bn3.weight                 loaded from backbone.body.layer1.1.bn3.weight                 of shape (256,)\n",
      "2019-06-28 12:08:34,379 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv1.weight               loaded from backbone.body.layer1.1.conv1.weight               of shape (64, 256, 1, 1)\n",
      "2019-06-28 12:08:34,380 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv2.weight               loaded from backbone.body.layer1.1.conv2.weight               of shape (64, 64, 3, 3)\n",
      "2019-06-28 12:08:34,380 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.1.conv3.weight               loaded from backbone.body.layer1.1.conv3.weight               of shape (256, 64, 1, 1)\n",
      "2019-06-28 12:08:34,382 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.bias                   loaded from backbone.body.layer1.2.bn1.bias                   of shape (64,)\n",
      "2019-06-28 12:08:34,383 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.running_mean           loaded from backbone.body.layer1.2.bn1.running_mean           of shape (64,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-28 12:08:34,384 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.running_var            loaded from backbone.body.layer1.2.bn1.running_var            of shape (64,)\n",
      "2019-06-28 12:08:34,385 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn1.weight                 loaded from backbone.body.layer1.2.bn1.weight                 of shape (64,)\n",
      "2019-06-28 12:08:34,386 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.bias                   loaded from backbone.body.layer1.2.bn2.bias                   of shape (64,)\n",
      "2019-06-28 12:08:34,386 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.running_mean           loaded from backbone.body.layer1.2.bn2.running_mean           of shape (64,)\n",
      "2019-06-28 12:08:34,387 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.running_var            loaded from backbone.body.layer1.2.bn2.running_var            of shape (64,)\n",
      "2019-06-28 12:08:34,388 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn2.weight                 loaded from backbone.body.layer1.2.bn2.weight                 of shape (64,)\n",
      "2019-06-28 12:08:34,389 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.bias                   loaded from backbone.body.layer1.2.bn3.bias                   of shape (256,)\n",
      "2019-06-28 12:08:34,389 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.running_mean           loaded from backbone.body.layer1.2.bn3.running_mean           of shape (256,)\n",
      "2019-06-28 12:08:34,390 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.running_var            loaded from backbone.body.layer1.2.bn3.running_var            of shape (256,)\n",
      "2019-06-28 12:08:34,390 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.bn3.weight                 loaded from backbone.body.layer1.2.bn3.weight                 of shape (256,)\n",
      "2019-06-28 12:08:34,392 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv1.weight               loaded from backbone.body.layer1.2.conv1.weight               of shape (64, 256, 1, 1)\n",
      "2019-06-28 12:08:34,392 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv2.weight               loaded from backbone.body.layer1.2.conv2.weight               of shape (64, 64, 3, 3)\n",
      "2019-06-28 12:08:34,393 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer1.2.conv3.weight               loaded from backbone.body.layer1.2.conv3.weight               of shape (256, 64, 1, 1)\n",
      "2019-06-28 12:08:34,394 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.bias                   loaded from backbone.body.layer2.0.bn1.bias                   of shape (128,)\n",
      "2019-06-28 12:08:34,394 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.running_mean           loaded from backbone.body.layer2.0.bn1.running_mean           of shape (128,)\n",
      "2019-06-28 12:08:34,396 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.running_var            loaded from backbone.body.layer2.0.bn1.running_var            of shape (128,)\n",
      "2019-06-28 12:08:34,396 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn1.weight                 loaded from backbone.body.layer2.0.bn1.weight                 of shape (128,)\n",
      "2019-06-28 12:08:34,397 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.bias                   loaded from backbone.body.layer2.0.bn2.bias                   of shape (128,)\n",
      "2019-06-28 12:08:34,398 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.running_mean           loaded from backbone.body.layer2.0.bn2.running_mean           of shape (128,)\n",
      "2019-06-28 12:08:34,399 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.running_var            loaded from backbone.body.layer2.0.bn2.running_var            of shape (128,)\n",
      "2019-06-28 12:08:34,400 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn2.weight                 loaded from backbone.body.layer2.0.bn2.weight                 of shape (128,)\n",
      "2019-06-28 12:08:34,400 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.bias                   loaded from backbone.body.layer2.0.bn3.bias                   of shape (512,)\n",
      "2019-06-28 12:08:34,401 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.running_mean           loaded from backbone.body.layer2.0.bn3.running_mean           of shape (512,)\n",
      "2019-06-28 12:08:34,402 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.running_var            loaded from backbone.body.layer2.0.bn3.running_var            of shape (512,)\n",
      "2019-06-28 12:08:34,403 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.bn3.weight                 loaded from backbone.body.layer2.0.bn3.weight                 of shape (512,)\n",
      "2019-06-28 12:08:34,403 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv1.weight               loaded from backbone.body.layer2.0.conv1.weight               of shape (128, 256, 1, 1)\n",
      "2019-06-28 12:08:34,404 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv2.weight               loaded from backbone.body.layer2.0.conv2.weight               of shape (128, 128, 3, 3)\n",
      "2019-06-28 12:08:34,405 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.conv3.weight               loaded from backbone.body.layer2.0.conv3.weight               of shape (512, 128, 1, 1)\n",
      "2019-06-28 12:08:34,406 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.0.weight        loaded from backbone.body.layer2.0.downsample.0.weight        of shape (512, 256, 1, 1)\n",
      "2019-06-28 12:08:34,407 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.bias          loaded from backbone.body.layer2.0.downsample.1.bias          of shape (512,)\n",
      "2019-06-28 12:08:34,407 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.running_mean  loaded from backbone.body.layer2.0.downsample.1.running_mean  of shape (512,)\n",
      "2019-06-28 12:08:34,409 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.running_var   loaded from backbone.body.layer2.0.downsample.1.running_var   of shape (512,)\n",
      "2019-06-28 12:08:34,409 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.weight        loaded from backbone.body.layer2.0.downsample.1.weight        of shape (512,)\n",
      "2019-06-28 12:08:34,410 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.bias                   loaded from backbone.body.layer2.1.bn1.bias                   of shape (128,)\n",
      "2019-06-28 12:08:34,411 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.running_mean           loaded from backbone.body.layer2.1.bn1.running_mean           of shape (128,)\n",
      "2019-06-28 12:08:34,412 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.running_var            loaded from backbone.body.layer2.1.bn1.running_var            of shape (128,)\n",
      "2019-06-28 12:08:34,413 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn1.weight                 loaded from backbone.body.layer2.1.bn1.weight                 of shape (128,)\n",
      "2019-06-28 12:08:34,415 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.bias                   loaded from backbone.body.layer2.1.bn2.bias                   of shape (128,)\n",
      "2019-06-28 12:08:34,415 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.running_mean           loaded from backbone.body.layer2.1.bn2.running_mean           of shape (128,)\n",
      "2019-06-28 12:08:34,416 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.running_var            loaded from backbone.body.layer2.1.bn2.running_var            of shape (128,)\n",
      "2019-06-28 12:08:34,418 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn2.weight                 loaded from backbone.body.layer2.1.bn2.weight                 of shape (128,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-28 12:08:34,419 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.bias                   loaded from backbone.body.layer2.1.bn3.bias                   of shape (512,)\n",
      "2019-06-28 12:08:34,419 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.running_mean           loaded from backbone.body.layer2.1.bn3.running_mean           of shape (512,)\n",
      "2019-06-28 12:08:34,422 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.running_var            loaded from backbone.body.layer2.1.bn3.running_var            of shape (512,)\n",
      "2019-06-28 12:08:34,423 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.bn3.weight                 loaded from backbone.body.layer2.1.bn3.weight                 of shape (512,)\n",
      "2019-06-28 12:08:34,425 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv1.weight               loaded from backbone.body.layer2.1.conv1.weight               of shape (128, 512, 1, 1)\n",
      "2019-06-28 12:08:34,427 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv2.weight               loaded from backbone.body.layer2.1.conv2.weight               of shape (128, 128, 3, 3)\n",
      "2019-06-28 12:08:34,428 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.1.conv3.weight               loaded from backbone.body.layer2.1.conv3.weight               of shape (512, 128, 1, 1)\n",
      "2019-06-28 12:08:34,429 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.bias                   loaded from backbone.body.layer2.2.bn1.bias                   of shape (128,)\n",
      "2019-06-28 12:08:34,430 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.running_mean           loaded from backbone.body.layer2.2.bn1.running_mean           of shape (128,)\n",
      "2019-06-28 12:08:34,432 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.running_var            loaded from backbone.body.layer2.2.bn1.running_var            of shape (128,)\n",
      "2019-06-28 12:08:34,433 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn1.weight                 loaded from backbone.body.layer2.2.bn1.weight                 of shape (128,)\n",
      "2019-06-28 12:08:34,433 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.bias                   loaded from backbone.body.layer2.2.bn2.bias                   of shape (128,)\n",
      "2019-06-28 12:08:34,434 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.running_mean           loaded from backbone.body.layer2.2.bn2.running_mean           of shape (128,)\n",
      "2019-06-28 12:08:34,435 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.running_var            loaded from backbone.body.layer2.2.bn2.running_var            of shape (128,)\n",
      "2019-06-28 12:08:34,437 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn2.weight                 loaded from backbone.body.layer2.2.bn2.weight                 of shape (128,)\n",
      "2019-06-28 12:08:34,438 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.bias                   loaded from backbone.body.layer2.2.bn3.bias                   of shape (512,)\n",
      "2019-06-28 12:08:34,439 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.running_mean           loaded from backbone.body.layer2.2.bn3.running_mean           of shape (512,)\n",
      "2019-06-28 12:08:34,439 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.running_var            loaded from backbone.body.layer2.2.bn3.running_var            of shape (512,)\n",
      "2019-06-28 12:08:34,440 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.bn3.weight                 loaded from backbone.body.layer2.2.bn3.weight                 of shape (512,)\n",
      "2019-06-28 12:08:34,441 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv1.weight               loaded from backbone.body.layer2.2.conv1.weight               of shape (128, 512, 1, 1)\n",
      "2019-06-28 12:08:34,442 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv2.weight               loaded from backbone.body.layer2.2.conv2.weight               of shape (128, 128, 3, 3)\n",
      "2019-06-28 12:08:34,443 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.2.conv3.weight               loaded from backbone.body.layer2.2.conv3.weight               of shape (512, 128, 1, 1)\n",
      "2019-06-28 12:08:34,443 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.bias                   loaded from backbone.body.layer2.3.bn1.bias                   of shape (128,)\n",
      "2019-06-28 12:08:34,445 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.running_mean           loaded from backbone.body.layer2.3.bn1.running_mean           of shape (128,)\n",
      "2019-06-28 12:08:34,446 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.running_var            loaded from backbone.body.layer2.3.bn1.running_var            of shape (128,)\n",
      "2019-06-28 12:08:34,446 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn1.weight                 loaded from backbone.body.layer2.3.bn1.weight                 of shape (128,)\n",
      "2019-06-28 12:08:34,447 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.bias                   loaded from backbone.body.layer2.3.bn2.bias                   of shape (128,)\n",
      "2019-06-28 12:08:34,448 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.running_mean           loaded from backbone.body.layer2.3.bn2.running_mean           of shape (128,)\n",
      "2019-06-28 12:08:34,449 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.running_var            loaded from backbone.body.layer2.3.bn2.running_var            of shape (128,)\n",
      "2019-06-28 12:08:34,450 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn2.weight                 loaded from backbone.body.layer2.3.bn2.weight                 of shape (128,)\n",
      "2019-06-28 12:08:34,451 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.bias                   loaded from backbone.body.layer2.3.bn3.bias                   of shape (512,)\n",
      "2019-06-28 12:08:34,452 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.running_mean           loaded from backbone.body.layer2.3.bn3.running_mean           of shape (512,)\n",
      "2019-06-28 12:08:34,453 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.running_var            loaded from backbone.body.layer2.3.bn3.running_var            of shape (512,)\n",
      "2019-06-28 12:08:34,453 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.bn3.weight                 loaded from backbone.body.layer2.3.bn3.weight                 of shape (512,)\n",
      "2019-06-28 12:08:34,455 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv1.weight               loaded from backbone.body.layer2.3.conv1.weight               of shape (128, 512, 1, 1)\n",
      "2019-06-28 12:08:34,456 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv2.weight               loaded from backbone.body.layer2.3.conv2.weight               of shape (128, 128, 3, 3)\n",
      "2019-06-28 12:08:34,457 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer2.3.conv3.weight               loaded from backbone.body.layer2.3.conv3.weight               of shape (512, 128, 1, 1)\n",
      "2019-06-28 12:08:34,457 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.bias                   loaded from backbone.body.layer3.0.bn1.bias                   of shape (256,)\n",
      "2019-06-28 12:08:34,458 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.running_mean           loaded from backbone.body.layer3.0.bn1.running_mean           of shape (256,)\n",
      "2019-06-28 12:08:34,459 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.running_var            loaded from backbone.body.layer3.0.bn1.running_var            of shape (256,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-28 12:08:34,460 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn1.weight                 loaded from backbone.body.layer3.0.bn1.weight                 of shape (256,)\n",
      "2019-06-28 12:08:34,461 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.bias                   loaded from backbone.body.layer3.0.bn2.bias                   of shape (256,)\n",
      "2019-06-28 12:08:34,464 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.running_mean           loaded from backbone.body.layer3.0.bn2.running_mean           of shape (256,)\n",
      "2019-06-28 12:08:34,465 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.running_var            loaded from backbone.body.layer3.0.bn2.running_var            of shape (256,)\n",
      "2019-06-28 12:08:34,465 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn2.weight                 loaded from backbone.body.layer3.0.bn2.weight                 of shape (256,)\n",
      "2019-06-28 12:08:34,467 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.bias                   loaded from backbone.body.layer3.0.bn3.bias                   of shape (1024,)\n",
      "2019-06-28 12:08:34,467 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.running_mean           loaded from backbone.body.layer3.0.bn3.running_mean           of shape (1024,)\n",
      "2019-06-28 12:08:34,468 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.running_var            loaded from backbone.body.layer3.0.bn3.running_var            of shape (1024,)\n",
      "2019-06-28 12:08:34,470 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.bn3.weight                 loaded from backbone.body.layer3.0.bn3.weight                 of shape (1024,)\n",
      "2019-06-28 12:08:34,470 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv1.weight               loaded from backbone.body.layer3.0.conv1.weight               of shape (256, 512, 1, 1)\n",
      "2019-06-28 12:08:34,471 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv2.weight               loaded from backbone.body.layer3.0.conv2.weight               of shape (256, 256, 3, 3)\n",
      "2019-06-28 12:08:34,472 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.conv3.weight               loaded from backbone.body.layer3.0.conv3.weight               of shape (1024, 256, 1, 1)\n",
      "2019-06-28 12:08:34,472 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.0.weight        loaded from backbone.body.layer3.0.downsample.0.weight        of shape (1024, 512, 1, 1)\n",
      "2019-06-28 12:08:34,473 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.bias          loaded from backbone.body.layer3.0.downsample.1.bias          of shape (1024,)\n",
      "2019-06-28 12:08:34,474 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.running_mean  loaded from backbone.body.layer3.0.downsample.1.running_mean  of shape (1024,)\n",
      "2019-06-28 12:08:34,475 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.running_var   loaded from backbone.body.layer3.0.downsample.1.running_var   of shape (1024,)\n",
      "2019-06-28 12:08:34,476 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.weight        loaded from backbone.body.layer3.0.downsample.1.weight        of shape (1024,)\n",
      "2019-06-28 12:08:34,476 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.bias                   loaded from backbone.body.layer3.1.bn1.bias                   of shape (256,)\n",
      "2019-06-28 12:08:34,477 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.running_mean           loaded from backbone.body.layer3.1.bn1.running_mean           of shape (256,)\n",
      "2019-06-28 12:08:34,478 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.running_var            loaded from backbone.body.layer3.1.bn1.running_var            of shape (256,)\n",
      "2019-06-28 12:08:34,479 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn1.weight                 loaded from backbone.body.layer3.1.bn1.weight                 of shape (256,)\n",
      "2019-06-28 12:08:34,481 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.bias                   loaded from backbone.body.layer3.1.bn2.bias                   of shape (256,)\n",
      "2019-06-28 12:08:34,482 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.running_mean           loaded from backbone.body.layer3.1.bn2.running_mean           of shape (256,)\n",
      "2019-06-28 12:08:34,482 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.running_var            loaded from backbone.body.layer3.1.bn2.running_var            of shape (256,)\n",
      "2019-06-28 12:08:34,483 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn2.weight                 loaded from backbone.body.layer3.1.bn2.weight                 of shape (256,)\n",
      "2019-06-28 12:08:34,484 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.bias                   loaded from backbone.body.layer3.1.bn3.bias                   of shape (1024,)\n",
      "2019-06-28 12:08:34,485 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.running_mean           loaded from backbone.body.layer3.1.bn3.running_mean           of shape (1024,)\n",
      "2019-06-28 12:08:34,489 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.running_var            loaded from backbone.body.layer3.1.bn3.running_var            of shape (1024,)\n",
      "2019-06-28 12:08:34,491 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.bn3.weight                 loaded from backbone.body.layer3.1.bn3.weight                 of shape (1024,)\n",
      "2019-06-28 12:08:34,491 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv1.weight               loaded from backbone.body.layer3.1.conv1.weight               of shape (256, 1024, 1, 1)\n",
      "2019-06-28 12:08:34,493 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv2.weight               loaded from backbone.body.layer3.1.conv2.weight               of shape (256, 256, 3, 3)\n",
      "2019-06-28 12:08:34,493 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.1.conv3.weight               loaded from backbone.body.layer3.1.conv3.weight               of shape (1024, 256, 1, 1)\n",
      "2019-06-28 12:08:34,494 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.bias                   loaded from backbone.body.layer3.2.bn1.bias                   of shape (256,)\n",
      "2019-06-28 12:08:34,495 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.running_mean           loaded from backbone.body.layer3.2.bn1.running_mean           of shape (256,)\n",
      "2019-06-28 12:08:34,499 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.running_var            loaded from backbone.body.layer3.2.bn1.running_var            of shape (256,)\n",
      "2019-06-28 12:08:34,500 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn1.weight                 loaded from backbone.body.layer3.2.bn1.weight                 of shape (256,)\n",
      "2019-06-28 12:08:34,501 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.bias                   loaded from backbone.body.layer3.2.bn2.bias                   of shape (256,)\n",
      "2019-06-28 12:08:34,502 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.running_mean           loaded from backbone.body.layer3.2.bn2.running_mean           of shape (256,)\n",
      "2019-06-28 12:08:34,503 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.running_var            loaded from backbone.body.layer3.2.bn2.running_var            of shape (256,)\n",
      "2019-06-28 12:08:34,505 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn2.weight                 loaded from backbone.body.layer3.2.bn2.weight                 of shape (256,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-28 12:08:34,506 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.bias                   loaded from backbone.body.layer3.2.bn3.bias                   of shape (1024,)\n",
      "2019-06-28 12:08:34,507 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.running_mean           loaded from backbone.body.layer3.2.bn3.running_mean           of shape (1024,)\n",
      "2019-06-28 12:08:34,508 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.running_var            loaded from backbone.body.layer3.2.bn3.running_var            of shape (1024,)\n",
      "2019-06-28 12:08:34,509 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.bn3.weight                 loaded from backbone.body.layer3.2.bn3.weight                 of shape (1024,)\n",
      "2019-06-28 12:08:34,509 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv1.weight               loaded from backbone.body.layer3.2.conv1.weight               of shape (256, 1024, 1, 1)\n",
      "2019-06-28 12:08:34,511 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv2.weight               loaded from backbone.body.layer3.2.conv2.weight               of shape (256, 256, 3, 3)\n",
      "2019-06-28 12:08:34,512 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.2.conv3.weight               loaded from backbone.body.layer3.2.conv3.weight               of shape (1024, 256, 1, 1)\n",
      "2019-06-28 12:08:34,513 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.bias                   loaded from backbone.body.layer3.3.bn1.bias                   of shape (256,)\n",
      "2019-06-28 12:08:34,514 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.running_mean           loaded from backbone.body.layer3.3.bn1.running_mean           of shape (256,)\n",
      "2019-06-28 12:08:34,515 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.running_var            loaded from backbone.body.layer3.3.bn1.running_var            of shape (256,)\n",
      "2019-06-28 12:08:34,516 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn1.weight                 loaded from backbone.body.layer3.3.bn1.weight                 of shape (256,)\n",
      "2019-06-28 12:08:34,517 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.bias                   loaded from backbone.body.layer3.3.bn2.bias                   of shape (256,)\n",
      "2019-06-28 12:08:34,518 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.running_mean           loaded from backbone.body.layer3.3.bn2.running_mean           of shape (256,)\n",
      "2019-06-28 12:08:34,518 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.running_var            loaded from backbone.body.layer3.3.bn2.running_var            of shape (256,)\n",
      "2019-06-28 12:08:34,519 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn2.weight                 loaded from backbone.body.layer3.3.bn2.weight                 of shape (256,)\n",
      "2019-06-28 12:08:34,520 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.bias                   loaded from backbone.body.layer3.3.bn3.bias                   of shape (1024,)\n",
      "2019-06-28 12:08:34,523 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.running_mean           loaded from backbone.body.layer3.3.bn3.running_mean           of shape (1024,)\n",
      "2019-06-28 12:08:34,524 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.running_var            loaded from backbone.body.layer3.3.bn3.running_var            of shape (1024,)\n",
      "2019-06-28 12:08:34,524 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.bn3.weight                 loaded from backbone.body.layer3.3.bn3.weight                 of shape (1024,)\n",
      "2019-06-28 12:08:34,525 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv1.weight               loaded from backbone.body.layer3.3.conv1.weight               of shape (256, 1024, 1, 1)\n",
      "2019-06-28 12:08:34,526 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv2.weight               loaded from backbone.body.layer3.3.conv2.weight               of shape (256, 256, 3, 3)\n",
      "2019-06-28 12:08:34,527 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.3.conv3.weight               loaded from backbone.body.layer3.3.conv3.weight               of shape (1024, 256, 1, 1)\n",
      "2019-06-28 12:08:34,527 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.bias                   loaded from backbone.body.layer3.4.bn1.bias                   of shape (256,)\n",
      "2019-06-28 12:08:34,528 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.running_mean           loaded from backbone.body.layer3.4.bn1.running_mean           of shape (256,)\n",
      "2019-06-28 12:08:34,529 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.running_var            loaded from backbone.body.layer3.4.bn1.running_var            of shape (256,)\n",
      "2019-06-28 12:08:34,531 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn1.weight                 loaded from backbone.body.layer3.4.bn1.weight                 of shape (256,)\n",
      "2019-06-28 12:08:34,532 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.bias                   loaded from backbone.body.layer3.4.bn2.bias                   of shape (256,)\n",
      "2019-06-28 12:08:34,533 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.running_mean           loaded from backbone.body.layer3.4.bn2.running_mean           of shape (256,)\n",
      "2019-06-28 12:08:34,535 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.running_var            loaded from backbone.body.layer3.4.bn2.running_var            of shape (256,)\n",
      "2019-06-28 12:08:34,536 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn2.weight                 loaded from backbone.body.layer3.4.bn2.weight                 of shape (256,)\n",
      "2019-06-28 12:08:34,537 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.bias                   loaded from backbone.body.layer3.4.bn3.bias                   of shape (1024,)\n",
      "2019-06-28 12:08:34,538 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.running_mean           loaded from backbone.body.layer3.4.bn3.running_mean           of shape (1024,)\n",
      "2019-06-28 12:08:34,539 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.running_var            loaded from backbone.body.layer3.4.bn3.running_var            of shape (1024,)\n",
      "2019-06-28 12:08:34,540 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.bn3.weight                 loaded from backbone.body.layer3.4.bn3.weight                 of shape (1024,)\n",
      "2019-06-28 12:08:34,541 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv1.weight               loaded from backbone.body.layer3.4.conv1.weight               of shape (256, 1024, 1, 1)\n",
      "2019-06-28 12:08:34,543 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv2.weight               loaded from backbone.body.layer3.4.conv2.weight               of shape (256, 256, 3, 3)\n",
      "2019-06-28 12:08:34,543 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.4.conv3.weight               loaded from backbone.body.layer3.4.conv3.weight               of shape (1024, 256, 1, 1)\n",
      "2019-06-28 12:08:34,545 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.bias                   loaded from backbone.body.layer3.5.bn1.bias                   of shape (256,)\n",
      "2019-06-28 12:08:34,547 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.running_mean           loaded from backbone.body.layer3.5.bn1.running_mean           of shape (256,)\n",
      "2019-06-28 12:08:34,549 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.running_var            loaded from backbone.body.layer3.5.bn1.running_var            of shape (256,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-28 12:08:34,550 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn1.weight                 loaded from backbone.body.layer3.5.bn1.weight                 of shape (256,)\n",
      "2019-06-28 12:08:34,551 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.bias                   loaded from backbone.body.layer3.5.bn2.bias                   of shape (256,)\n",
      "2019-06-28 12:08:34,552 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.running_mean           loaded from backbone.body.layer3.5.bn2.running_mean           of shape (256,)\n",
      "2019-06-28 12:08:34,553 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.running_var            loaded from backbone.body.layer3.5.bn2.running_var            of shape (256,)\n",
      "2019-06-28 12:08:34,553 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn2.weight                 loaded from backbone.body.layer3.5.bn2.weight                 of shape (256,)\n",
      "2019-06-28 12:08:34,554 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.bias                   loaded from backbone.body.layer3.5.bn3.bias                   of shape (1024,)\n",
      "2019-06-28 12:08:34,555 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.running_mean           loaded from backbone.body.layer3.5.bn3.running_mean           of shape (1024,)\n",
      "2019-06-28 12:08:34,556 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.running_var            loaded from backbone.body.layer3.5.bn3.running_var            of shape (1024,)\n",
      "2019-06-28 12:08:34,557 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.bn3.weight                 loaded from backbone.body.layer3.5.bn3.weight                 of shape (1024,)\n",
      "2019-06-28 12:08:34,558 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv1.weight               loaded from backbone.body.layer3.5.conv1.weight               of shape (256, 1024, 1, 1)\n",
      "2019-06-28 12:08:34,559 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv2.weight               loaded from backbone.body.layer3.5.conv2.weight               of shape (256, 256, 3, 3)\n",
      "2019-06-28 12:08:34,560 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer3.5.conv3.weight               loaded from backbone.body.layer3.5.conv3.weight               of shape (1024, 256, 1, 1)\n",
      "2019-06-28 12:08:34,561 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.bias                   loaded from backbone.body.layer4.0.bn1.bias                   of shape (512,)\n",
      "2019-06-28 12:08:34,562 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.running_mean           loaded from backbone.body.layer4.0.bn1.running_mean           of shape (512,)\n",
      "2019-06-28 12:08:34,563 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.running_var            loaded from backbone.body.layer4.0.bn1.running_var            of shape (512,)\n",
      "2019-06-28 12:08:34,563 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn1.weight                 loaded from backbone.body.layer4.0.bn1.weight                 of shape (512,)\n",
      "2019-06-28 12:08:34,564 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.bias                   loaded from backbone.body.layer4.0.bn2.bias                   of shape (512,)\n",
      "2019-06-28 12:08:34,564 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.running_mean           loaded from backbone.body.layer4.0.bn2.running_mean           of shape (512,)\n",
      "2019-06-28 12:08:34,565 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.running_var            loaded from backbone.body.layer4.0.bn2.running_var            of shape (512,)\n",
      "2019-06-28 12:08:34,565 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn2.weight                 loaded from backbone.body.layer4.0.bn2.weight                 of shape (512,)\n",
      "2019-06-28 12:08:34,567 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.bias                   loaded from backbone.body.layer4.0.bn3.bias                   of shape (2048,)\n",
      "2019-06-28 12:08:34,567 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.running_mean           loaded from backbone.body.layer4.0.bn3.running_mean           of shape (2048,)\n",
      "2019-06-28 12:08:34,568 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.running_var            loaded from backbone.body.layer4.0.bn3.running_var            of shape (2048,)\n",
      "2019-06-28 12:08:34,569 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.bn3.weight                 loaded from backbone.body.layer4.0.bn3.weight                 of shape (2048,)\n",
      "2019-06-28 12:08:34,570 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv1.weight               loaded from backbone.body.layer4.0.conv1.weight               of shape (512, 1024, 1, 1)\n",
      "2019-06-28 12:08:34,570 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv2.weight               loaded from backbone.body.layer4.0.conv2.weight               of shape (512, 512, 3, 3)\n",
      "2019-06-28 12:08:34,571 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.conv3.weight               loaded from backbone.body.layer4.0.conv3.weight               of shape (2048, 512, 1, 1)\n",
      "2019-06-28 12:08:34,573 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.0.weight        loaded from backbone.body.layer4.0.downsample.0.weight        of shape (2048, 1024, 1, 1)\n",
      "2019-06-28 12:08:34,574 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.bias          loaded from backbone.body.layer4.0.downsample.1.bias          of shape (2048,)\n",
      "2019-06-28 12:08:34,575 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.running_mean  loaded from backbone.body.layer4.0.downsample.1.running_mean  of shape (2048,)\n",
      "2019-06-28 12:08:34,576 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.running_var   loaded from backbone.body.layer4.0.downsample.1.running_var   of shape (2048,)\n",
      "2019-06-28 12:08:34,577 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.weight        loaded from backbone.body.layer4.0.downsample.1.weight        of shape (2048,)\n",
      "2019-06-28 12:08:34,578 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.bias                   loaded from backbone.body.layer4.1.bn1.bias                   of shape (512,)\n",
      "2019-06-28 12:08:34,580 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.running_mean           loaded from backbone.body.layer4.1.bn1.running_mean           of shape (512,)\n",
      "2019-06-28 12:08:34,581 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.running_var            loaded from backbone.body.layer4.1.bn1.running_var            of shape (512,)\n",
      "2019-06-28 12:08:34,582 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn1.weight                 loaded from backbone.body.layer4.1.bn1.weight                 of shape (512,)\n",
      "2019-06-28 12:08:34,583 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.bias                   loaded from backbone.body.layer4.1.bn2.bias                   of shape (512,)\n",
      "2019-06-28 12:08:34,583 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.running_mean           loaded from backbone.body.layer4.1.bn2.running_mean           of shape (512,)\n",
      "2019-06-28 12:08:34,586 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.running_var            loaded from backbone.body.layer4.1.bn2.running_var            of shape (512,)\n",
      "2019-06-28 12:08:34,587 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn2.weight                 loaded from backbone.body.layer4.1.bn2.weight                 of shape (512,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-28 12:08:34,589 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.bias                   loaded from backbone.body.layer4.1.bn3.bias                   of shape (2048,)\n",
      "2019-06-28 12:08:34,590 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.running_mean           loaded from backbone.body.layer4.1.bn3.running_mean           of shape (2048,)\n",
      "2019-06-28 12:08:34,591 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.running_var            loaded from backbone.body.layer4.1.bn3.running_var            of shape (2048,)\n",
      "2019-06-28 12:08:34,592 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.bn3.weight                 loaded from backbone.body.layer4.1.bn3.weight                 of shape (2048,)\n",
      "2019-06-28 12:08:34,593 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv1.weight               loaded from backbone.body.layer4.1.conv1.weight               of shape (512, 2048, 1, 1)\n",
      "2019-06-28 12:08:34,593 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv2.weight               loaded from backbone.body.layer4.1.conv2.weight               of shape (512, 512, 3, 3)\n",
      "2019-06-28 12:08:34,596 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.1.conv3.weight               loaded from backbone.body.layer4.1.conv3.weight               of shape (2048, 512, 1, 1)\n",
      "2019-06-28 12:08:34,597 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.bias                   loaded from backbone.body.layer4.2.bn1.bias                   of shape (512,)\n",
      "2019-06-28 12:08:34,597 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.running_mean           loaded from backbone.body.layer4.2.bn1.running_mean           of shape (512,)\n",
      "2019-06-28 12:08:34,598 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.running_var            loaded from backbone.body.layer4.2.bn1.running_var            of shape (512,)\n",
      "2019-06-28 12:08:34,599 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn1.weight                 loaded from backbone.body.layer4.2.bn1.weight                 of shape (512,)\n",
      "2019-06-28 12:08:34,601 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.bias                   loaded from backbone.body.layer4.2.bn2.bias                   of shape (512,)\n",
      "2019-06-28 12:08:34,602 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.running_mean           loaded from backbone.body.layer4.2.bn2.running_mean           of shape (512,)\n",
      "2019-06-28 12:08:34,603 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.running_var            loaded from backbone.body.layer4.2.bn2.running_var            of shape (512,)\n",
      "2019-06-28 12:08:34,604 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn2.weight                 loaded from backbone.body.layer4.2.bn2.weight                 of shape (512,)\n",
      "2019-06-28 12:08:34,605 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.bias                   loaded from backbone.body.layer4.2.bn3.bias                   of shape (2048,)\n",
      "2019-06-28 12:08:34,606 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.running_mean           loaded from backbone.body.layer4.2.bn3.running_mean           of shape (2048,)\n",
      "2019-06-28 12:08:34,607 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.running_var            loaded from backbone.body.layer4.2.bn3.running_var            of shape (2048,)\n",
      "2019-06-28 12:08:34,608 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.bn3.weight                 loaded from backbone.body.layer4.2.bn3.weight                 of shape (2048,)\n",
      "2019-06-28 12:08:34,609 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv1.weight               loaded from backbone.body.layer4.2.conv1.weight               of shape (512, 2048, 1, 1)\n",
      "2019-06-28 12:08:34,610 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv2.weight               loaded from backbone.body.layer4.2.conv2.weight               of shape (512, 512, 3, 3)\n",
      "2019-06-28 12:08:34,611 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.layer4.2.conv3.weight               loaded from backbone.body.layer4.2.conv3.weight               of shape (2048, 512, 1, 1)\n",
      "2019-06-28 12:08:34,613 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.bias                       loaded from backbone.body.stem.bn1.bias                       of shape (64,)\n",
      "2019-06-28 12:08:34,613 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.running_mean               loaded from backbone.body.stem.bn1.running_mean               of shape (64,)\n",
      "2019-06-28 12:08:34,614 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.running_var                loaded from backbone.body.stem.bn1.running_var                of shape (64,)\n",
      "2019-06-28 12:08:34,615 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.bn1.weight                     loaded from backbone.body.stem.bn1.weight                     of shape (64,)\n",
      "2019-06-28 12:08:34,616 maskrcnn_benchmark.utils.model_serialization INFO: backbone.body.stem.conv1.weight                   loaded from backbone.body.stem.conv1.weight                   of shape (64, 3, 7, 7)\n",
      "2019-06-28 12:08:34,616 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner1.bias                      loaded from backbone.fpn.fpn_inner1.bias                      of shape (256,)\n",
      "2019-06-28 12:08:34,617 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner1.weight                    loaded from backbone.fpn.fpn_inner1.weight                    of shape (256, 256, 1, 1)\n",
      "2019-06-28 12:08:34,618 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner2.bias                      loaded from backbone.fpn.fpn_inner2.bias                      of shape (256,)\n",
      "2019-06-28 12:08:34,619 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner2.weight                    loaded from backbone.fpn.fpn_inner2.weight                    of shape (256, 512, 1, 1)\n",
      "2019-06-28 12:08:34,619 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner3.bias                      loaded from backbone.fpn.fpn_inner3.bias                      of shape (256,)\n",
      "2019-06-28 12:08:34,620 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner3.weight                    loaded from backbone.fpn.fpn_inner3.weight                    of shape (256, 1024, 1, 1)\n",
      "2019-06-28 12:08:34,621 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner4.bias                      loaded from backbone.fpn.fpn_inner4.bias                      of shape (256,)\n",
      "2019-06-28 12:08:34,622 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_inner4.weight                    loaded from backbone.fpn.fpn_inner4.weight                    of shape (256, 2048, 1, 1)\n",
      "2019-06-28 12:08:34,623 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer1.bias                      loaded from backbone.fpn.fpn_layer1.bias                      of shape (256,)\n",
      "2019-06-28 12:08:34,625 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer1.weight                    loaded from backbone.fpn.fpn_layer1.weight                    of shape (256, 256, 3, 3)\n",
      "2019-06-28 12:08:34,627 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer2.bias                      loaded from backbone.fpn.fpn_layer2.bias                      of shape (256,)\n",
      "2019-06-28 12:08:34,628 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer2.weight                    loaded from backbone.fpn.fpn_layer2.weight                    of shape (256, 256, 3, 3)\n",
      "2019-06-28 12:08:34,630 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer3.bias                      loaded from backbone.fpn.fpn_layer3.bias                      of shape (256,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-28 12:08:34,631 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer3.weight                    loaded from backbone.fpn.fpn_layer3.weight                    of shape (256, 256, 3, 3)\n",
      "2019-06-28 12:08:34,632 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer4.bias                      loaded from backbone.fpn.fpn_layer4.bias                      of shape (256,)\n",
      "2019-06-28 12:08:34,634 maskrcnn_benchmark.utils.model_serialization INFO: backbone.fpn.fpn_layer4.weight                    loaded from backbone.fpn.fpn_layer4.weight                    of shape (256, 256, 3, 3)\n",
      "2019-06-28 12:08:34,635 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc6.bias          loaded from roi_heads.box.feature_extractor.fc6.bias          of shape (1024,)\n",
      "2019-06-28 12:08:34,636 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc6.weight        loaded from roi_heads.box.feature_extractor.fc6.weight        of shape (1024, 12544)\n",
      "2019-06-28 12:08:34,637 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc7.bias          loaded from roi_heads.box.feature_extractor.fc7.bias          of shape (1024,)\n",
      "2019-06-28 12:08:34,637 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.box.feature_extractor.fc7.weight        loaded from roi_heads.box.feature_extractor.fc7.weight        of shape (1024, 1024)\n",
      "2019-06-28 12:08:34,638 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.mask.feature_extractor.mask_fcn1.bias   loaded from roi_heads.mask.feature_extractor.mask_fcn1.bias   of shape (256,)\n",
      "2019-06-28 12:08:34,639 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.mask.feature_extractor.mask_fcn1.weight loaded from roi_heads.mask.feature_extractor.mask_fcn1.weight of shape (256, 256, 3, 3)\n",
      "2019-06-28 12:08:34,640 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.mask.feature_extractor.mask_fcn2.bias   loaded from roi_heads.mask.feature_extractor.mask_fcn2.bias   of shape (256,)\n",
      "2019-06-28 12:08:34,641 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.mask.feature_extractor.mask_fcn2.weight loaded from roi_heads.mask.feature_extractor.mask_fcn2.weight of shape (256, 256, 3, 3)\n",
      "2019-06-28 12:08:34,642 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.mask.feature_extractor.mask_fcn3.bias   loaded from roi_heads.mask.feature_extractor.mask_fcn3.bias   of shape (256,)\n",
      "2019-06-28 12:08:34,643 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.mask.feature_extractor.mask_fcn3.weight loaded from roi_heads.mask.feature_extractor.mask_fcn3.weight of shape (256, 256, 3, 3)\n",
      "2019-06-28 12:08:34,644 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.mask.feature_extractor.mask_fcn4.bias   loaded from roi_heads.mask.feature_extractor.mask_fcn4.bias   of shape (256,)\n",
      "2019-06-28 12:08:34,645 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.mask.feature_extractor.mask_fcn4.weight loaded from roi_heads.mask.feature_extractor.mask_fcn4.weight of shape (256, 256, 3, 3)\n",
      "2019-06-28 12:08:34,646 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.mask.predictor.conv5_mask.bias          loaded from roi_heads.mask.predictor.conv5_mask.bias          of shape (256,)\n",
      "2019-06-28 12:08:34,647 maskrcnn_benchmark.utils.model_serialization INFO: roi_heads.mask.predictor.conv5_mask.weight        loaded from roi_heads.mask.predictor.conv5_mask.weight        of shape (256, 256, 2, 2)\n",
      "2019-06-28 12:08:34,648 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.0               loaded from rpn.anchor_generator.cell_anchors.0               of shape (3, 4)\n",
      "2019-06-28 12:08:34,649 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.1               loaded from rpn.anchor_generator.cell_anchors.1               of shape (3, 4)\n",
      "2019-06-28 12:08:34,650 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.2               loaded from rpn.anchor_generator.cell_anchors.2               of shape (3, 4)\n",
      "2019-06-28 12:08:34,651 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.3               loaded from rpn.anchor_generator.cell_anchors.3               of shape (3, 4)\n",
      "2019-06-28 12:08:34,652 maskrcnn_benchmark.utils.model_serialization INFO: rpn.anchor_generator.cell_anchors.4               loaded from rpn.anchor_generator.cell_anchors.4               of shape (3, 4)\n",
      "2019-06-28 12:08:34,653 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bbox_pred.bias                           loaded from rpn.head.bbox_pred.bias                           of shape (12,)\n",
      "2019-06-28 12:08:34,654 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.bbox_pred.weight                         loaded from rpn.head.bbox_pred.weight                         of shape (12, 256, 1, 1)\n",
      "2019-06-28 12:08:34,655 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.cls_logits.bias                          loaded from rpn.head.cls_logits.bias                          of shape (3,)\n",
      "2019-06-28 12:08:34,655 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.cls_logits.weight                        loaded from rpn.head.cls_logits.weight                        of shape (3, 256, 1, 1)\n",
      "2019-06-28 12:08:34,656 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.conv.bias                                loaded from rpn.head.conv.bias                                of shape (256,)\n",
      "2019-06-28 12:08:34,658 maskrcnn_benchmark.utils.model_serialization INFO: rpn.head.conv.weight                              loaded from rpn.head.conv.weight                              of shape (256, 256, 3, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-28 12:08:34,708 maskrcnn_benchmark.trainer INFO: Start training\n",
      "2019-06-28 12:08:47,205 maskrcnn_benchmark.trainer INFO: eta: 0:10:12  iter: 20  loss: 1.0726 (1.3397)  loss_classifier: 0.3113 (0.4078)  loss_box_reg: 0.1371 (0.1464)  loss_mask: 0.5809 (0.7512)  loss_objectness: 0.0190 (0.0229)  loss_rpn_box_reg: 0.0105 (0.0114)  time: 0.6228 (0.6247)  data: 0.0081 (0.0317)  lr: 0.001800  max mem: 6544\n",
      "2019-06-28 12:09:00,279 maskrcnn_benchmark.trainer INFO: eta: 0:10:13  iter: 40  loss: 0.7243 (1.0395)  loss_classifier: 0.2564 (0.3317)  loss_box_reg: 0.2048 (0.1744)  loss_mask: 0.2486 (0.5095)  loss_objectness: 0.0079 (0.0154)  loss_rpn_box_reg: 0.0053 (0.0084)  time: 0.6491 (0.6392)  data: 0.0084 (0.0203)  lr: 0.001933  max mem: 6685\n",
      "2019-06-28 12:09:12,808 maskrcnn_benchmark.trainer INFO: eta: 0:09:56  iter: 60  loss: 0.4187 (0.8343)  loss_classifier: 0.1463 (0.2711)  loss_box_reg: 0.1647 (0.1723)  loss_mask: 0.0895 (0.3737)  loss_objectness: 0.0019 (0.0109)  loss_rpn_box_reg: 0.0020 (0.0064)  time: 0.6232 (0.6350)  data: 0.0084 (0.0164)  lr: 0.002067  max mem: 6685\n",
      "2019-06-28 12:09:25,723 maskrcnn_benchmark.trainer INFO: eta: 0:09:46  iter: 80  loss: 0.2977 (0.7059)  loss_classifier: 0.0923 (0.2283)  loss_box_reg: 0.1257 (0.1613)  loss_mask: 0.0744 (0.3022)  loss_objectness: 0.0009 (0.0087)  loss_rpn_box_reg: 0.0024 (0.0054)  time: 0.6421 (0.6377)  data: 0.0087 (0.0145)  lr: 0.002200  max mem: 6685\n",
      "2019-06-28 12:09:38,658 maskrcnn_benchmark.trainer INFO: eta: 0:09:35  iter: 100  loss: 0.1940 (0.6091)  loss_classifier: 0.0603 (0.1958)  loss_box_reg: 0.0543 (0.1416)  loss_mask: 0.0639 (0.2596)  loss_objectness: 0.0004 (0.0074)  loss_rpn_box_reg: 0.0018 (0.0048)  time: 0.6328 (0.6395)  data: 0.0086 (0.0134)  lr: 0.002333  max mem: 6685\n",
      "2019-06-28 12:09:38,661 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to shapeDir/model_0000100.pth\n",
      "2019-06-28 12:09:51,892 maskrcnn_benchmark.trainer INFO: eta: 0:09:25  iter: 120  loss: 0.1813 (0.5395)  loss_classifier: 0.0543 (0.1727)  loss_box_reg: 0.0392 (0.1243)  loss_mask: 0.0842 (0.2316)  loss_objectness: 0.0007 (0.0065)  loss_rpn_box_reg: 0.0018 (0.0043)  time: 0.6437 (0.6432)  data: 0.0084 (0.0161)  lr: 0.002467  max mem: 6685\n",
      "2019-06-28 12:10:05,467 maskrcnn_benchmark.trainer INFO: eta: 0:09:17  iter: 140  loss: 0.1463 (0.4865)  loss_classifier: 0.0431 (0.1559)  loss_box_reg: 0.0279 (0.1113)  loss_mask: 0.0739 (0.2094)  loss_objectness: 0.0004 (0.0059)  loss_rpn_box_reg: 0.0015 (0.0040)  time: 0.6735 (0.6483)  data: 0.0093 (0.0152)  lr: 0.002600  max mem: 6685\n",
      "2019-06-28 12:10:17,874 maskrcnn_benchmark.trainer INFO: eta: 0:09:01  iter: 160  loss: 0.1300 (0.4410)  loss_classifier: 0.0325 (0.1404)  loss_box_reg: 0.0210 (0.1000)  loss_mask: 0.0689 (0.1915)  loss_objectness: 0.0003 (0.0054)  loss_rpn_box_reg: 0.0012 (0.0037)  time: 0.6011 (0.6448)  data: 0.0088 (0.0144)  lr: 0.002733  max mem: 6685\n",
      "2019-06-28 12:10:30,691 maskrcnn_benchmark.trainer INFO: eta: 0:08:48  iter: 180  loss: 0.1122 (0.4051)  loss_classifier: 0.0339 (0.1285)  loss_box_reg: 0.0173 (0.0911)  loss_mask: 0.0569 (0.1772)  loss_objectness: 0.0002 (0.0048)  loss_rpn_box_reg: 0.0008 (0.0034)  time: 0.6511 (0.6443)  data: 0.0089 (0.0139)  lr: 0.002867  max mem: 6685\n",
      "2019-06-28 12:10:43,332 maskrcnn_benchmark.trainer INFO: eta: 0:08:34  iter: 200  loss: 0.0930 (0.3744)  loss_classifier: 0.0281 (0.1184)  loss_box_reg: 0.0139 (0.0834)  loss_mask: 0.0476 (0.1650)  loss_objectness: 0.0002 (0.0044)  loss_rpn_box_reg: 0.0006 (0.0031)  time: 0.6254 (0.6431)  data: 0.0087 (0.0134)  lr: 0.003000  max mem: 6685\n",
      "2019-06-28 12:10:43,335 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to shapeDir/model_0000200.pth\n",
      "2019-06-28 12:10:56,043 maskrcnn_benchmark.trainer INFO: eta: 0:08:21  iter: 220  loss: 0.0870 (0.3496)  loss_classifier: 0.0257 (0.1102)  loss_box_reg: 0.0141 (0.0772)  loss_mask: 0.0499 (0.1552)  loss_objectness: 0.0001 (0.0040)  loss_rpn_box_reg: 0.0007 (0.0030)  time: 0.6270 (0.6424)  data: 0.0090 (0.0149)  lr: 0.003133  max mem: 6685\n",
      "2019-06-28 12:11:09,329 maskrcnn_benchmark.trainer INFO: eta: 0:08:09  iter: 240  loss: 0.0994 (0.3303)  loss_classifier: 0.0269 (0.1038)  loss_box_reg: 0.0182 (0.0725)  loss_mask: 0.0518 (0.1475)  loss_objectness: 0.0001 (0.0037)  loss_rpn_box_reg: 0.0011 (0.0028)  time: 0.6507 (0.6442)  data: 0.0102 (0.0145)  lr: 0.003267  max mem: 6685\n",
      "2019-06-28 12:11:22,549 maskrcnn_benchmark.trainer INFO: eta: 0:07:57  iter: 260  loss: 0.0919 (0.3133)  loss_classifier: 0.0266 (0.0981)  loss_box_reg: 0.0125 (0.0682)  loss_mask: 0.0514 (0.1407)  loss_objectness: 0.0001 (0.0035)  loss_rpn_box_reg: 0.0013 (0.0027)  time: 0.6502 (0.6455)  data: 0.0100 (0.0142)  lr: 0.003400  max mem: 6738\n",
      "2019-06-28 12:11:35,209 maskrcnn_benchmark.trainer INFO: eta: 0:07:44  iter: 280  loss: 0.0874 (0.2975)  loss_classifier: 0.0221 (0.0930)  loss_box_reg: 0.0125 (0.0644)  loss_mask: 0.0522 (0.1342)  loss_objectness: 0.0000 (0.0033)  loss_rpn_box_reg: 0.0010 (0.0026)  time: 0.6228 (0.6446)  data: 0.0095 (0.0139)  lr: 0.003533  max mem: 6738\n",
      "2019-06-28 12:11:48,017 maskrcnn_benchmark.trainer INFO: eta: 0:07:31  iter: 300  loss: 0.0745 (0.2839)  loss_classifier: 0.0199 (0.0883)  loss_box_reg: 0.0091 (0.0610)  loss_mask: 0.0465 (0.1290)  loss_objectness: 0.0000 (0.0031)  loss_rpn_box_reg: 0.0007 (0.0025)  time: 0.6333 (0.6444)  data: 0.0096 (0.0136)  lr: 0.003667  max mem: 6738\n",
      "2019-06-28 12:11:48,019 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to shapeDir/model_0000300.pth\n",
      "2019-06-28 12:12:01,780 maskrcnn_benchmark.trainer INFO: eta: 0:07:20  iter: 320  loss: 0.0839 (0.2723)  loss_classifier: 0.0245 (0.0844)  loss_box_reg: 0.0095 (0.0580)  loss_mask: 0.0482 (0.1245)  loss_objectness: 0.0001 (0.0030)  loss_rpn_box_reg: 0.0008 (0.0024)  time: 0.6715 (0.6471)  data: 0.0091 (0.0147)  lr: 0.003800  max mem: 6738\n",
      "2019-06-28 12:12:14,654 maskrcnn_benchmark.trainer INFO: eta: 0:07:06  iter: 340  loss: 0.0897 (0.2615)  loss_classifier: 0.0196 (0.0808)  loss_box_reg: 0.0118 (0.0554)  loss_mask: 0.0484 (0.1202)  loss_objectness: 0.0000 (0.0028)  loss_rpn_box_reg: 0.0005 (0.0023)  time: 0.6269 (0.6469)  data: 0.0094 (0.0144)  lr: 0.003933  max mem: 6738\n",
      "2019-06-28 12:12:28,094 maskrcnn_benchmark.trainer INFO: eta: 0:06:54  iter: 360  loss: 0.0907 (0.2523)  loss_classifier: 0.0258 (0.0778)  loss_box_reg: 0.0122 (0.0530)  loss_mask: 0.0592 (0.1166)  loss_objectness: 0.0001 (0.0027)  loss_rpn_box_reg: 0.0006 (0.0022)  time: 0.6717 (0.6483)  data: 0.0100 (0.0142)  lr: 0.004067  max mem: 6738\n",
      "2019-06-28 12:12:41,271 maskrcnn_benchmark.trainer INFO: eta: 0:06:42  iter: 380  loss: 0.0866 (0.2439)  loss_classifier: 0.0218 (0.0748)  loss_box_reg: 0.0116 (0.0509)  loss_mask: 0.0514 (0.1135)  loss_objectness: 0.0001 (0.0026)  loss_rpn_box_reg: 0.0007 (0.0022)  time: 0.6628 (0.6488)  data: 0.0103 (0.0140)  lr: 0.004200  max mem: 6738\n",
      "2019-06-28 12:12:54,456 maskrcnn_benchmark.trainer INFO: eta: 0:06:29  iter: 400  loss: 0.0799 (0.2366)  loss_classifier: 0.0194 (0.0723)  loss_box_reg: 0.0101 (0.0490)  loss_mask: 0.0460 (0.1107)  loss_objectness: 0.0000 (0.0025)  loss_rpn_box_reg: 0.0007 (0.0021)  time: 0.6340 (0.6494)  data: 0.0102 (0.0138)  lr: 0.004333  max mem: 6762\n",
      "2019-06-28 12:12:54,459 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to shapeDir/model_0000400.pth\n",
      "2019-06-28 12:13:07,634 maskrcnn_benchmark.trainer INFO: eta: 0:06:16  iter: 420  loss: 0.0807 (0.2292)  loss_classifier: 0.0194 (0.0697)  loss_box_reg: 0.0076 (0.0471)  loss_mask: 0.0514 (0.1079)  loss_objectness: 0.0000 (0.0024)  loss_rpn_box_reg: 0.0005 (0.0020)  time: 0.6527 (0.6498)  data: 0.0107 (0.0147)  lr: 0.004467  max mem: 6762\n",
      "2019-06-28 12:13:20,486 maskrcnn_benchmark.trainer INFO: eta: 0:06:03  iter: 440  loss: 0.0824 (0.2227)  loss_classifier: 0.0183 (0.0675)  loss_box_reg: 0.0103 (0.0455)  loss_mask: 0.0455 (0.1055)  loss_objectness: 0.0000 (0.0023)  loss_rpn_box_reg: 0.0007 (0.0020)  time: 0.6376 (0.6495)  data: 0.0096 (0.0145)  lr: 0.004600  max mem: 6762\n",
      "2019-06-28 12:13:33,582 maskrcnn_benchmark.trainer INFO: eta: 0:05:50  iter: 460  loss: 0.0865 (0.2170)  loss_classifier: 0.0220 (0.0655)  loss_box_reg: 0.0084 (0.0441)  loss_mask: 0.0473 (0.1033)  loss_objectness: 0.0000 (0.0022)  loss_rpn_box_reg: 0.0006 (0.0019)  time: 0.6600 (0.6497)  data: 0.0094 (0.0143)  lr: 0.004733  max mem: 6762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-28 12:13:46,166 maskrcnn_benchmark.trainer INFO: eta: 0:05:37  iter: 480  loss: 0.0663 (0.2110)  loss_classifier: 0.0147 (0.0635)  loss_box_reg: 0.0058 (0.0426)  loss_mask: 0.0417 (0.1009)  loss_objectness: 0.0000 (0.0021)  loss_rpn_box_reg: 0.0004 (0.0019)  time: 0.6129 (0.6489)  data: 0.0095 (0.0142)  lr: 0.004867  max mem: 6762\n",
      "2019-06-28 12:13:59,229 maskrcnn_benchmark.trainer INFO: eta: 0:05:24  iter: 500  loss: 0.0738 (0.2055)  loss_classifier: 0.0188 (0.0618)  loss_box_reg: 0.0088 (0.0413)  loss_mask: 0.0392 (0.0986)  loss_objectness: 0.0000 (0.0020)  loss_rpn_box_reg: 0.0005 (0.0018)  time: 0.6601 (0.6490)  data: 0.0101 (0.0140)  lr: 0.005000  max mem: 6762\n",
      "2019-06-28 12:13:59,230 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to shapeDir/model_0000500.pth\n",
      "2019-06-28 12:14:11,982 maskrcnn_benchmark.trainer INFO: eta: 0:05:11  iter: 520  loss: 0.0795 (0.2006)  loss_classifier: 0.0186 (0.0602)  loss_box_reg: 0.0077 (0.0401)  loss_mask: 0.0476 (0.0966)  loss_objectness: 0.0000 (0.0019)  loss_rpn_box_reg: 0.0010 (0.0018)  time: 0.6208 (0.6486)  data: 0.0094 (0.0147)  lr: 0.005000  max mem: 6762\n",
      "2019-06-28 12:14:24,238 maskrcnn_benchmark.trainer INFO: eta: 0:04:57  iter: 540  loss: 0.0523 (0.1955)  loss_classifier: 0.0121 (0.0585)  loss_box_reg: 0.0046 (0.0388)  loss_mask: 0.0328 (0.0945)  loss_objectness: 0.0000 (0.0019)  loss_rpn_box_reg: 0.0004 (0.0018)  time: 0.5956 (0.6473)  data: 0.0101 (0.0146)  lr: 0.005000  max mem: 6762\n",
      "2019-06-28 12:14:36,773 maskrcnn_benchmark.trainer INFO: eta: 0:04:44  iter: 560  loss: 0.0680 (0.1909)  loss_classifier: 0.0159 (0.0569)  loss_box_reg: 0.0075 (0.0377)  loss_mask: 0.0395 (0.0927)  loss_objectness: 0.0000 (0.0018)  loss_rpn_box_reg: 0.0005 (0.0017)  time: 0.6261 (0.6465)  data: 0.0095 (0.0144)  lr: 0.005000  max mem: 6762\n",
      "2019-06-28 12:14:49,985 maskrcnn_benchmark.trainer INFO: eta: 0:04:31  iter: 580  loss: 0.0708 (0.1874)  loss_classifier: 0.0193 (0.0558)  loss_box_reg: 0.0079 (0.0368)  loss_mask: 0.0478 (0.0913)  loss_objectness: 0.0000 (0.0018)  loss_rpn_box_reg: 0.0006 (0.0017)  time: 0.6586 (0.6470)  data: 0.0096 (0.0143)  lr: 0.005000  max mem: 6762\n",
      "2019-06-28 12:15:02,574 maskrcnn_benchmark.trainer INFO: eta: 0:04:18  iter: 600  loss: 0.0602 (0.1833)  loss_classifier: 0.0154 (0.0544)  loss_box_reg: 0.0058 (0.0358)  loss_mask: 0.0365 (0.0896)  loss_objectness: 0.0000 (0.0017)  loss_rpn_box_reg: 0.0004 (0.0017)  time: 0.6140 (0.6464)  data: 0.0097 (0.0141)  lr: 0.005000  max mem: 6762\n",
      "2019-06-28 12:15:02,578 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to shapeDir/model_0000600.pth\n",
      "2019-06-28 12:15:15,215 maskrcnn_benchmark.trainer INFO: eta: 0:04:05  iter: 620  loss: 0.0516 (0.1797)  loss_classifier: 0.0138 (0.0532)  loss_box_reg: 0.0053 (0.0350)  loss_mask: 0.0355 (0.0882)  loss_objectness: 0.0000 (0.0017)  loss_rpn_box_reg: 0.0005 (0.0016)  time: 0.6254 (0.6460)  data: 0.0094 (0.0147)  lr: 0.005000  max mem: 6762\n",
      "2019-06-28 12:15:27,473 maskrcnn_benchmark.trainer INFO: eta: 0:03:52  iter: 640  loss: 0.0621 (0.1763)  loss_classifier: 0.0160 (0.0522)  loss_box_reg: 0.0062 (0.0342)  loss_mask: 0.0435 (0.0867)  loss_objectness: 0.0000 (0.0016)  loss_rpn_box_reg: 0.0003 (0.0016)  time: 0.6071 (0.6449)  data: 0.0095 (0.0145)  lr: 0.005000  max mem: 6762\n",
      "2019-06-28 12:15:39,861 maskrcnn_benchmark.trainer INFO: eta: 0:03:39  iter: 660  loss: 0.0662 (0.1730)  loss_classifier: 0.0167 (0.0511)  loss_box_reg: 0.0085 (0.0334)  loss_mask: 0.0393 (0.0854)  loss_objectness: 0.0000 (0.0016)  loss_rpn_box_reg: 0.0007 (0.0016)  time: 0.6225 (0.6442)  data: 0.0092 (0.0144)  lr: 0.005000  max mem: 6778\n",
      "2019-06-28 12:15:52,306 maskrcnn_benchmark.trainer INFO: eta: 0:03:25  iter: 680  loss: 0.0630 (0.1699)  loss_classifier: 0.0153 (0.0501)  loss_box_reg: 0.0055 (0.0326)  loss_mask: 0.0411 (0.0841)  loss_objectness: 0.0000 (0.0015)  loss_rpn_box_reg: 0.0004 (0.0015)  time: 0.6148 (0.6435)  data: 0.0088 (0.0142)  lr: 0.005000  max mem: 6778\n",
      "2019-06-28 12:16:04,261 maskrcnn_benchmark.trainer INFO: eta: 0:03:12  iter: 700  loss: 0.0606 (0.1670)  loss_classifier: 0.0116 (0.0491)  loss_box_reg: 0.0053 (0.0319)  loss_mask: 0.0430 (0.0830)  loss_objectness: 0.0000 (0.0015)  loss_rpn_box_reg: 0.0004 (0.0015)  time: 0.5783 (0.6422)  data: 0.0092 (0.0141)  lr: 0.000500  max mem: 6778\n",
      "2019-06-28 12:16:04,263 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to shapeDir/model_0000700.pth\n",
      "2019-06-28 12:16:16,461 maskrcnn_benchmark.trainer INFO: eta: 0:02:59  iter: 720  loss: 0.0597 (0.1642)  loss_classifier: 0.0128 (0.0481)  loss_box_reg: 0.0046 (0.0311)  loss_mask: 0.0380 (0.0819)  loss_objectness: 0.0000 (0.0015)  loss_rpn_box_reg: 0.0003 (0.0015)  time: 0.5918 (0.6413)  data: 0.0091 (0.0145)  lr: 0.000500  max mem: 6778\n",
      "2019-06-28 12:16:28,602 maskrcnn_benchmark.trainer INFO: eta: 0:02:46  iter: 740  loss: 0.0527 (0.1614)  loss_classifier: 0.0113 (0.0472)  loss_box_reg: 0.0052 (0.0305)  loss_mask: 0.0358 (0.0809)  loss_objectness: 0.0000 (0.0014)  loss_rpn_box_reg: 0.0004 (0.0014)  time: 0.6043 (0.6404)  data: 0.0095 (0.0144)  lr: 0.000500  max mem: 6778\n",
      "2019-06-28 12:16:40,762 maskrcnn_benchmark.trainer INFO: eta: 0:02:33  iter: 760  loss: 0.0536 (0.1588)  loss_classifier: 0.0106 (0.0463)  loss_box_reg: 0.0042 (0.0298)  loss_mask: 0.0380 (0.0798)  loss_objectness: 0.0000 (0.0014)  loss_rpn_box_reg: 0.0003 (0.0014)  time: 0.5838 (0.6395)  data: 0.0100 (0.0143)  lr: 0.000500  max mem: 6778\n",
      "2019-06-28 12:16:52,801 maskrcnn_benchmark.trainer INFO: eta: 0:02:20  iter: 780  loss: 0.0469 (0.1561)  loss_classifier: 0.0096 (0.0454)  loss_box_reg: 0.0029 (0.0292)  loss_mask: 0.0329 (0.0787)  loss_objectness: 0.0000 (0.0014)  loss_rpn_box_reg: 0.0003 (0.0014)  time: 0.5857 (0.6386)  data: 0.0095 (0.0141)  lr: 0.000500  max mem: 6778\n",
      "2019-06-28 12:17:05,201 maskrcnn_benchmark.trainer INFO: eta: 0:02:07  iter: 800  loss: 0.0501 (0.1536)  loss_classifier: 0.0127 (0.0446)  loss_box_reg: 0.0051 (0.0286)  loss_mask: 0.0325 (0.0777)  loss_objectness: 0.0000 (0.0013)  loss_rpn_box_reg: 0.0002 (0.0014)  time: 0.6163 (0.6381)  data: 0.0099 (0.0140)  lr: 0.000050  max mem: 6778\n",
      "2019-06-28 12:17:05,204 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to shapeDir/model_0000800.pth\n",
      "2019-06-28 12:17:17,105 maskrcnn_benchmark.trainer INFO: eta: 0:01:54  iter: 820  loss: 0.0531 (0.1512)  loss_classifier: 0.0100 (0.0438)  loss_box_reg: 0.0046 (0.0280)  loss_mask: 0.0352 (0.0767)  loss_objectness: 0.0000 (0.0013)  loss_rpn_box_reg: 0.0003 (0.0013)  time: 0.5845 (0.6371)  data: 0.0095 (0.0145)  lr: 0.000050  max mem: 6778\n",
      "2019-06-28 12:17:29,456 maskrcnn_benchmark.trainer INFO: eta: 0:01:41  iter: 840  loss: 0.0544 (0.1491)  loss_classifier: 0.0116 (0.0431)  loss_box_reg: 0.0034 (0.0275)  loss_mask: 0.0366 (0.0759)  loss_objectness: 0.0000 (0.0013)  loss_rpn_box_reg: 0.0002 (0.0013)  time: 0.6042 (0.6366)  data: 0.0094 (0.0143)  lr: 0.000050  max mem: 6778\n",
      "2019-06-28 12:17:41,606 maskrcnn_benchmark.trainer INFO: eta: 0:01:29  iter: 860  loss: 0.0506 (0.1470)  loss_classifier: 0.0124 (0.0424)  loss_box_reg: 0.0034 (0.0270)  loss_mask: 0.0328 (0.0750)  loss_objectness: 0.0000 (0.0013)  loss_rpn_box_reg: 0.0002 (0.0013)  time: 0.6142 (0.6359)  data: 0.0093 (0.0142)  lr: 0.000050  max mem: 6778\n",
      "2019-06-28 12:17:54,122 maskrcnn_benchmark.trainer INFO: eta: 0:01:16  iter: 880  loss: 0.0521 (0.1450)  loss_classifier: 0.0113 (0.0417)  loss_box_reg: 0.0051 (0.0265)  loss_mask: 0.0371 (0.0742)  loss_objectness: 0.0000 (0.0012)  loss_rpn_box_reg: 0.0004 (0.0013)  time: 0.6138 (0.6357)  data: 0.0099 (0.0142)  lr: 0.000050  max mem: 6778\n",
      "2019-06-28 12:18:06,477 maskrcnn_benchmark.trainer INFO: eta: 0:01:03  iter: 900  loss: 0.0530 (0.1430)  loss_classifier: 0.0129 (0.0411)  loss_box_reg: 0.0051 (0.0260)  loss_mask: 0.0354 (0.0735)  loss_objectness: 0.0000 (0.0012)  loss_rpn_box_reg: 0.0003 (0.0013)  time: 0.6065 (0.6353)  data: 0.0098 (0.0141)  lr: 0.000050  max mem: 6778\n",
      "2019-06-28 12:18:06,480 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to shapeDir/model_0000900.pth\n",
      "2019-06-28 12:18:18,727 maskrcnn_benchmark.trainer INFO: eta: 0:00:50  iter: 920  loss: 0.0487 (0.1412)  loss_classifier: 0.0101 (0.0405)  loss_box_reg: 0.0033 (0.0256)  loss_mask: 0.0353 (0.0728)  loss_objectness: 0.0000 (0.0012)  loss_rpn_box_reg: 0.0002 (0.0012)  time: 0.5890 (0.6348)  data: 0.0098 (0.0144)  lr: 0.000050  max mem: 6778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-28 12:18:30,851 maskrcnn_benchmark.trainer INFO: eta: 0:00:38  iter: 940  loss: 0.0489 (0.1394)  loss_classifier: 0.0117 (0.0399)  loss_box_reg: 0.0037 (0.0251)  loss_mask: 0.0340 (0.0720)  loss_objectness: 0.0000 (0.0012)  loss_rpn_box_reg: 0.0002 (0.0012)  time: 0.6098 (0.6342)  data: 0.0096 (0.0143)  lr: 0.000050  max mem: 6778\n",
      "2019-06-28 12:18:43,579 maskrcnn_benchmark.trainer INFO: eta: 0:00:25  iter: 960  loss: 0.0525 (0.1377)  loss_classifier: 0.0114 (0.0393)  loss_box_reg: 0.0042 (0.0247)  loss_mask: 0.0344 (0.0713)  loss_objectness: 0.0000 (0.0011)  loss_rpn_box_reg: 0.0002 (0.0012)  time: 0.6322 (0.6342)  data: 0.0096 (0.0143)  lr: 0.000050  max mem: 6778\n",
      "2019-06-28 12:18:56,100 maskrcnn_benchmark.trainer INFO: eta: 0:00:12  iter: 980  loss: 0.0558 (0.1361)  loss_classifier: 0.0123 (0.0388)  loss_box_reg: 0.0048 (0.0243)  loss_mask: 0.0338 (0.0706)  loss_objectness: 0.0000 (0.0011)  loss_rpn_box_reg: 0.0003 (0.0012)  time: 0.6298 (0.6341)  data: 0.0095 (0.0142)  lr: 0.000050  max mem: 6778\n",
      "2019-06-28 12:19:08,590 maskrcnn_benchmark.trainer INFO: eta: 0:00:00  iter: 1000  loss: 0.0474 (0.1345)  loss_classifier: 0.0102 (0.0383)  loss_box_reg: 0.0044 (0.0240)  loss_mask: 0.0316 (0.0700)  loss_objectness: 0.0000 (0.0011)  loss_rpn_box_reg: 0.0003 (0.0012)  time: 0.6199 (0.6339)  data: 0.0098 (0.0141)  lr: 0.000050  max mem: 6778\n",
      "2019-06-28 12:19:08,593 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to shapeDir/model_0001000.pth\n",
      "2019-06-28 12:19:09,020 maskrcnn_benchmark.utils.checkpoint INFO: Saving checkpoint to shapeDir/model_final.pth\n",
      "2019-06-28 12:19:09,343 maskrcnn_benchmark.trainer INFO: Total training time: 0:10:34.633153 (0.6346 s / it)\n"
     ]
    }
   ],
   "source": [
    "config_file = \"shapes_config.yaml\"\n",
    "\n",
    "# update the config options with the config file\n",
    "cfg.merge_from_file(config_file)\n",
    "\n",
    "cfg.merge_from_list(['OUTPUT_DIR', 'shapeDir']) # The output folder where all our model checkpoints will be saved during training.\n",
    "cfg.merge_from_list(['SOLVER.IMS_PER_BATCH', 4]) # Number of images to take inside a single batch. This number depends on the size of your GPU\n",
    "cfg.merge_from_list(['SOLVER.BASE_LR', 0.0050]) # The Learning Rate when training starts. Please check Detectron scaling rules to determine your learning for your GPU setup. \n",
    "cfg.merge_from_list(['SOLVER.MAX_ITER', 1000]) # The number of training iterations that will be executed during training. One iteration is given as one forward and backward pass of a mini batch of the network\n",
    "cfg.merge_from_list(['SOLVER.STEPS', \"(700, 800)\"]) # These two numbers represent after how many iterations is the learning rate divided by 10. \n",
    "cfg.merge_from_list(['TEST.IMS_PER_BATCH', 1]) # Batch size during testing/evaluation\n",
    "cfg.merge_from_list(['MODEL.RPN.FPN_POST_NMS_TOP_N_TRAIN', 4000]) # This determines how many region proposals to take in for processing into the stage after the RPN. The rule is 1000*batch_size = 4*1000 \n",
    "cfg.merge_from_list(['SOLVER.CHECKPOINT_PERIOD', 100]) # After how many iterations does one want to save the model.\n",
    "\n",
    "# Make the Output dir if one doesnt exist.\n",
    "output_dir = cfg.OUTPUT_DIR\n",
    "if output_dir:\n",
    "    mkdir(output_dir)\n",
    "\n",
    "# Start training.\n",
    "model = train(cfg, local_rank=1, distributed=False, dataset=ShapeDataset(500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ONldqRzHUAm0"
   },
   "source": [
    "# Evaluation\n",
    "\n",
    "Now after our model is trained, we would like to see how well it predicts objects in our sample images. One way to validate your model is through a standard metric called COCO mAP. This metric is used widely. Hence, we shall do this now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s8YFliWAUG-E"
   },
   "source": [
    "### Doing Inference\n",
    "\n",
    "Helper function to perform inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6VbvZXhWkQ-0"
   },
   "outputs": [],
   "source": [
    "\n",
    "def do_inference(\n",
    "        model,\n",
    "        data_loader,\n",
    "        dataset_name,\n",
    "        iou_types=(\"bbox\",),\n",
    "        box_only=False,\n",
    "        device=\"cuda\",\n",
    "        expected_results=(),\n",
    "        expected_results_sigma_tol=4,\n",
    "        output_folder=None,):\n",
    "  \n",
    "    # convert to a torch.device for efficiency\n",
    "    device = torch.device(device)\n",
    "    num_devices = get_world_size()\n",
    "    logger = logging.getLogger(\"maskrcnn_benchmark.inference\")\n",
    "    dataset = data_loader.dataset\n",
    "    logger.info(\"Start evaluation on {} dataset({} images).\".format(dataset_name, len(dataset)))\n",
    "    total_timer = Timer()\n",
    "    inference_timer = Timer()\n",
    "    total_timer.tic()\n",
    "    predictions = compute_on_dataset(model, data_loader, device, inference_timer)\n",
    "    \n",
    "    # wait for all processes to complete before measuring the time\n",
    "    synchronize()\n",
    "    total_time = total_timer.toc()\n",
    "    total_time_str = get_time_str(total_time)\n",
    "    logger.info(\n",
    "        \"Total run time: {} ({} s / img per device, on {} devices)\".format(\n",
    "            total_time_str, total_time * num_devices / len(dataset), num_devices\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    total_infer_time = get_time_str(inference_timer.total_time)\n",
    "    logger.info(\n",
    "        \"Model inference time: {} ({} s / img per device, on {} devices)\".format(\n",
    "            total_infer_time,\n",
    "            inference_timer.total_time * num_devices / len(dataset),\n",
    "            num_devices,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    predictions = _accumulate_predictions_from_multiple_gpus(predictions)\n",
    "    if not is_main_process():\n",
    "        return\n",
    "\n",
    "    if output_folder:\n",
    "        torch.save(predictions, os.path.join(output_folder, \"predictions.pth\"))\n",
    "\n",
    "    extra_args = dict(\n",
    "        box_only=box_only,\n",
    "        iou_types=iou_types,\n",
    "        expected_results=expected_results,\n",
    "        expected_results_sigma_tol=expected_results_sigma_tol,\n",
    "    )\n",
    "\n",
    "    return coco_evaluation(dataset=dataset,\n",
    "                    predictions=predictions,\n",
    "                    output_folder=output_folder,\n",
    "                    **extra_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YcAidp5fUccv"
   },
   "source": [
    "### Testing Function\n",
    "\n",
    "Driver function to run the model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rIC4k6dUd4UB"
   },
   "outputs": [],
   "source": [
    "def run_test(cfg, model, distributed, dataset):\n",
    "    if distributed:\n",
    "        model = model.module\n",
    "    torch.cuda.empty_cache()  # TODO check if it helps\n",
    "    iou_types = (\"bbox\",)\n",
    "    \n",
    "    data_loaders_val = build_data_loader(cfg, dataset, is_train=False)\n",
    "    mkdir(\"shapeVal\")\n",
    "    for data_loader in data_loaders_val:\n",
    "      do_inference(\n",
    "          model,\n",
    "          data_loader, # For test we need this as zero\n",
    "          dataset_name=\"shape-val\",\n",
    "          iou_types=iou_types,\n",
    "          box_only=False if cfg.MODEL.RETINANET_ON else cfg.MODEL.RPN_ONLY,\n",
    "          device=cfg.MODEL.DEVICE,\n",
    "          expected_results=cfg.TEST.EXPECTED_RESULTS,\n",
    "          expected_results_sigma_tol=cfg.TEST.EXPECTED_RESULTS_SIGMA_TOL,\n",
    "          output_folder=\"shapeVal\",\n",
    "      )\n",
    "      synchronize()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LdVLSfrAd9Mi"
   },
   "source": [
    "### Run Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 598
    },
    "colab_type": "code",
    "id": "0GAUbBC-hsUq",
    "outputId": "6a51b2cc-d7c3-40b9-b8e7-15a96f30df8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "2019-06-02 18:58:27,806 maskrcnn_benchmark.inference INFO: Start evaluation on shape-val dataset(50 images).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:05<00:00, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-02 18:58:33,089 maskrcnn_benchmark.inference INFO: Total run time: 0:00:05.282553 (0.10565105438232422 s / img per device, on 1 devices)\n",
      "2019-06-02 18:58:33,090 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:04.614043 (0.09228085994720459 s / img per device, on 1 devices)\n",
      "2019-06-02 18:58:33,105 maskrcnn_benchmark.inference INFO: Preparing results for COCO format\n",
      "2019-06-02 18:58:33,107 maskrcnn_benchmark.inference INFO: Preparing bbox results\n",
      "2019-06-02 18:58:33,117 maskrcnn_benchmark.inference INFO: Evaluating predictions\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.04s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.885\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.976\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.957\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.885\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.714\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.908\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.908\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.908\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "2019-06-02 18:58:33,193 maskrcnn_benchmark.inference INFO: OrderedDict([('bbox', OrderedDict([('AP', 0.8847684644516638), ('AP50', 0.9764087519863097), ('AP75', 0.956912357902457), ('APs', -1.0), ('APm', 0.8847684644516638), ('APl', -1.0)]))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cfg.merge_from_list(['TEST.IMS_PER_BATCH', 1])\n",
    "\n",
    "run_test(cfg, model=model, distributed=False, dataset=ShapeDataset(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ccHt8YMdKq6K"
   },
   "source": [
    "# Visualise\n",
    "\n",
    "Another important part of validating your model is visualising the results. This is done below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kb9VchvVzRpu"
   },
   "outputs": [],
   "source": [
    "# Load Trained Model\n",
    "config_file = \"shapes_config.yaml\"\n",
    "\n",
    "cfg.merge_from_file(config_file)\n",
    "# manual override some options\n",
    "cfg.merge_from_list([\"MODEL.DEVICE\", \"cpu\"])\n",
    "\n",
    "vis_demo = COCODemo(\n",
    "    cfg, \n",
    "    min_image_size=800,\n",
    "    confidence_threshold=0.7)\n",
    "\n",
    "# Load Dataset\n",
    "dataset = ShapeDataset(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c8b6wHAXjyE5"
   },
   "source": [
    "## Visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "colab_type": "code",
    "id": "StOBbFmujxIw",
    "outputId": "c52ae633-20d7-4aa8-ad8a-1e1caeaf3ba5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAHVCAYAAADLvzPyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nITkDABCY/x+cDZZHF35ZBQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x576 with 4 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualise Results\n",
    "rows = 2\n",
    "cols = 2\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "for i in range(1, rows*cols+1):\n",
    "  img = dataset.load_image(i)\n",
    "  image = np.array(img)[:, :, [2, 1, 0]]\n",
    "  result = vis_demo.run_on_opencv_image(image)\n",
    "  \n",
    "  fig.add_subplot(rows, cols, i)\n",
    "  plt.imshow(result)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Mc6KoQ2eL6I"
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "Looks good! Have fun training the models on your own dataset ! There are a lot of features that this demo doesn't use, like:\n",
    "\n",
    "1. Mixed precision training\n",
    "2. Lighter object detection architectures like RetinaNet\n",
    "\n",
    "and so much more !"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "xnr8tbDz7WjS",
    "5DC0K7tW7d-M",
    "BI2ncK7kATEh",
    "hbzY16ocEdrg",
    "If8z4OZfDHmC",
    "mOo-0LGFEAmc",
    "bbCBInqHFUg7",
    "tAn3omCjTFGI",
    "BTKsrHa-TkGr"
   ],
   "name": "objdet.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "maskrcnn_benchmark",
   "language": "python",
   "name": "maskrcnn_benchmark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
